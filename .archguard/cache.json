{
  "filesHash": "77733e583c9a15ec86e9371c8c921c22a350fdc72303e062560fd4b6ffb76015",
  "fileHashes": {
    "packages/dashboard/tailwind.config.ts": "66811532d81e6e132cac1a47b4953d6648524e48672ae987ba42bbde0fd34bcf",
    "packages/dashboard/postcss.config.js": "fa650b380adfabb151a0b352f7135e107e6352345f899060f1c5c231228f94bf",
    "packages/dashboard/next.config.js": "b98503a136e11ad31696aace30e33102409ad34a95c1dc108225be7d691ffe6e",
    "packages/dashboard/next-env.d.ts": "9dd9d642cdb87d4d5b3173217e0c45429b3e47a6f5cf5fb0ead6c644ec5fed01",
    "packages/work-summary/src/summarizer.ts": "97928c17df17df1870806d94888372963ea8e42acef7ac53a5317a5850f97411",
    "packages/work-summary/src/scheduler.ts": "421e7f4f7ff3687da411d480c8c1ea107ebf61ecc7dc4ca0c5254cc653ac5744",
    "packages/work-summary/src/index.ts": "9eabca06020ffb2cd627d91cbc2aab0d2873a7f684bcf95c6f091df27a1d8797",
    "packages/work-summary/src/collector.ts": "9faab093b196cec78fa598fe12a4d1e46b1f65c97c1a2345400e2e7000ef6c51",
    "packages/velocity/src/types.ts": "62754dc9c335a2b18aed0635f5425ab3193ddc502064ae4da3665fc60484b107",
    "packages/velocity/src/index.ts": "0a571843cbff4f10762853af21b26b446de0093df5c195c19dd6b87f6abe08bf",
    "packages/server/src/index.ts": "d09d0a8b08307fc7681fda2f496bd14bacf4f63123ebbacd663e54fd85afce6f",
    "packages/server/src/hono-env.d.ts": "d94f6e7361059499520dcb625b48791c3604faa8d65fa2a1cfc6e043fd34b002",
    "packages/reviewer/src/severity.ts": "5d2287a315247a3322f913e762cf9a52edde5935fd688ebc0c73c81d79752fd7",
    "packages/reviewer/src/rule-engine.ts": "6dbdca0d3e9d81a233af430456aa730a752c8cba1e6b21a9d71322d07f9f4948",
    "packages/reviewer/src/llm-reviewer.ts": "75af44bf2ca0f87d5b93a78e06bd5fe82bf195f9f989093b5a9ece0c377842a8",
    "packages/reviewer/src/index.ts": "7b0929fbcea63568cfa3d8c23e05f101dabc23f5879231083786e3005d292050",
    "packages/reviewer/src/diff-analyzer.ts": "e3924176ad52ae0025c0b15c581f152ee861ce2aca9c84843694c40d533c924f",
    "packages/mcp-server/src/index.ts": "8d231c49542f3056bc43f30dab596f05084e5aba82a5c8fe4def9e4084b64ac5",
    "packages/integrations/src/index.ts": "4e7ab26bb15ce91180e80eefa81b8d14eff1822ba21ecd306c79c64b84027bb3",
    "packages/core/src/utils.ts": "fc04b4ec76f11cb0cafcaced1757eaca77f788a52f5a3d50d5a0a730887f2be8",
    "packages/core/src/types.ts": "55585a9a26d87e1c66b1f4d212b43772496aaf85e06458c23a874c2b36512369",
    "packages/core/src/logger.ts": "7d438bb5387fb1aa94f975ba826715e4b0b1258d53530fbe13f9a554975d37eb",
    "packages/core/src/llm.ts": "82b4c68e7d95596dd09d0018aee75c6867063bc2a69bd0c7edacc521a6e70742",
    "packages/core/src/index.ts": "c32d3cba0c9b68ad2f3fe2901a2d5232a55f7315347ad4d26f9e7dcc73c87086",
    "packages/core/src/git.ts": "486f0c5af21c6c278ce10f05c0ba41d826205347eccae16e8d9944a9108b8d7a",
    "packages/core/src/config.ts": "1385f4006ac824b5aa8ae1130e68a1eba4306f825afa54425bed0696af8797be",
    "packages/core/src/auth.ts": "a2878a1ea1ae42f10611c12a8fcf4686f5a68313e705a40e6f95603017648da3",
    "packages/context-sync/src/templates.ts": "c6a4ef4d25f5258a190c9a620c2e6db0052762cddcc68ef08adca1e775da6513",
    "packages/context-sync/src/sync-engine.ts": "d95dd294a074b1d02d0eebf716a5b9dc81f17892362db7e4bc9536356d407123",
    "packages/context-sync/src/llm-sync.ts": "51d3336200b23cff0bac924d14d6862878d70e27352d83a6f860afd6d78d35d7",
    "packages/context-sync/src/index.ts": "b1c600a899c8757dea98318efd88054d53c581fdacbfeeb319ba96ce7dacfc2f",
    "packages/cli/src/tapir-spinner.ts": "891bcd545c8ce76d52215aeb661b5635092c470a5fdf594a43aa80c2e86f49ef",
    "packages/cli/src/index.ts": "1625d804e9a320ea660d06933d6063e34664092e395a53653110efed0ef8867a",
    "packages/analyzer/src/trend-analyzer.ts": "867c94173ce14668a80c7f50d315c7bcfc054e1af0c1f201b7baa3ffa7389e9f",
    "packages/analyzer/src/scanner.ts": "345bd776447a46067e3d69fabf1a80407ced488b5e01c4c71778420c1561164d",
    "packages/analyzer/src/pattern-detector.ts": "95c0910494a93f89eccfb9d1f7f0fe9ae0c9be879665454fa50d511b7fb76fdc",
    "packages/analyzer/src/layer-detector.ts": "179e3d9357a397e06b11e7a170ff0ffd6788148ef827aa77cbd86741183ff4e0",
    "packages/analyzer/src/index.ts": "424ba0797ce7c873e88dccd7e116264974fc3e33882b981d59bd0b878cad06c7",
    "packages/analyzer/src/drift-detector.ts": "99fa50785e32e90c4ce57cbfbb96c6aa45da02361d13c2587a3b55c75a3e4961",
    "packages/analyzer/src/dependency-mapper.ts": "7fad462ef8800394ed67630585304bd111b1f7a8fbf08036da833eef4feaa8cb",
    "packages/analyzer/src/decision-extractor.ts": "93610055a1642b2ad6606c79e1d1fb7b7f252c17b979c4bf4473091906f43837",
    "packages/analyzer/src/cache.ts": "9231272767c0f2bd592beda00d91a680b391b70d6317f7ff3167785f2e9cb542",
    "packages/work-summary/src/templates/standup.ts": "d9aa3fba94bc596ad5413edc0601251c9aa2d28184abd1639964355d3e963694",
    "packages/work-summary/src/templates/sprint-review.ts": "41a5aac651a38df35a9ed81ed3d56159c6d91eea82be4b6b503d3167f9307845",
    "packages/work-summary/src/templates/progress-report.ts": "256115edc5ab8a267ce26856573ccd3d8ee6501bc8b7ece8a66dcbca6b9b0799",
    "packages/work-summary/src/templates/one-on-one.ts": "1f60e94fc2bdcec615e286c6f7b51edad889b672ea1c21f8209ff7706b4527b7",
    "packages/velocity/src/scoring/velocity-calculator.ts": "1d1ce18dc77369f47575cda677ca7da4ee6dbddae5d3ec5038a687c63338497f",
    "packages/velocity/src/scoring/impact-score.ts": "247b3fec5815a97948afb8d7824bb61dbd051c94ebf02e6996328828b4491708",
    "packages/velocity/src/scoring/effort-model.ts": "d270a3a1f042e758886f7f50e8fc55f742eb74a4592c13ba3950fe6abc5e15ca",
    "packages/velocity/src/collectors/pr-metrics.ts": "10464facf587db5fc457c501a287c825196b1a3a40d1661bb0b27052bda6c1ca",
    "packages/velocity/src/collectors/issue-tracker.ts": "98ffa15c52e1e4269bc970b04f67c12b983cf085aa7043b22dc18c5c598eb9e0",
    "packages/velocity/src/collectors/git-stats.ts": "56d6eab4f643ef7f0bbb16c92b6d58d8dc0cb272ea5c01922fcf2de96a5f0a2f",
    "packages/velocity/src/collectors/complexity.ts": "81b017ee3cfe964e23d3a293da75d9f1a24551826bf8ccdeba0d0d5a29953aca",
    "packages/velocity/src/blockers/detector.ts": "49ca06e8ded17c8569a4010ced8643b48c9aef3cc082de2f7db7c469e0f5bcb6",
    "packages/velocity/src/blockers/alerts.ts": "98b842cb3e0c93218231482d6eb3a9c84469d53e18d7b6aefa6c8d5fedd57bd7",
    "packages/server/src/routes/webhooks.ts": "fccc3f7941f39def2cad1733bc1a2503664ed210dea40d101df625f1168e50bb",
    "packages/server/src/routes/velocity.ts": "66ba7d72c98cb6075dd3a0e545f57f807f20385afcfd34e7cdd04956fc8739a2",
    "packages/server/src/routes/teams.ts": "b8cef85daf8337ad388bb65adbc397463a02957420336e17fbff46d86cb9be25",
    "packages/server/src/routes/sync.ts": "f9449d3977744e8a14df48606747975c932f0826f23b4646ac53cbab37e42ad0",
    "packages/server/src/routes/summaries.ts": "45646029d8ecd2de42bca421fc6591036972f7202c3d37f3e520c89b745bd396",
    "packages/server/src/routes/sse.ts": "fe9fbe9050256cb6363c5fbe99187f6c339fc82449dbf68981c4bff66eeb322e",
    "packages/server/src/routes/settings.ts": "1e221f06b80077968b78200374b8da1ae7f28803002fc7b88705dc4fa93b891e",
    "packages/server/src/routes/reviews.ts": "ec0a1a773f686e05689f0b3434d942f1af15c3c90dda65c6067e01ec24054b9a",
    "packages/server/src/routes/repos.ts": "3b4fcce11a16fd9087807ba642dd85ac4646148a9fd90cd9877aea761ad5045e",
    "packages/server/src/routes/decisions.ts": "6f466af299edc69bc1f84be0edb331fe1ab26848db1050dbdf4e0648d8db619c",
    "packages/server/src/routes/analysis.ts": "f5a38faa984b5ae9272f1877d07a4774ac94a6de61b3bcc5dd0a288474adaccc",
    "packages/server/src/middleware/rbac.ts": "9973cfd152c35995874fd1486d8dd288ba37dc6f77b61674b4e4d5a4dc9461cc",
    "packages/server/src/middleware/rate-limit.ts": "f2f4cb6a5dcbcd0c3ddfa31210a7a61a65da578ddac10dfb7650cd92b74686dd",
    "packages/server/src/middleware/org-context.ts": "aa7cb38b3ba65bd932df2e83b282ab5914891e4fce08e00a8624d6cfc90ad98c",
    "packages/server/src/middleware/auth.ts": "cce2222721a306460c1e37dab009d73467cb945c060de7bc0c4160f2ac0fb392",
    "packages/server/src/jobs/velocity.job.ts": "d63d218fbfd11e838062e6042abf7fd5d28a83f5eac656b9ab190b44a9804577",
    "packages/server/src/jobs/sync.job.ts": "d5edacec589a7a015b037fe774cb4a13899b9922d7763d089c8f2d34b608c382",
    "packages/server/src/jobs/summary.job.ts": "54ae572454a7dde4135ca4cc8fee23e318b3699500f0e1cf39c345bf41563fdf",
    "packages/server/src/jobs/review.job.ts": "fb32dd565eee488ee1e7b117932a2526da94c26a15eecd271b1e7bea362ccd1f",
    "packages/server/src/jobs/queue.ts": "dc0f14e2eb7a9ee290bbd9bdf0f1acee6e4fd69c0bf263fd2f908a4b0bd0c5e0",
    "packages/server/src/jobs/analyze.job.ts": "b27ef63085100c37b7751bfb8f39431c757b59249b8c58b590d4712daf173d22",
    "packages/server/src/auth/saml.ts": "c2a799a252da7dd880e00fdbd7f439dbcd6b3212e8917bd0080bce66d1110ce4",
    "packages/server/src/auth/roles.ts": "0b45b111d28d9d0582ba6d0340f13b2bf56242d9a0501d3360a756ac88a86768",
    "packages/server/src/auth/rbac.ts": "ea6442224cc89e51b1ed0183a184a2b1ca82b1ea461ce14714d36876b8ef47c8",
    "packages/server/src/auth/index.ts": "c72b013fc3170fe1db701cb08f236016b35a6fa43f67334af37977890bf0f5e5",
    "packages/reviewer/src/formatters/terminal.ts": "b3a09709599444278a3b83b6cc14186a5c6d07a331c5e418653ac82d50c19c97",
    "packages/reviewer/src/formatters/json.ts": "c46950455aafece32e71fd39df052244cc139b17707351e73eaac7c956df7c1d",
    "packages/reviewer/src/formatters/github-pr.ts": "3f91daee7132880a58344db64200a830361db2f0abea0b4b7e5652a83ea561a5",
    "packages/reviewer/src/formatters/bitbucket-pr.ts": "cae8973ef9e783c8733eb6044aa62104f121ba57168a29d07390062d5b75834d",
    "packages/mcp-server/src/tools/suggest-approach.ts": "f28b69fb385b0c3ce2b71345338289f5ccb175e3cbc47cc23434cac0946ba35c",
    "packages/mcp-server/src/tools/get-dependencies.ts": "dd384f00b81f51c84a2e4c2b624c137443b2a7d547a5644e2cb5707b68e73130",
    "packages/mcp-server/src/tools/get-decisions.ts": "e59e7f29bf945486355fef1771ba8cfa60661f232f0d5b8dda5fdd6d9964fe73",
    "packages/mcp-server/src/tools/check-pattern.ts": "2f6cb1862159f87d27bd36cfe6032a8d5ec902f5b7b0e4f8498f5e6520aa453f",
    "packages/mcp-server/src/resources/patterns.ts": "9a79ddfacc106532c8409eb56c48c1c161e2fff9e0966ed08f6f39bcb3b231d9",
    "packages/mcp-server/src/resources/decisions.ts": "cba66a8629c3afef8a0957a4916cf7071a8de62747ef96656015a047a872993a",
    "packages/integrations/src/slack/notifications.ts": "d5379f5c5477f098816395de9777f56af5a6136b8ef2f7cca3c37aa6289a84dc",
    "packages/integrations/src/slack/commands.ts": "6640ebd5b82dff8f5cdbf548d03737256e1ee178d4653207360ebc8c6912d5ba",
    "packages/integrations/src/slack/blocks.ts": "e0fbdc1c9db651cace35eda5a3a3a0016799aa81fb51de63b3517a74becc6e00",
    "packages/integrations/src/slack/app.ts": "4433be988680602a15d223dd1a127daab22ac83b0335d0dd9de0ad5dda4330fd",
    "packages/integrations/src/github/pr-bot.ts": "994bb0de970ae69f0f7e1a4844db086ca7fb87f2924b9bbabde4872c1bf1802f",
    "packages/integrations/src/github/check-run.ts": "7b3349eaeaa2f67b60f771cb2e9237ddac45b3c7827dcef7582f7238d98d3682",
    "packages/integrations/src/github/app.ts": "cd3b772fcefc1ef44456b1dd5ce1acfddaa84f94578319eb802748e5dd02d09b",
    "packages/integrations/src/github/api.ts": "1772522eb513f6c600f2b83b3a67517898d2db5412cf6edf51c9545d859c7d5d",
    "packages/integrations/src/bitbucket/webhook.ts": "ad1e86fb156a7bcd1fd8e61b1d18598ba4933351e4282b784a54440cca85147b",
    "packages/integrations/src/bitbucket/pr-bot.ts": "b299738be55a7290e243923047c7afa3de38098dcd1cca861a2e3ae47b570843",
    "packages/integrations/src/bitbucket/api.ts": "091a7c0e3d376bc064ad80cce202d056cc90ad89b016c62d640211bb6c509588",
    "packages/dashboard/src/lib/utils.ts": "acb0d31a3eb1c631a655b79e3a2d935cec90eeaac426baa5c89494eb0c758462",
    "packages/dashboard/src/lib/sse.ts": "16e51f1a17f558ade78c92756e2475c73a8ce40286899be670905dc171fbf420",
    "packages/dashboard/src/lib/auth.ts": "c15cb4842e104a59c147f7fe0178d25fdbe10417c38d6cdf6ee736684e2a52cd",
    "packages/dashboard/src/lib/api.ts": "e1497df5f991d8f3d28c519dd63159b035efc02ecfcbf5e85f54dbcf8884921e",
    "packages/dashboard/src/hooks/use-velocity.ts": "e04f8983d1c5121afa58a44bf874b99bb666a232b744c439990230c3101cbec3",
    "packages/dashboard/src/hooks/use-sse.ts": "b9ea7db5255218729bed9a285ee565b192d8b1ba7e3c6667d652a7935b3ac125",
    "packages/dashboard/src/hooks/use-reviews.ts": "e1dbc89a3c9c5db806836e46fb1b80188029bb172f3d8a3bb3d1530a2bfeabfe",
    "packages/dashboard/src/hooks/use-decisions.ts": "1e3d000add841104469148da98430e0ca6826a67072ebba0bff48dfee6019248",
    "packages/dashboard/src/app/page.tsx": "1f2e1d1ffbe82ef332b74ee5e0b08642782b26ed723993fa37e2569ce8921d36",
    "packages/dashboard/src/app/layout.tsx": "9fb4c297986494f088bb7f66bc3e784608b2146ca199ee511f940b2185d79ce1",
    "packages/core/src/db/seed.ts": "6da2dcdfbd5cfc910aafe1b4c93e352e1547a5a84a1a4e70d75d832f396400ca",
    "packages/core/src/db/schema.ts": "fb554c851257c5c11ca492ea8987954a4c7ddc8a270ae047ce3cee3a0ebb48ed",
    "packages/core/src/db/index.ts": "273dae88a32916d52abf20f2342d2a7eacd5125af9e8fc5cc9a3c025c6ac1a21",
    "packages/context-sync/src/generators/windsurf.ts": "cdf5647018be09af328e1084b617b3bcd5f30910fa0dd731807822de238ca5dd",
    "packages/context-sync/src/generators/kiro.ts": "92f40a22553de0dd206479391d0d23b1a269b58fbf2745bc6576585b3409c30c",
    "packages/context-sync/src/generators/custom.ts": "283502ad7ae2d415b9e362f42f0425abc49c5545977904d1596bccdbece1cefa",
    "packages/context-sync/src/generators/cursorrules.ts": "e111f6c41b4cae4759d66c22c9df8e2c9c967ecc445d1cf0e5cb2dbeab916559",
    "packages/context-sync/src/generators/copilot.ts": "f89b84ce6d1bc0510221ffcfe502d145bc2bb8851e4fe2c155256dcbd8e00464",
    "packages/context-sync/src/generators/claude-md.ts": "3789f791e1f4513e8ca027b1c7653666a83543b4126db834fabaa857ef058518",
    "packages/context-sync/src/generators/agents-md.ts": "6f3971f6e09ba20779786216a9b846316721e296cb5fb6ae2845fc1b609bcfd5",
    "packages/cli/src/commands/watch.ts": "f0aade12faecbfc2cd1e414e0a3baf12fb4b0391665a48150cef6dfdb859674c",
    "packages/cli/src/commands/velocity.ts": "ac8022d17c054de1b0ac37fc2b200e57dceaa19db69c0f60f4a8bf66cb136945",
    "packages/cli/src/commands/sync.ts": "35510d444cea04f33adb1f444276b4756d41e29a7fc846e04f243e372e8a2b94",
    "packages/cli/src/commands/summary.ts": "f517193a52d48305c40ee9964d9ec4bee658a8c0d1500480f5a6a79c3c65c621",
    "packages/cli/src/commands/server.ts": "ea9b4951a6a351a74742458f73684fac603f3640da736343d8896c390fa0ce52",
    "packages/cli/src/commands/serve.ts": "202698d51e8e951f4b7572a864f3865111712d2702cf92343cfb94d084a51cae",
    "packages/cli/src/commands/review.ts": "259c068e6bb0d062426ff0abc04324fdf61482b55beeab1e6dacdef41f5e9c15",
    "packages/cli/src/commands/login.ts": "d7dccb24dd57728e925022ecac54b243c0d771475b87207e37cbbc3d460b1051",
    "packages/cli/src/commands/init.ts": "f7605dd9e75d98a4057454a0bcaad3dcdd0b4a7034397a26dcf34dc8ff725779",
    "packages/cli/src/commands/decisions.ts": "24fe74e29e332af57a7f9109a067bc30bbf62ffaab3f524c02042d3215245661",
    "packages/cli/src/commands/costs.ts": "0c2c0fe2b6740c98eadfae785f5f9499ee72c0ef74ac1511efab9dcff776ed7b",
    "packages/cli/src/commands/analyze.ts": "5b2f0eb26e30c85243eaaf215c79a4cee20c436102872ff4055577ce3bd5d7f0",
    "packages/analyzer/src/reporters/markdown.ts": "cb1a277eecf4c4ebab745cd297c9a96fec1f8db0745193db580ad23aed418e24",
    "packages/analyzer/src/reporters/json.ts": "a1045391fce4f6f76f0a45c3c0c92b2ce8289ea48ac87ebf6a2fb094719b4f6d",
    "packages/dashboard/src/components/velocity/velocity-card.tsx": "d4627225fbac5f9b39aa96b99f5e3fbf19d70f27e2ff4fb33fdd6469006e2688",
    "packages/dashboard/src/components/velocity/dev-profile.tsx": "e4b13dd8f795137cbe340b499b7629b236564b0e0a24fe2dc74fa2c55b0de65e",
    "packages/dashboard/src/components/velocity/blocker-list.tsx": "a337da430641e8d236c156f2819bf1e697320b1779c8e9fc86c0845ea7769141",
    "packages/dashboard/src/components/summaries/summary-editor.tsx": "95edf2e876a36d8c488056d90052891ee3107eed969c48b45cbbde1c41350a77",
    "packages/dashboard/src/components/summaries/summary-card.tsx": "9b252fe6636350d7ba4be51760fc09d06bf05510855fdcfcba9dcf61f295ad23",
    "packages/dashboard/src/components/reviews/violation-list.tsx": "0053f3ca2f20714b0d92e492864cb86e35c06e0ee6e9854c7a50fe506665ddc9",
    "packages/dashboard/src/components/reviews/review-summary.tsx": "b5e356c6b63623dfdb20face0b5e5f1e7e8d8243fe16a9f7e7e4607b6f34f476",
    "packages/dashboard/src/components/reviews/diff-viewer.tsx": "6d8f27f116da46b14f4482ddbcee815e1855b465ef8003453a41385012420cf7",
    "packages/dashboard/src/components/layout/sidebar.tsx": "408a718d802167242f449bf2e2409a263298f56c3fc6fee7d801dd9fd40c3793",
    "packages/dashboard/src/components/layout/org-switcher.tsx": "ed83c053d72015150d25e8e945177cef0a541e5f6b7a2ded42c207643f2fa9c8",
    "packages/dashboard/src/components/layout/header.tsx": "37009a204a4ca6a9a74e35948950a479f9a40434115c4c264ae7d3acd552748c",
    "packages/dashboard/src/components/graphs/dependency-graph.tsx": "67969790dde4b3af808a6f811478ad3f7fd51a8a3a67ef270715b7fa880a37bb",
    "packages/dashboard/src/components/decisions/evidence-viewer.tsx": "106b749b6b5a60f54f3a6d3bb729e71446be23a75383fb3468944c2b781222c9",
    "packages/dashboard/src/components/decisions/decision-table.tsx": "36d9ebcdaf2af57229c5304761fa9409cec41f092f302cc9d7323a336716ac0c",
    "packages/dashboard/src/components/decisions/decision-editor.tsx": "a83d195b1107aeb0cefdd82c6a5a08a1f14ac238fd4d36f573959e36b94f73dd",
    "packages/dashboard/src/components/decisions/decision-card.tsx": "f373288d89f331165b2e61d4288bc53ac632576bae9ae4feba272a8c15b239a9",
    "packages/dashboard/src/components/charts/violation-breakdown.tsx": "8ea3a45fd2da042eeafd8b6fd743eccd6326a48742de98ed52425f40119d4209",
    "packages/dashboard/src/components/charts/velocity-chart.tsx": "e90b89318bbcfa42c651a1e80d56b2c6b0bac34c729ce1d0cf0855d8b5c2bc4a",
    "packages/dashboard/src/components/charts/drift-timeline.tsx": "b9aaf49ebe7c07fb9b0b5aa36e199a365ce9468acef8b45e49e4465c7b536e07",
    "packages/dashboard/src/components/charts/contribution-chart.tsx": "5a5bf9a36cc677e75d647618c8c5201e98bb9cb2c0706dfa23c6563d1fca1a2b",
    "packages/dashboard/src/components/charts/complexity-heatmap.tsx": "5243858425a59e28ff154a05efc7e7f61cfc953f619a869c1dfd2c87bd59aba9",
    "packages/dashboard/src/app/(app)/layout.tsx": "d386849899b3e27aa9749b17dfae9d2671c2564ac01cd663015a3b3f040a5513",
    "packages/dashboard/src/app/(auth)/sso/page.tsx": "3962751ad859018a1ad48e8120faae9b40ef1bb63470e36eb912f5cc3a9d0e84",
    "packages/dashboard/src/app/(auth)/signup/page.tsx": "f71031cb19548c0dce16c63567331992302505b7c7c4ce792b8171c794c20e85",
    "packages/dashboard/src/app/(auth)/login/page.tsx": "38669fdcf371a104ddb5ad89904ef8062b5e169c8c3b3dc1c9fbec9e052f5823",
    "packages/dashboard/src/app/(app)/team/page.tsx": "e85b637293040c7144723b41ec666e8481f0972a7f395cdb4f0ac0f91d664c75",
    "packages/dashboard/src/app/(app)/velocity/page.tsx": "c993ff2e2f011791f5aea9328f48519788285f2636c7bda7cb6d0edd2b98e039",
    "packages/dashboard/src/app/(app)/summaries/page.tsx": "46c59060ec63e856856065eb025ae5c35f2955006ea62bd35aee373c409ba411",
    "packages/dashboard/src/app/(app)/settings/page.tsx": "391048e44f547dc1ce6f4541277d8ecf1a48291d7755c8794aef094b61985203",
    "packages/dashboard/src/app/(app)/reviews/page.tsx": "b464686dba825c18517eb90a878b0ae6024d9bf098c94744e335a0610dadcfdb",
    "packages/dashboard/src/app/(app)/repos/page.tsx": "b271f39bb8ad729e61063840abfa4b84012757b5c1ccab362f54b10ac9e5b30a",
    "packages/dashboard/src/app/(app)/drift/page.tsx": "1f435c5a5bd138e1e5671fe904a9fd628aa10dc5d92f0e9978207de9fc0ec005",
    "packages/dashboard/src/app/(app)/dependencies/page.tsx": "f747dd8a118d1a293b1895f391749c2623e708e7018bebe3e99e858b6a708f25",
    "packages/dashboard/src/app/(app)/decisions/page.tsx": "eae8a6dee39e0868cd747c35f32c1927e9843054a0eabef5a93e020e6c3fa2d4",
    "packages/dashboard/src/app/(app)/dashboard/page.tsx": "e4d7a03775b17f2294c0fcefdb27121ae65d4f1534d620252bf42b57a9d7ae77",
    "packages/dashboard/src/app/(app)/team/invite/page.tsx": "8866dfa2b0ccc994d3476cdc18a07f8c2d6ceeec2126c5e986a712e1329d3f47",
    "packages/dashboard/src/app/(app)/velocity/[devId]/page.tsx": "070132ec7c41d394ec36635b92476266900f4bce2203f7e62e14be2bc798e8a8",
    "packages/dashboard/src/app/(app)/summaries/[id]/page.tsx": "2ff6017343f421ea0648435d26b49df7e239199462be64910831123bd6b24f08",
    "packages/dashboard/src/app/(app)/settings/sso/page.tsx": "582c424b1814d506fa904ced0a725c4ee41001e7c597defc69dfd0d438d4d02c",
    "packages/dashboard/src/app/(app)/settings/rules/page.tsx": "50f3dad1b58ba4b26e3e0efccf29e8e716aa56946552d29b0d18883b23ee2597",
    "packages/dashboard/src/app/(app)/settings/integrations/page.tsx": "a8584f73d28ea87a1aecc59e8b80824282ba55b0327bc5188f0034bebd80f324",
    "packages/dashboard/src/app/(app)/reviews/[id]/page.tsx": "a1ddbbc354f4f12da7416b73d4e4534f487a32ae74db6ed82ced8edde175bf93",
    "packages/dashboard/src/app/(app)/repos/[id]/page.tsx": "40d81a96938cac2c11a2bbea289ab5b8194a018406b8da1d022260b92b99b5f6",
    "packages/dashboard/src/app/(app)/decisions/[id]/page.tsx": "ebe90458f14720c540382874361acfcc7f894979238c96e534ce711e9b87e8c3"
  },
  "decisions": [
    {
      "id": "fmTnlKu7Zr8i3t0CwRKmF",
      "title": "Monorepo with Domain-Driven Package Decomposition",
      "description": "The codebase is organized as a monorepo under packages/ with 11 distinct packages, each representing a bounded domain: core (shared types/utils), analyzer (codebase analysis), reviewer (code review), velocity (team metrics), work-summary (developer summaries), integrations (GitHub/Bitbucket/Slack), context-sync (AI context file generation), mcp-server (Model Context Protocol), server (HTTP API), dashboard (web UI), and cli (command-line interface). Each package has its own src/ directory and index.ts barrel export.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The directory structure clearly shows 11 packages under packages/, each with a dedicated src/ and index.ts. The naming is domain-specific (not arbitrary), and each package re-exports its public API through index.ts barrel files. The import patterns show packages importing from @archguard/* namespaces, confirming this is a deliberate monorepo with scoped packages. The consistency across all 11 packages makes this unambiguously intentional.",
      "evidence": [
        {
          "filePath": "packages/core/src/index.ts",
          "lineRange": [
            1,
            106
          ],
          "snippet": "export { loadConfig, writeDefaultConfig, getDefaultConfig } from './config.js';\nexport { createSqliteClient, initializeDatabase, schema, ... } from './db/index.js';",
          "explanation": "Core package barrel export re-exports all shared functionality — types, DB, LLM, git, auth, utils"
        },
        {
          "filePath": "packages/integrations/src/index.ts",
          "lineRange": [
            1,
            135
          ],
          "snippet": "export { createGitHubApp, ... } from './github/app.js';\nexport { createBitbucketWebhookHandler, ... } from './bitbucket/webhook.js';\nexport { createSlackApp, ... } from './slack/app.js';",
          "explanation": "Integrations package barrel export aggregates GitHub, Bitbucket, and Slack sub-modules into a single public API"
        },
        {
          "filePath": "packages/velocity/src/index.ts",
          "lineRange": [
            1,
            80
          ],
          "snippet": "export { collectGitStats, ... } from './collectors/git-stats.js';\nexport { calculateEffortScores, ... } from './scoring/effort-model.js';\nexport { detectBlockers, ... } from './blockers/detector.js';",
          "explanation": "Velocity package barrel export shows internal sub-module organization (collectors, scoring, blockers) with clean public API"
        }
      ],
      "constraints": [
        "Each package must have an index.ts barrel export defining its public API",
        "Cross-package imports must use @archguard/* scoped package names, not relative paths",
        "New domain capabilities should be added as new packages, not bolted onto existing ones",
        "Shared types and utilities must live in @archguard/core"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "monorepo",
        "domain-driven",
        "package-decomposition",
        "barrel-exports"
      ]
    },
    {
      "id": "RurQef7M8MFvJQJQBGSUf",
      "title": "Shared Core Types Package as Single Source of Truth",
      "description": "All domain types (ArchDecision, Violation, ReviewResult, VelocityScore, TeamVelocity, WorkSummary, ArchGuardConfig, etc.) are defined in packages/core/src/types.ts (541 lines) and re-exported through @archguard/core. Every other package imports types from this central location rather than defining their own.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The types.ts file in core contains 541 lines of type definitions spanning every domain concept. Every package that uses these types imports from @archguard/core. The reviewer, velocity, integrations, analyzer, and work-summary packages all import types like ReviewResult, Violation, ArchDecision from @archguard/core. This is a deliberate centralization strategy to prevent type drift across packages.",
      "evidence": [
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            1,
            541
          ],
          "snippet": "export type ArchCategory = 'structural' | 'behavioral' | ...\nexport interface ArchDecision { ... }\nexport interface ReviewResult { ... }\nexport interface VelocityScore { ... }\nexport interface ArchGuardConfig { ... }",
          "explanation": "Single 541-line file defines ALL shared domain types for the entire platform"
        },
        {
          "filePath": "packages/reviewer/src/index.ts",
          "lineRange": [
            12,
            18
          ],
          "snippet": "import type {\n  ArchDecision,\n  ArchGuardConfig,\n  ReviewResult,\n  Violation,\n  ViolationSeverity,\n} from '@archguard/core';",
          "explanation": "Reviewer package imports all domain types from @archguard/core"
        },
        {
          "filePath": "packages/velocity/src/types.ts",
          "lineRange": [
            7,
            23
          ],
          "snippet": "export type {\n  VelocityScore,\n  VelocityPeriod,\n  ...\n} from '@archguard/core';\nexport type { DevGitStats, FileDiff, DiffHunk } from '@archguard/core';",
          "explanation": "Velocity package re-exports core types and only adds internal-only types"
        }
      ],
      "constraints": [
        "All shared domain types must be defined in packages/core/src/types.ts",
        "Packages must not redefine types that exist in core — they should import or re-export them",
        "Package-internal types can be defined locally but must not be exported as part of the public API if they duplicate core types"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "shared-types",
        "single-source-of-truth",
        "type-centralization"
      ]
    },
    {
      "id": "Sp2Ysv7X9fIKviY0nynVt",
      "title": "Functional Factory Pattern over Classes",
      "description": "The codebase consistently uses factory functions (createGitHubClient, createBitbucketClient, createSlackApp, createGitClient, createLlmClient, createMcpServer) that return configured instances, rather than class-based constructors. The pattern is: export a create* function that takes a config/options object and returns a configured client or app instance.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "Across all integration clients (GitHub, Bitbucket, Slack), core utilities (git, LLM), and server components (MCP), the pattern is consistently factory functions, not classes. The only classes in the codebase are error types (BitbucketApiError, LlmError), the SyncEngine, SummaryScheduler, and Logger — all of which are stateful by nature. The overwhelming majority of the codebase uses pure functions and factory patterns. This consistency across 11 packages indicates a deliberate architectural choice.",
      "evidence": [
        {
          "filePath": "packages/integrations/src/github/api.ts",
          "lineRange": [
            107,
            113
          ],
          "snippet": "export function createGitHubClient(options: GitHubClientOptions): Octokit {\n  return new Octokit({\n    auth: options.token,\n    ...(options.baseUrl ? { baseUrl: options.baseUrl } : {}),\n  });\n}",
          "explanation": "GitHub client uses factory function pattern, wrapping Octokit construction"
        },
        {
          "filePath": "packages/integrations/src/bitbucket/api.ts",
          "lineRange": [
            118,
            125
          ],
          "snippet": "export function createBitbucketClient(options: BitbucketClientOptions): BitbucketClient {\n  return {\n    token: options.token,\n    workspace: options.workspace,\n    baseUrl: options.baseUrl ?? BITBUCKET_CLOUD_BASE,\n  };\n}",
          "explanation": "Bitbucket client returns a plain object from factory function, not a class instance"
        },
        {
          "filePath": "packages/integrations/src/slack/app.ts",
          "lineRange": [
            87,
            100
          ],
          "snippet": "export function createSlackApp(\n  config: SlackAppConfig,\n  dataProvider: SlackCommandDataProvider,\n  eventHandlers: SlackAppEventHandlers = {}\n): App {",
          "explanation": "Slack app creation uses factory function that configures and returns a Bolt App"
        },
        {
          "filePath": "packages/integrations/src/bitbucket/webhook.ts",
          "lineRange": [
            133,
            145
          ],
          "snippet": "export function createBitbucketWebhookHandler(\n  config: BitbucketWebhookConfig,\n  handlers: BitbucketWebhookHandlers = {}\n): (eventType: string, payload: unknown) => Promise<WebhookHandlerResult> {",
          "explanation": "Webhook handler factory returns a closure function, not a class"
        }
      ],
      "constraints": [
        "New API clients and service wrappers should use factory functions, not classes",
        "Stateless modules should export pure functions, not class instances",
        "Configuration should be passed as typed options objects to factory functions"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "functional",
        "factory-pattern",
        "composition-over-inheritance"
      ]
    },
    {
      "id": "MKHTUR5LtqhIbwlxObl3M",
      "title": "LLM-First Architecture with Anthropic Claude as Primary Provider",
      "description": "The entire platform is built around LLM-powered analysis as a core capability, not an add-on. The Anthropic Claude API (via @anthropic-ai/sdk) is the sole LLM provider. The config supports per-operation model selection (analyze, review, mcp, summary, sync) with different Claude models for different tasks. Cost tracking, caching, and rate limiting are built into the LLM layer.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The core/src/llm.ts file (650 lines) is dedicated to Anthropic SDK integration with sophisticated cost tracking, caching, retry logic, and per-operation model selection. The ArchGuardConfig type has a detailed llm section with models.analyze, models.review, models.mcp, models.summary, models.sync. The analyzer's index.ts comment explicitly states 'Requires an Anthropic API key — the LLM IS the product.' There is no abstraction layer for multiple LLM providers — it's Anthropic-specific throughout.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/index.ts",
          "lineRange": [
            1,
            15
          ],
          "snippet": "/**\n * @archguard/analyzer - Architecture Agent: Codebase Analysis\n *\n * Requires an Anthropic API key — the LLM IS the product.\n */",
          "explanation": "Explicit comment declaring LLM is the core product, not optional"
        },
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            370,
            395
          ],
          "snippet": "llm: {\n    provider: string;\n    apiKeyEnv: string;\n    models: {\n      analyze: string;\n      review: string;\n      mcp: string;\n      summary: string;\n      sync: string;\n    };\n    maxTokensPerAnalysis: number;\n    cacheTtlHours: number;\n    maxRetries: number;\n    ...\n    maxCostPerRun: number;\n  };",
          "explanation": "Config type shows per-operation model selection and cost controls built into the type system"
        },
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "import Anthropic from '@anthropic-ai/sdk';",
          "explanation": "LLM module directly imports Anthropic SDK — no provider abstraction layer"
        }
      ],
      "constraints": [
        "All LLM calls must go through the core LLM module for cost tracking and caching",
        "Each operation type (analyze, review, summary, etc.) should use its configured model",
        "LLM cost limits must be enforced per-run via maxCostPerRun config",
        "Adding a second LLM provider would require significant refactoring of the LLM layer"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "llm-first",
        "anthropic",
        "claude",
        "cost-tracking",
        "per-operation-models"
      ]
    },
    {
      "id": "rOeZkvkNxq4dbieatcG__",
      "title": "Dual Review Pipeline: Deterministic Rules + LLM Analysis",
      "description": "The reviewer package implements a two-pass review system: first a deterministic rule engine (rule-engine.ts, 774 lines) checks for import violations, file placement, naming conventions, and custom rules; then an LLM reviewer (llm-reviewer.ts) performs deep contextual analysis. Results are merged and deduplicated, with rule-based violations preferred over LLM ones when they overlap.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The reviewChanges function in reviewer/src/index.ts explicitly orchestrates both passes in sequence: Step 2 runs checkRules(), Step 3 runs runLlmReview(), Step 4 deduplicates. The deduplication logic specifically handles the rule-based vs LLM distinction by checking if rule names start with 'llm:'. This is a deliberate hybrid approach combining deterministic guarantees with LLM flexibility.",
      "evidence": [
        {
          "filePath": "packages/reviewer/src/index.ts",
          "lineRange": [
            140,
            175
          ],
          "snippet": "// Step 2: Run rule-based checks\nconst ruleViolations = checkRules(diffAnalysis, ruleConfig);\n\n// Step 3: Run LLM review (always — API key is required)\nconst llmViolations = await runLlmReview(...);\n\n// Step 4: Combine and deduplicate violations\nconst allViolations = deduplicateViolations([...ruleViolations, ...llmViolations]);",
          "explanation": "Explicit two-pass pipeline: deterministic rules then LLM, with deduplication"
        },
        {
          "filePath": "packages/reviewer/src/index.ts",
          "lineRange": [
            218,
            245
          ],
          "snippet": "function deduplicateViolations(violations: Violation[]): Violation[] {\n  ...\n  const existingIsLlm = existing.rule.startsWith('llm:');\n  const currentIsLlm = v.rule.startsWith('llm:');\n  if (existingIsLlm && !currentIsLlm) {\n    // Keep the rule-based one, but merge suggestion if LLM has a better one\n    ...\n  }",
          "explanation": "Deduplication logic explicitly prefers deterministic rule violations over LLM ones, merging LLM suggestions"
        },
        {
          "filePath": "packages/reviewer/src/rule-engine.ts",
          "lineRange": [
            85,
            105
          ],
          "snippet": "export function checkRules(diffAnalysis: DiffAnalysis, config: RuleEngineConfig): Violation[] {\n  const violations: Violation[] = [];\n  const layerBoundaries = inferLayerBoundaries(config.decisions);\n  violations.push(...checkImportViolations(...));\n  violations.push(...checkFilePlacementViolations(...));\n  violations.push(...checkNamingConventionViolations(...));\n  violations.push(...checkCustomRuleViolations(...));\n  return violations;\n}",
          "explanation": "Rule engine runs four deterministic check categories: imports, placement, naming, custom rules"
        }
      ],
      "constraints": [
        "Rule-based violations take precedence over LLM violations when they overlap",
        "LLM review runs on every review (API key is required, not optional)",
        "Custom rules in .archguard.yml are enforced deterministically, not via LLM",
        "New deterministic checks should be added to the rule engine, not the LLM reviewer"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "hybrid-review",
        "deterministic-rules",
        "llm-review",
        "deduplication"
      ]
    },
    {
      "id": "6wPTuZmqmgSNLO1Z9ClSK",
      "title": "Hono-based HTTP Server with Middleware Chain",
      "description": "The server package uses Hono as the HTTP framework with a layered middleware chain: CORS → logger → auth → org-context → rate-limit → route handlers. Routes are organized as separate Hono routers mounted on the main app. The server uses @hono/node-server for Node.js deployment.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The server/src/index.ts imports from 'hono', 'hono/cors', 'hono/logger', and '@hono/node-server'. The hono-env.d.ts file extends Hono's ContextVariableMap with custom types (AuthUser, OrgContext). Routes are organized in separate files under routes/ and mounted as sub-routers. Middleware files (auth.ts, org-context.ts, rate-limit.ts, rbac.ts) follow Hono's middleware pattern.",
      "evidence": [
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "import { Hono } from 'hono';\nimport { cors } from 'hono/cors';\nimport { logger } from 'hono/logger';\nimport { serve } from '@hono/node-server';",
          "explanation": "Server uses Hono framework with standard middleware imports"
        },
        {
          "filePath": "packages/server/src/hono-env.d.ts",
          "lineRange": [
            1,
            17
          ],
          "snippet": "interface ContextVariableMap {\n  user: AuthUser;\n  orgContext: OrgContext;\n}",
          "explanation": "Hono context is extended with typed variables for auth user and org context"
        },
        {
          "filePath": "packages/server/src/middleware/rate-limit.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import type { Context, Next } from 'hono';",
          "explanation": "Rate limiting middleware follows Hono's middleware pattern"
        }
      ],
      "constraints": [
        "All HTTP routes must be defined as Hono routers and mounted on the main app",
        "Middleware must follow Hono's (c: Context, next: Next) pattern",
        "Auth context must be set via Hono's c.set('user', ...) pattern",
        "Route handlers access org context via c.get('orgContext')"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "hono",
        "middleware-chain",
        "http-server",
        "node-server"
      ]
    },
    {
      "id": "hltR3csrYeUohurG7B1ED",
      "title": "BullMQ Job Queue for Async Processing with Redis",
      "description": "Long-running operations (analysis, review, velocity calculation, summary generation, context sync) are processed asynchronously via BullMQ queues backed by Redis. Five named queues handle different job types with configurable concurrency, retry policies (exponential backoff, 3 attempts), and job lifecycle management.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The server/src/jobs/queue.ts file (276 lines) sets up a complete BullMQ infrastructure with 5 named queues, typed job data interfaces, convenience enqueue functions, worker registration, and graceful shutdown. Each job type has its own worker file (analyze.job.ts, review.job.ts, etc.). The queue configuration includes exponential backoff, job retention policies, and rate limiting. This is clearly a deliberate async processing architecture.",
      "evidence": [
        {
          "filePath": "packages/server/src/jobs/queue.ts",
          "lineRange": [
            37,
            48
          ],
          "snippet": "export const QUEUE_NAMES = {\n  ANALYSIS: 'archguard:analysis',\n  REVIEW: 'archguard:review',\n  VELOCITY: 'archguard:velocity',\n  SUMMARY: 'archguard:summary',\n  SYNC: 'archguard:sync',\n} as const;",
          "explanation": "Five named queues for different async job types"
        },
        {
          "filePath": "packages/server/src/jobs/queue.ts",
          "lineRange": [
            55,
            72
          ],
          "snippet": "const queue = new Queue(name, {\n  connection: getRedisConnection() as never,\n  defaultJobOptions: {\n    removeOnComplete: { age: 24 * 3600, count: 1000 },\n    removeOnFail: { age: 7 * 24 * 3600, count: 5000 },\n    attempts: 3,\n    backoff: { type: 'exponential', delay: 5000 },\n  },\n});",
          "explanation": "Queue configuration with retention policies, retry attempts, and exponential backoff"
        },
        {
          "filePath": "packages/server/src/jobs/queue.ts",
          "lineRange": [
            150,
            170
          ],
          "snippet": "export async function enqueueAnalysis(data: AnalysisJobData): Promise<string> {\n  const queue = getQueue(QUEUE_NAMES.ANALYSIS);\n  const job = await queue.add('analyze', data, { priority: 1 });\n  return job.id ?? '';\n}",
          "explanation": "Typed convenience functions for enqueueing jobs with priority levels"
        }
      ],
      "constraints": [
        "Long-running operations must be processed via BullMQ queues, not inline in HTTP handlers",
        "Each job type must have a typed data interface (AnalysisJobData, ReviewJobData, etc.)",
        "Redis must be available for the server to function (REDIS_URL env var)",
        "Workers must handle failures gracefully with the configured retry policy"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "bullmq",
        "redis",
        "async-processing",
        "job-queue",
        "retry-policy"
      ]
    },
    {
      "id": "2DKvHaOO3fWAYl8dJQqWs",
      "title": "Next.js App Router with Route Group Layout Pattern",
      "description": "The dashboard uses Next.js App Router with route groups: (auth) for login/signup/SSO pages and (app) for authenticated application pages. Each group has its own layout. The (app) layout includes sidebar and header components, while (auth) pages have their own split-panel branding layout.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The directory structure clearly shows (auth) and (app) route groups under src/app/. The (app)/layout.tsx imports Sidebar and Header components. Auth pages (login, signup, sso) have their own full-page layouts with branding panels. This is a deliberate use of Next.js route groups to separate authenticated and unauthenticated experiences.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/app/(app)/layout.tsx",
          "lineRange": [
            1,
            17
          ],
          "snippet": "import { Sidebar } from '@/components/layout/sidebar'; import { Header } from '@/components/layout/header'; ... function AppLayout({ children }) { ... }",
          "explanation": "App layout wraps all authenticated pages with sidebar and header"
        },
        {
          "filePath": "packages/dashboard/src/app/(auth)/login/page.tsx",
          "lineRange": [
            1,
            10
          ],
          "snippet": "'use client';\nimport Link from 'next/link';\nimport { useRouter } from 'next/navigation';",
          "explanation": "Auth pages are client components with their own full-page layout including branding panel"
        },
        {
          "filePath": "packages/dashboard/src/app/(auth)/signup/page.tsx",
          "lineRange": [
            44,
            50
          ],
          "snippet": "<div className=\"flex min-h-screen\">\n      {/* Left panel - branding */}\n      <div className=\"hidden lg:flex lg:w-1/2 flex-col justify-between bg-gradient-to-br from-brand-900",
          "explanation": "Signup page uses split-panel layout with branding - consistent auth page pattern"
        }
      ],
      "constraints": [
        "Authenticated pages must be placed under (app)/ route group",
        "Authentication pages must be placed under (auth)/ route group",
        "The (app) layout must include sidebar and header navigation",
        "All dashboard pages are client components ('use client')"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.600Z",
      "tags": [
        "nextjs",
        "app-router",
        "route-groups",
        "layout-pattern"
      ]
    },
    {
      "id": "FXl12oBnxYHpdiHvAGut9",
      "title": "RBAC with Role Hierarchy and Permission-Based Access Control",
      "description": "The server implements role-based access control with four roles (owner > admin > member > viewer) in a strict hierarchy. Permissions are mapped to roles, and middleware functions (requirePermission, requireRole, requireAnyPermission) enforce access at the route level. The auth system supports multiple providers (email, GitHub, Google, SAML SSO).",
      "category": "security",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The auth subsystem spans four files: roles.ts (role hierarchy and permissions), rbac.ts (middleware enforcement), index.ts (session management), and saml.ts (enterprise SSO). The Role type is defined in core/types.ts as 'owner' | 'admin' | 'member' | 'viewer'. The RBAC middleware checks permissions before route handlers execute. SAML SSO with JIT provisioning indicates enterprise-grade auth design.",
      "evidence": [
        {
          "filePath": "packages/server/src/auth/roles.ts",
          "lineRange": [
            1,
            55
          ],
          "snippet": "export const ROLE_HIERARCHY = { owner: 4, admin: 3, member: 2, viewer: 1 };\nexport const PERMISSIONS = { ... };\nexport function isRoleAtLeast(role: Role, minimumRole: Role): boolean { ... }",
          "explanation": "Role hierarchy with numeric levels and permission constants"
        },
        {
          "filePath": "packages/server/src/auth/rbac.ts",
          "lineRange": [
            1,
            30
          ],
          "snippet": "export function requirePermission(permission: string) {\n  return async (c: Context, next: Next) => { ... };\n}",
          "explanation": "RBAC middleware factory that creates Hono middleware for permission checks"
        },
        {
          "filePath": "packages/server/src/auth/saml.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "/**\n * SAML 2.0 SSO configuration and handlers for ArchGuard enterprise.\n * Supports: Okta, Azure AD, OneLogin, and other SAML 2.0 IdPs\n * - Just-in-time user provisioning\n * - Role mapping from SAML attributes\n */",
          "explanation": "Enterprise SAML SSO with JIT provisioning indicates deliberate enterprise auth design"
        },
        {
          "filePath": "packages/server/src/auth/index.ts",
          "lineRange": [
            7,
            12
          ],
          "snippet": "/** In-memory session store. Replace with Redis in production. */\nconst sessions = new Map<string, { userId: string; orgId: string; expiresAt: number }>();",
          "explanation": "Session management with explicit note about production Redis upgrade"
        }
      ],
      "constraints": [
        "All protected routes must use requirePermission or requireRole middleware",
        "Role hierarchy must be respected: owner > admin > member > viewer",
        "SAML SSO must support JIT user provisioning",
        "Session tokens must be validated on every request via auth middleware"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "rbac",
        "role-hierarchy",
        "permissions",
        "saml-sso",
        "multi-auth"
      ]
    },
    {
      "id": "5ZHvSqk0JU_orFiIz9rta",
      "title": "Multi-Platform Integration Pattern (GitHub, Bitbucket, Slack)",
      "description": "The integrations package provides parallel implementations for GitHub and Bitbucket (API clients, PR bots, webhook handlers) and Slack (app, commands, notifications, block builders). Each platform follows the same structural pattern: api.ts (low-level client), pr-bot.ts (PR review logic), and webhook/app.ts (event routing). The reviewer package has parallel formatters for each platform.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The integrations package has three sub-directories (github/, bitbucket/, slack/) with parallel file structures. GitHub has api.ts, app.ts, check-run.ts, pr-bot.ts; Bitbucket has api.ts, pr-bot.ts, webhook.ts. The reviewer package has formatters/github-pr.ts and formatters/bitbucket-pr.ts with nearly identical interfaces (both produce formatted output with comments and annotations). This symmetry is clearly intentional.",
      "evidence": [
        {
          "filePath": "packages/integrations/src/github/api.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * GitHub API client wrapper.\n * Provides typed functions for interacting with the GitHub REST API\n * via Octokit\n */",
          "explanation": "GitHub API client follows same pattern as Bitbucket API client"
        },
        {
          "filePath": "packages/integrations/src/bitbucket/api.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * Bitbucket REST API 2.0 client.\n * Provides typed functions for interacting with the Bitbucket Cloud API\n */",
          "explanation": "Bitbucket API client mirrors GitHub API client structure"
        },
        {
          "filePath": "packages/reviewer/src/formatters/github-pr.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * GitHub PR comment formatter for architectural review results.\n */",
          "explanation": "GitHub formatter parallels Bitbucket formatter with platform-specific output"
        },
        {
          "filePath": "packages/reviewer/src/formatters/bitbucket-pr.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * Bitbucket PR comment formatter for architectural review results.\n */",
          "explanation": "Bitbucket formatter parallels GitHub formatter"
        }
      ],
      "constraints": [
        "New git platform integrations should follow the api.ts + pr-bot.ts + webhook.ts pattern",
        "Each platform must have a corresponding formatter in the reviewer package",
        "Platform-specific types must be defined in the integration module, not in core",
        "PR bot logic should be platform-agnostic where possible, with platform-specific adapters"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "multi-platform",
        "github",
        "bitbucket",
        "slack",
        "parallel-implementations"
      ]
    },
    {
      "id": "z3LCt-bWsFi1vQJCYJbkj",
      "title": "SQLite with Drizzle ORM for Persistence",
      "description": "The application uses SQLite as its primary database via better-sqlite3, with Drizzle ORM for schema definition and query building. The schema is defined using Drizzle's sqliteTable API with 16 tables covering the full domain model.",
      "category": "data",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The schema.ts file uses drizzle-orm/sqlite-core exclusively. The db/index.ts creates a SQLite client via better-sqlite3. The server index.ts calls initializeDatabase() which returns a Drizzle client. All route handlers use Drizzle query builders (eq, and, desc, etc.). This is a deliberate choice for simplicity and local-first operation.",
      "evidence": [
        {
          "filePath": "packages/core/src/db/schema.ts",
          "lineRange": [
            1,
            12
          ],
          "snippet": "import { sqliteTable, text, integer, real } from 'drizzle-orm/sqlite-core';",
          "explanation": "Schema uses Drizzle's SQLite-specific table definitions"
        },
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            55,
            57
          ],
          "snippet": "const dbPath = process.env.DATABASE_PATH ?? undefined;\nconst db = initializeDatabase(dbPath);",
          "explanation": "Server initializes SQLite database at startup"
        },
        {
          "filePath": "packages/core/src/db/schema.ts",
          "lineRange": [
            14,
            236
          ],
          "snippet": "export const organizations = sqliteTable('organizations', {...});\nexport const users = sqliteTable('users', {...});\n...\nexport const samlConfigs = sqliteTable('saml_configs', {...});",
          "explanation": "16 tables defined covering the complete domain model"
        }
      ],
      "constraints": [
        "All database interactions must go through Drizzle ORM query builders",
        "Schema changes require updating the Drizzle schema definitions in core/db/schema.ts",
        "SQLite limitations apply: no concurrent writes, limited JSON support, no native array types (stored as JSON text)",
        "JSON fields (constraints, tags, blockers, settings) are stored as text and parsed at read time"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "sqlite",
        "drizzle-orm",
        "database",
        "local-first",
        "persistence"
      ]
    },
    {
      "id": "TKj7p3oLe6U87s1S3E_0B",
      "title": "Server-Sent Events for Real-Time Dashboard Updates",
      "description": "The server implements SSE (Server-Sent Events) for pushing real-time updates to the dashboard. The server has a dedicated SSE route (routes/sse.ts) with broadcastEvent and client management. The dashboard has both a useSSE hook and a useEventSource hook for consuming SSE streams.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The server/src/routes/sse.ts exports broadcastEvent and createSSERouter. The dashboard has hooks/use-sse.ts and lib/sse.ts for consuming SSE. The server's index.ts re-exports broadcastEvent, indicating it's used by job workers to push updates. This is a deliberate choice of SSE over WebSockets for unidirectional server-to-client updates.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/sse.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "export type SSEEventType = ...;\nexport function broadcastEvent(event: SSEEvent): void { ... }\nexport function getConnectedClientCount(): number { ... }\nexport function createSSERouter(): Hono { ... }",
          "explanation": "SSE route with broadcast capability and client tracking"
        },
        {
          "filePath": "packages/dashboard/src/hooks/use-sse.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "export interface SSEOptions { ... }\nexport interface SSEMessage { ... }\nexport type SSEStatus = ...;\nexport function useSSE(options: SSEOptions): { ... }",
          "explanation": "Dashboard SSE hook for consuming server events"
        },
        {
          "filePath": "packages/dashboard/src/lib/api.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "export function createSSEConnection(...): EventSource { ... }",
          "explanation": "API utility includes SSE connection factory"
        }
      ],
      "constraints": [
        "Real-time updates must use SSE, not WebSockets or polling",
        "SSE events must be broadcast through the broadcastEvent function",
        "Dashboard components should use the useSSE hook for consuming events",
        "SSE connections must be scoped to the authenticated user's organization"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "sse",
        "real-time",
        "server-sent-events",
        "push-updates"
      ]
    },
    {
      "id": "5kksbIdR0h13E2rqd0Prj",
      "title": "Multi-Format AI Context File Generation (Cursor, Claude, Copilot, Windsurf, Kiro, Agents)",
      "description": "The context-sync package generates AI assistant context files in 7 formats: .cursorrules, CLAUDE.md, AGENTS.md, .github/copilot-instructions.md, .windsurfrules, .kiro/steering.md, and custom templates. Each format has a dedicated generator that transforms architectural decisions into format-specific context. The sync engine supports file watching, user section preservation, and optional LLM-powered intelligent compression.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The context-sync/src/generators/ directory has 7 generator files, one per format. The SyncFormat type in core/types.ts enumerates all supported formats. The SyncEngine class orchestrates generation across formats with file watching via chokidar. The config has sync.formats, sync.useLlm, and sync.preserveUserSections options. This is a core differentiating feature of the product.",
      "evidence": [
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            310,
            320
          ],
          "snippet": "export type SyncFormat =\n  | 'cursorrules'\n  | 'claude'\n  | 'copilot'\n  | 'agents'\n  | 'windsurf'\n  | 'kiro'\n  | 'custom';",
          "explanation": "Seven supported sync formats defined as a union type"
        },
        {
          "filePath": "packages/context-sync/src/sync-engine.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "import { generateCursorRules } from './generators/cursorrules.js';\nimport { generateClaudeMd } from './generators/claude-md.js';\nimport { generateAgentsMd } from './generators/agents-md.js';\nimport { generateCopilotInstructions } from './generators/copilot.js';\nimport { generateWindsurfRules } from './generators/windsurf.js';\nimport { generateKiroSteering } from './generators/kiro.js';\nimport { generateCustom } from './generators/custom.js';",
          "explanation": "Sync engine imports all 7 generators for multi-format output"
        }
      ],
      "constraints": [
        "Each AI assistant format must have its own generator file in generators/",
        "Generators must accept ArchDecision[] and produce format-specific output",
        "User-edited sections in generated files must be preserved across regeneration",
        "New AI assistant formats should be added as new generators with a SyncFormat enum value"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "context-sync",
        "ai-assistants",
        "multi-format",
        "cursor",
        "claude",
        "copilot"
      ]
    },
    {
      "id": "B6iJnA5O4A61Knw9Cijdr",
      "title": "MCP (Model Context Protocol) Server for IDE Integration",
      "description": "The mcp-server package implements a Model Context Protocol server that exposes architectural decisions, patterns, and dependencies as resources and tools for AI coding assistants. It supports three transport modes: stdio, SSE, and streamable HTTP. Tools include get-decisions, check-pattern, suggest-approach, and get-dependencies.",
      "category": "api",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "The mcp-server/src/index.ts (565 lines) imports from @modelcontextprotocol/sdk and sets up a full MCP server with tools and resources. The tools/ directory has 4 tool implementations, and resources/ has 2 resource providers. The config supports mcp.transport as 'stdio' | 'sse'. This is a deliberate integration point for AI coding assistants to query architectural knowledge.",
      "evidence": [
        {
          "filePath": "packages/mcp-server/src/index.ts",
          "lineRange": [
            1,
            15
          ],
          "snippet": "import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';\nimport { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';\nimport { SSEServerTransport } from '@modelcontextprotocol/sdk/server/sse.js';",
          "explanation": "MCP server uses official SDK with multiple transport options"
        },
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            325,
            328
          ],
          "snippet": "export type McpTransport = 'stdio' | 'sse';",
          "explanation": "MCP transport configuration in the core config type"
        }
      ],
      "constraints": [
        "MCP tools must follow the MCP SDK's tool registration pattern",
        "MCP resources must provide read-only access to architectural data",
        "The MCP server must support both stdio and SSE transports",
        "Tool implementations should be in separate files under tools/"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "mcp",
        "model-context-protocol",
        "ide-integration",
        "ai-tools"
      ]
    },
    {
      "id": "tHMTZIEb4ug_ytWcgzgX-",
      "title": "Multi-Tenant Organization Model",
      "description": "The platform is designed as a multi-tenant SaaS with organizations as the primary tenant boundary. All data (repositories, decisions, velocity scores, summaries) is scoped to an organization. The server uses org-context middleware to inject the current organization into every request. Users can be members of organizations with different roles.",
      "category": "security",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "The database schema has orgId on repositories, developers, work summaries, and org members. The server has dedicated org-context middleware (middleware/org-context.ts) that resolves and injects OrgContext. The dashboard auth includes orgId and orgName in the session. Routes filter data by orgId. The Organization entity has a plan field ('free' | 'starter' | 'teams' | 'enterprise'), indicating SaaS tiering.",
      "evidence": [
        {
          "filePath": "packages/server/src/middleware/org-context.ts",
          "lineRange": [
            1,
            15
          ],
          "snippet": "export interface OrgContext { ... }\nexport function orgContextMiddleware() { ... }\nexport function getOrgContext(c: Context): OrgContext { ... }",
          "explanation": "Dedicated middleware for resolving and injecting organization context"
        },
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            262,
            275
          ],
          "snippet": "export interface Organization {\n  id: string;\n  name: string;\n  slug: string;\n  plan: 'free' | 'starter' | 'teams' | 'enterprise';\n  settings: Record<string, unknown>;\n  ...\n}",
          "explanation": "Organization entity with SaaS plan tiers"
        },
        {
          "filePath": "packages/dashboard/src/lib/auth.ts",
          "lineRange": [
            3,
            12
          ],
          "snippet": "export interface User {\n  id: string;\n  email: string;\n  name: string;\n  orgId: string;\n  orgName: string;\n  role: 'owner' | 'admin' | 'member' | 'viewer';\n}",
          "explanation": "Dashboard user type includes orgId and role, confirming multi-tenant model"
        }
      ],
      "constraints": [
        "All data queries must be scoped to the current organization's ID",
        "The org-context middleware must run before any data-accessing route handlers",
        "Cross-organization data access must be prevented at the middleware level",
        "Organization plan determines feature availability"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "multi-tenant",
        "organization-scoped",
        "saas",
        "tenant-isolation"
      ]
    },
    {
      "id": "1Cd98dciHswBp3yLvWpjM",
      "title": "Incremental Analysis with File-Level Caching",
      "description": "The analyzer implements incremental analysis by hashing all source files and comparing against a cached state. When only some files have changed, only those files are sent to the LLM for analysis, and results are merged with cached decisions. The cache stores file hashes, decisions, and a TTL. A --force flag bypasses the cache entirely.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The analyzer/src/cache.ts exports hashFiles, identifyChangedFiles, loadCache, saveCache, clearCache, and mergeDecisions. The analyzer/src/index.ts runAnalysis function has explicit cache-checking logic: full cache hit (no files changed), partial cache (incremental analysis of changed files), and force mode. The mergeDecisions function handles combining cached and new decisions while removing decisions for deleted files.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/index.ts",
          "lineRange": [
            115,
            155
          ],
          "snippet": "if (!force) {\n    const cache = loadCache(projectDir, config.llm.cacheTtlHours);\n    if (cache && cache.filesHash === filesHash) {\n      // Cache hit: no files changed at all\n      ...\n    } else if (cache) {\n      // Partial cache: some files changed, do incremental analysis\n      const changes = identifyChangedFiles(fileHashes, cache.fileHashes);\n      changedFiles = [...changes.added, ...changes.modified];\n      ...\n    }\n  }",
          "explanation": "Three-way cache logic: full hit, partial (incremental), and miss"
        },
        {
          "filePath": "packages/analyzer/src/cache.ts",
          "lineRange": [
            1,
            15
          ],
          "snippet": "export interface AnalysisCache {\n  filesHash: string;\n  fileHashes: Record<string, string>;\n  decisions: ArchDecision[];\n  ...\n}\nexport function hashFiles(...): { filesHash: string; fileHashes: Record<string, string> } { ... }",
          "explanation": "Cache structure stores per-file hashes for incremental change detection"
        }
      ],
      "constraints": [
        "LLM analysis should only run on changed files when a valid cache exists",
        "Cache TTL must be configurable via llm.cacheTtlHours config",
        "The --force flag must bypass all caching",
        "Deleted files must have their decisions removed during merge"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "incremental-analysis",
        "caching",
        "file-hashing",
        "cost-optimization"
      ]
    },
    {
      "id": "NK-iN0QcEfS1snsevELDV",
      "title": "Webhook-Driven PR Review Automation",
      "description": "Both GitHub and Bitbucket integrations implement webhook handlers that automatically trigger architectural reviews on pull request events (opened, updated/synchronize). The webhook flow: receive event → validate payload → fetch diff → run review → post inline comments + check run/build status + summary comment. Custom handlers can override the default behavior.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The GitHub app.ts registers handlers for pull_request.opened and pull_request.synchronize. The Bitbucket webhook.ts handles pullrequest:created and pullrequest:updated. Both route to their respective PR bot implementations. The server's webhooks route (routes/webhooks.ts) receives incoming webhooks and enqueues review jobs. The PR bots post inline comments, check runs, and summary comments.",
      "evidence": [
        {
          "filePath": "packages/integrations/src/github/app.ts",
          "lineRange": [
            95,
            115
          ],
          "snippet": "app.webhooks.on('pull_request.opened', async ({ octokit, payload }) => {\n    ...\n    if (handlers.onPullRequest) {\n      await handlers.onPullRequest(ctx);\n    } else {\n      await handlePREvent(ctx);\n    }\n  });",
          "explanation": "GitHub App registers PR opened webhook with default handler and custom override"
        },
        {
          "filePath": "packages/integrations/src/bitbucket/webhook.ts",
          "lineRange": [
            133,
            160
          ],
          "snippet": "export function createBitbucketWebhookHandler(\n  config: BitbucketWebhookConfig,\n  handlers: BitbucketWebhookHandlers = {}\n): (eventType: string, payload: unknown) => Promise<WebhookHandlerResult> {",
          "explanation": "Bitbucket webhook handler factory with customizable handlers"
        },
        {
          "filePath": "packages/integrations/src/github/pr-bot.ts",
          "lineRange": [
            100,
            140
          ],
          "snippet": "export async function handlePREvent(ctx: PREventContext, options: PRBotOptions = {}): Promise<PRBotResult> {\n  // Step 1: Fetch the diff\n  // Step 2: Run architectural review\n  // Step 3: Post inline review comments\n  // Step 4: Create check run\n  // Step 5: Post summary comment\n}",
          "explanation": "PR bot implements 5-step review pipeline: diff → review → comments → check → summary"
        }
      ],
      "constraints": [
        "Webhook handlers must validate payload structure before processing",
        "PR reviews must be enqueued as async jobs, not processed synchronously in webhook handlers",
        "Custom handlers must be supported via the handlers parameter pattern",
        "Error handling must post an error comment on the PR so authors are informed"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "webhooks",
        "pr-automation",
        "github-app",
        "bitbucket-webhooks"
      ]
    },
    {
      "id": "ka6LIwwaaP549e7Ym_8DE",
      "title": "CLI with Commander.js and Subcommand Pattern",
      "description": "The CLI uses Commander.js with 12 subcommands (init, analyze, decisions, sync, watch, serve, review, velocity, summary, login, server, costs), each registered in a separate file under commands/. Each command file exports a registerXCommand function that adds the command to the Commander program.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The cli/src/index.ts imports 12 registerXCommand functions and calls them to build the CLI. Each command file follows the same pattern: export a function that takes a Commander.Command and adds a subcommand with options and an action handler. The CLI also has a custom tapir-spinner.ts for branded loading animations.",
      "evidence": [
        {
          "filePath": "packages/cli/src/index.ts",
          "lineRange": [
            1,
            30
          ],
          "snippet": "import { registerInitCommand } from './commands/init.js';\nimport { registerAnalyzeCommand } from './commands/analyze.js';\nimport { registerDecisionsCommand } from './commands/decisions.js';\n...",
          "explanation": "CLI entry point imports and registers all 12 subcommands"
        },
        {
          "filePath": "packages/cli/src/commands/analyze.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import { Command } from 'commander';\nexport function registerAnalyzeCommand(program: Command): void { ... }",
          "explanation": "Each command follows the registerXCommand pattern"
        }
      ],
      "constraints": [
        "Each CLI command must be in its own file under commands/",
        "Command files must export a registerXCommand function",
        "Commands should use ora spinners for long-running operations",
        "Commands should use chalk for colored output"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "cli",
        "commander",
        "subcommands",
        "command-pattern"
      ]
    },
    {
      "id": "UVfCv4hDrB-WAPihcRfm4",
      "title": "Velocity Scoring with Multi-Dimensional Metrics",
      "description": "Developer velocity is calculated as a composite score from multiple dimensions: git statistics (commits, LOC), complexity-weighted effort, architectural impact (boundary crossings), PR metrics (cycle time, review throughput), refactoring ratio, and blocker detection. The scoring uses configurable weights from .archguard.yml and produces per-developer scores that aggregate into team velocity.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "The velocity package has a clear pipeline: collectors (git-stats, complexity, pr-metrics, issue-tracker) → scoring (effort-model, impact-score, velocity-calculator) → blockers (detector, alerts). The calculateVelocity orchestrator in index.ts runs all 9 steps. The config has velocity.complexityWeight, velocity.archImpactWeight, velocity.reviewWeight, velocity.refactoringWeight. This is a sophisticated, deliberate scoring system.",
      "evidence": [
        {
          "filePath": "packages/velocity/src/index.ts",
          "lineRange": [
            165,
            230
          ],
          "snippet": "// Step 1: Create git client and collect git stats\n// Step 2: Get diffs for complexity analysis\n// Step 3: Calculate refactoring ratios\n// Step 4: Aggregate PR metrics\n// Step 5: Calculate effort scores\n// Step 6: Calculate impact scores\n// Step 7: Detect blockers\n// Step 8: Calculate developer velocity scores\n// Step 9: Calculate team velocity",
          "explanation": "9-step velocity calculation pipeline with clear separation of concerns"
        },
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            380,
            395
          ],
          "snippet": "velocity: {\n    enabled: boolean;\n    calculationSchedule: string;\n    complexityWeight: number;\n    archImpactWeight: number;\n    reviewWeight: number;\n    refactoringWeight: number;\n    stalePrDays: number;\n    longBranchDays: number;\n  };",
          "explanation": "Configurable weights for velocity scoring dimensions"
        }
      ],
      "constraints": [
        "Velocity scores must be calculated from multiple dimensions, not just LOC",
        "Scoring weights must be configurable via .archguard.yml",
        "Blocker detection must run as part of velocity calculation",
        "Team velocity must aggregate individual developer scores"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "velocity-scoring",
        "multi-dimensional",
        "configurable-weights",
        "blocker-detection"
      ]
    },
    {
      "id": "I2dRtZZDen-XCvNfiIMXm",
      "title": "YAML-Based Configuration with Zod Validation",
      "description": "The platform uses .archguard.yml as its configuration file, parsed with js-yaml and validated with Zod schemas. The ArchGuardConfig type defines the full configuration structure with sensible defaults. The config covers analysis, LLM, sync, MCP, review, velocity, summaries, layers, Slack, and custom rules.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The core/src/config.ts imports js-yaml and zod, exports loadConfig and getDefaultConfig. The ArchGuardConfig type in types.ts is comprehensive (100+ lines) covering all platform features. The CLI init command generates a default .archguard.yml. Multiple packages call loadConfig to read configuration.",
      "evidence": [
        {
          "filePath": "packages/core/src/config.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import yaml from 'js-yaml';\nimport { z } from 'zod';\nimport type { ArchGuardConfig } from './types.js';",
          "explanation": "Config module uses js-yaml for parsing and Zod for validation"
        },
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            340,
            440
          ],
          "snippet": "export interface ArchGuardConfig {\n  version: number;\n  server?: { ... };\n  analysis: { ... };\n  llm: { ... };\n  sync: { ... };\n  mcp: { ... };\n  review: { ... };\n  velocity: { ... };\n  summaries: { ... };\n  layers: LayerDefinition[];\n  slack?: { ... };\n  rules: CustomRule[];\n}",
          "explanation": "Comprehensive config type covering all platform features"
        }
      ],
      "constraints": [
        "All configuration must be in .archguard.yml at the project root",
        "Config must be validated with Zod schemas on load",
        "Sensible defaults must be provided for all optional config values",
        "Config changes should not require code changes — behavior should be config-driven"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "yaml-config",
        "zod-validation",
        "configuration-driven"
      ]
    },
    {
      "id": "dQWI0tvUKT37Lt5jatIrK",
      "title": "Custom React Hooks for Data Fetching Pattern",
      "description": "The dashboard uses a consistent pattern of custom React hooks (useDecisions, useReviews, useTeamVelocity, useDeveloperVelocity, useSSE) that encapsulate API fetching, loading/error state management, and refetch capabilities. Each hook returns { data, loading, error, refetch? } and uses the centralized apiFetch utility.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "All four data hooks in dashboard/src/hooks/ follow the identical pattern: useState for data/loading/error, useCallback for fetch function, useEffect to trigger initial fetch, and return { data, loading, error, refetch }. They all use apiFetch from @/lib/api. This consistency across all hooks indicates a deliberate pattern, not coincidence.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/hooks/use-velocity.ts",
          "lineRange": [
            66,
            90
          ],
          "snippet": "export function useTeamVelocity() {\n  const [data, setData] = useState<TeamVelocityData | null>(null);\n  const [loading, setLoading] = useState(true);\n  const [error, setError] = useState<string | null>(null);\n  const fetchData = useCallback(async () => { ... }, []);\n  useEffect(() => { fetchData(); }, [fetchData]);\n  return { data, loading, error, refetch: fetchData };\n}",
          "explanation": "Velocity hook follows the standard data fetching pattern"
        },
        {
          "filePath": "packages/dashboard/src/hooks/use-reviews.ts",
          "lineRange": [
            55,
            80
          ],
          "snippet": "export function useReviews(filters?: ReviewFilters) {\n  const [reviews, setReviews] = useState<ReviewSummaryData[]>([]);\n  const [loading, setLoading] = useState(true);\n  const [error, setError] = useState<string | null>(null);\n  ...\n  return { reviews, loading, error, refetch: fetchReviews };\n}",
          "explanation": "Reviews hook follows the same pattern with filter support"
        }
      ],
      "constraints": [
        "Data fetching hooks must return { data, loading, error } at minimum",
        "All API calls must go through the apiFetch utility",
        "Hooks must handle loading and error states consistently",
        "List hooks should support refetch capability"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "react-hooks",
        "data-fetching",
        "consistent-pattern",
        "loading-state"
      ]
    },
    {
      "id": "wCn3yOzxqfzH1c-AxGvkv",
      "title": "Webhook Signature Verification for Security",
      "description": "Both GitHub and Bitbucket webhook integrations implement cryptographic signature verification. GitHub uses the standard webhook secret verification via @octokit/app. Bitbucket implements HMAC-SHA256 signature verification with constant-time comparison to prevent timing attacks.",
      "category": "security",
      "status": "detected",
      "confidence": 0.92,
      "reasoning": "The Bitbucket webhook.ts has an explicit verifyWebhookSignature function using crypto.createHmac('sha256', secret) with crypto.timingSafeEqual for constant-time comparison. The GitHub app.ts passes webhookSecret to the App constructor. The server's webhooks route validates signatures before processing. This is a deliberate security measure.",
      "evidence": [
        {
          "filePath": "packages/integrations/src/bitbucket/webhook.ts",
          "lineRange": [
            195,
            230
          ],
          "snippet": "export function verifyWebhookSignature(\n  secret: string,\n  signature: string | undefined,\n  body: string\n): boolean {\n  ...\n  const expectedSignature = crypto\n    .createHmac('sha256', secret)\n    .update(body, 'utf-8')\n    .digest('hex');\n  return crypto.timingSafeEqual(sigBuffer, expectedBuffer);\n}",
          "explanation": "HMAC-SHA256 verification with constant-time comparison prevents timing attacks"
        },
        {
          "filePath": "packages/integrations/src/github/app.ts",
          "lineRange": [
            88,
            95
          ],
          "snippet": "const app = new App({\n    appId: config.appId,\n    privateKey: config.privateKey,\n    webhooks: {\n      secret: config.webhookSecret,\n    },\n  });",
          "explanation": "GitHub App configured with webhook secret for automatic signature verification"
        }
      ],
      "constraints": [
        "All webhook endpoints must verify request signatures before processing",
        "Signature comparison must use constant-time algorithms to prevent timing attacks",
        "Webhook secrets must be stored securely (environment variables, not code)"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "webhook-security",
        "hmac",
        "signature-verification",
        "timing-safe"
      ]
    },
    {
      "id": "P8pvJs05RfUuFa4jOfzzN",
      "title": "Architectural Layer Violation Detection from Decisions",
      "description": "The rule engine infers layer boundaries from architectural decisions (not just static config) and checks import statements against those boundaries. It uses well-known layer patterns (domain, application, infrastructure, presentation, shared) with default restriction rules, and can also parse explicit constraints from decision text. The analyzer has a separate layer-detector that works with the dependency graph.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The rule-engine.ts has 200+ lines dedicated to layer boundary inference (inferLayerBoundaries, buildDefaultLayerBoundaries, inferFromDecisionMetadata) and import violation checking. It defines WELL_KNOWN_LAYERS and DEFAULT_LAYER_RESTRICTIONS. The analyzer has layer-detector.ts that works with LayerDefinition[] from config. This dual approach (config-based + decision-inferred) is deliberate.",
      "evidence": [
        {
          "filePath": "packages/reviewer/src/rule-engine.ts",
          "lineRange": [
            30,
            50
          ],
          "snippet": "const WELL_KNOWN_LAYERS: Record<string, string[]> = {\n  domain: ['domain', 'entities', 'models', 'core/domain', 'core/entities'],\n  application: ['application', 'use-cases', 'usecases', 'services', 'app'],\n  infrastructure: ['infrastructure', 'infra', 'adapters', 'persistence', 'repositories/impl'],\n  presentation: ['presentation', 'controllers', 'routes', 'handlers', 'api', 'web', 'ui'],\n  shared: ['shared', 'common', 'utils', 'lib', 'helpers'],\n};",
          "explanation": "Well-known layer patterns for automatic layer detection"
        },
        {
          "filePath": "packages/reviewer/src/rule-engine.ts",
          "lineRange": [
            530,
            570
          ],
          "snippet": "function inferLayerBoundaries(decisions: ArchDecision[]): LayerBoundary[] {\n  const archDecisions = decisions.filter(d =>\n    d.title.toLowerCase().includes('layer') ||\n    d.title.toLowerCase().includes('hexagonal') ||\n    d.title.toLowerCase().includes('clean') ||\n    ...\n  );",
          "explanation": "Layer boundaries are inferred from architectural decision titles, descriptions, and tags"
        }
      ],
      "constraints": [
        "Layer violations must be detected from both config-defined layers and decision-inferred layers",
        "Import violations must reference the specific decision that established the boundary",
        "Well-known layer patterns should be used as defaults when no explicit decisions exist"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "layer-violations",
        "import-checking",
        "decision-inference",
        "clean-architecture"
      ]
    },
    {
      "id": "krtQC89nODDlPwqzLt2uU",
      "title": "JSON Output with Schema Versioning for CI Integration",
      "description": "The reviewer's JSON formatter includes a 'version' field (currently '1.0.0') in the output schema for forward compatibility. The JSON output is structured with metadata, summary, violations, fileResults, and ruleResults — designed for machine consumption by CI pipelines and dashboards.",
      "category": "api",
      "status": "detected",
      "confidence": 0.9,
      "reasoning": "The JsonReviewOutput interface explicitly includes a version field with the comment 'Schema version for forward compatibility'. The output structure is designed for programmatic consumption with grouped results by file and by rule. This versioning indicates planning for future schema evolution.",
      "evidence": [
        {
          "filePath": "packages/reviewer/src/formatters/json.ts",
          "lineRange": [
            18,
            45
          ],
          "snippet": "export interface JsonReviewOutput {\n  /** Schema version for forward compatibility */\n  version: string;\n  metadata: { ... };\n  summary: { ... };\n  violations: JsonViolation[];\n  fileResults: JsonFileResult[];\n  ruleResults: JsonRuleResult[];\n}",
          "explanation": "JSON output schema with explicit version field for forward compatibility"
        },
        {
          "filePath": "packages/reviewer/src/formatters/json.ts",
          "lineRange": [
            95,
            100
          ],
          "snippet": "return {\n    version: '1.0.0',\n    metadata: { ... },\n    ...\n  };",
          "explanation": "Version set to 1.0.0, indicating initial schema version"
        }
      ],
      "constraints": [
        "JSON output must include a version field for schema evolution",
        "Breaking changes to the JSON schema must increment the version",
        "Output must be structured for machine parsing, not human reading"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "json-output",
        "schema-versioning",
        "ci-integration",
        "machine-readable"
      ]
    },
    {
      "id": "4Q--9XxeC4tMapVkUa6sn",
      "title": "In-Memory Session Store with Production Redis Upgrade Path",
      "description": "The server's auth module uses an in-memory Map for session storage, with an explicit comment indicating this should be replaced with Redis in production. This is a deliberate development-first approach that acknowledges the production requirement.",
      "category": "deployment",
      "status": "detected",
      "confidence": 0.88,
      "reasoning": "The auth/index.ts has a clear comment '/** In-memory session store. Replace with Redis in production. */' above the sessions Map. This is a conscious trade-off for development simplicity with a documented upgrade path. The BullMQ queue already uses Redis, so the infrastructure is available.",
      "evidence": [
        {
          "filePath": "packages/server/src/auth/index.ts",
          "lineRange": [
            7,
            12
          ],
          "snippet": "/** In-memory session store. Replace with Redis in production. */\nconst sessions = new Map<string, { userId: string; orgId: string; expiresAt: number }>();",
          "explanation": "Explicit comment documenting the production upgrade path"
        }
      ],
      "constraints": [
        "Session store must be replaced with Redis for production deployment",
        "Session interface must remain the same regardless of backing store",
        "Session TTL must be enforced (currently 24 hours)"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "session-management",
        "in-memory",
        "development-first",
        "redis-upgrade"
      ]
    },
    {
      "id": "K1DvQ7cM1BexCUCKxXMKu",
      "title": "Rate Limiting Middleware with Tiered Limits",
      "description": "The server implements rate limiting middleware with three tiers: standardLimit (general API), strictLimit (auth endpoints), and analysisLimit (expensive operations). Rate limiting uses in-memory tracking with configurable windows and max requests.",
      "category": "security",
      "status": "detected",
      "confidence": 0.91,
      "reasoning": "The middleware/rate-limit.ts exports rateLimit factory plus three pre-configured tiers (standardLimit, strictLimit, analysisLimit). The rate limiter sets standard HTTP headers (X-RateLimit-*). Multiple routes in the server apply different rate limit tiers based on endpoint sensitivity.",
      "evidence": [
        {
          "filePath": "packages/server/src/middleware/rate-limit.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "export function rateLimit(options: RateLimitOptions) { ... }\nexport const standardLimit = rateLimit({ ... });\nexport const strictLimit = rateLimit({ ... });\nexport const analysisLimit = rateLimit({ ... });",
          "explanation": "Three rate limit tiers for different endpoint categories"
        }
      ],
      "constraints": [
        "Auth endpoints must use strictLimit",
        "Analysis/review endpoints must use analysisLimit",
        "Rate limit headers must be set on all responses",
        "Rate limiting should be upgraded to Redis-backed for multi-instance deployment"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "rate-limiting",
        "tiered-limits",
        "security",
        "middleware"
      ]
    },
    {
      "id": "D9VOoc3VUsszTkdc2iGIy",
      "title": "Dependency Graph with Robert C. Martin Coupling Metrics",
      "description": "The analyzer builds a full dependency graph from import analysis and calculates Robert C. Martin's coupling metrics: afferent coupling (Ca), efferent coupling (Ce), instability (I = Ce/(Ca+Ce)), abstractness (A), and distance from main sequence (D = |A+I-1|). It also detects circular dependencies via DFS.",
      "category": "data",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The CouplingMetrics interface in core/types.ts explicitly defines afferent/efferent coupling, instability, abstractness, and distance from main sequence with JSDoc comments explaining each metric. The dependency-mapper.ts (733 lines) implements these calculations along with circular dependency detection. This is a deliberate adoption of established software engineering metrics.",
      "evidence": [
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            130,
            150
          ],
          "snippet": "export interface CouplingMetrics {\n  /** Afferent coupling: number of modules that depend on this module */\n  afferentCoupling: number;\n  /** Efferent coupling: number of modules this module depends on */\n  efferentCoupling: number;\n  /** Instability: Ce / (Ca + Ce). 0 = maximally stable, 1 = maximally unstable */\n  instability: number;\n  /** Abstractness: ratio of abstract types to total types (0-1) */\n  abstractness: number;\n  /** Distance from main sequence: |A + I - 1|. 0 = ideal balance */\n  distanceFromMainSequence: number;\n}",
          "explanation": "Full Robert C. Martin coupling metrics with detailed JSDoc"
        },
        {
          "filePath": "packages/analyzer/src/dependency-mapper.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "export interface DependencyGraph { ... }\nexport function buildDependencyGraph(...): DependencyGraph { ... }",
          "explanation": "733-line dependency mapper with coupling metrics calculation"
        }
      ],
      "constraints": [
        "Dependency analysis must calculate all five Martin metrics",
        "Circular dependencies must be detected and reported",
        "Import resolution must support TypeScript path aliases and workspace packages",
        "The dependency graph must be serializable for storage and reporting"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "coupling-metrics",
        "martin-metrics",
        "dependency-graph",
        "circular-dependencies"
      ]
    },
    {
      "id": "xNJ3V6KUgvjw7PrViEOLi",
      "title": "Work Summary Templates with LLM-Powered Generation",
      "description": "The work-summary package supports four summary types (standup, one-on-one, sprint review, progress report), each with a dedicated template that builds structured prompts for LLM generation. Data is collected from git history, PR metrics, and velocity scores, then formatted into XML-structured prompts for the LLM to generate human-readable summaries.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The work-summary/src/templates/ directory has four template files. The summarizer.ts builds XML-structured prompts from collected data. The collector.ts gathers commits, PRs, velocity, and module activity. The scheduler.ts uses cron for automated summary generation. The config has summaries.schedules with cron expressions and Slack channels.",
      "evidence": [
        {
          "filePath": "packages/work-summary/src/collector.ts",
          "lineRange": [
            80,
            100
          ],
          "snippet": "export interface CollectedData {\n  developer: string;\n  periodStart: string;\n  periodEnd: string;\n  commits: CommitInfo[];\n  pullRequests: PullRequestInfo[];\n  velocity: PeriodVelocity;\n  filesChanged: string[];\n  modules: ModuleActivity[];\n  gitStats: DevGitStats | null;\n  dataPoints: SummaryDataPoints;\n}",
          "explanation": "Comprehensive data collection for summary generation"
        },
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            240,
            250
          ],
          "snippet": "export type SummaryType = 'one_on_one' | 'standup' | 'sprint_review' | 'progress_report';",
          "explanation": "Four supported summary types"
        }
      ],
      "constraints": [
        "Each summary type must have a dedicated template file",
        "Templates must produce structured prompts suitable for LLM consumption",
        "Data collection must be separate from summary generation",
        "Summaries must support both manual and scheduled generation"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:25.690Z",
      "tags": [
        "work-summaries",
        "llm-generation",
        "templates",
        "scheduled-generation"
      ]
    },
    {
      "id": "SlROoa7oJJKG31Z9qNJbj",
      "title": "Monorepo with Domain-Oriented Package Architecture",
      "description": "The codebase is organized as a monorepo with 11 distinct packages under packages/, each representing a bounded domain: core (shared types/utilities), analyzer (codebase scanning), reviewer (code review), velocity (developer metrics), work-summary (summaries), context-sync (AI context file generation), integrations (GitHub/Bitbucket/Slack), mcp-server (MCP protocol), server (HTTP API), dashboard (web UI), and cli (command-line interface). Each package has its own src/ directory and exports via an index.ts barrel file.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The directory structure is extremely deliberate — 11 packages with clear domain boundaries, each with consistent internal structure (src/, index.ts barrel). Cross-package imports use the @archguard/ scope prefix (e.g., @archguard/core, @archguard/analyzer), confirming this is a pnpm workspace monorepo. The dependency-mapper.ts even has explicit pnpm-workspace.yaml resolution logic. This level of organization cannot be accidental.",
      "evidence": [
        {
          "filePath": "packages/core/src/index.ts",
          "lineRange": [
            1,
            106
          ],
          "snippet": "export { loadConfig, writeDefaultConfig, getDefaultConfig } ... export { createGitClient, getDiff ... } ... export { generateId, now, hash ... }",
          "explanation": "Core package barrel file re-exports all shared utilities, types, LLM client, git helpers, auth, and database — serving as the foundation all other packages depend on"
        },
        {
          "filePath": "packages/analyzer/src/dependency-mapper.ts",
          "lineRange": [
            93,
            140
          ],
          "snippet": "function loadWorkspacePackages(projectDir: string, files: ParsedFile[]): Map<string, string> { ... const workspacePath = path.join(projectDir, 'pnpm-workspace.yaml'); ... }",
          "explanation": "Explicit pnpm workspace resolution logic confirms the monorepo tooling choice"
        },
        {
          "filePath": "packages/integrations/src/index.ts",
          "lineRange": [
            1,
            135
          ],
          "snippet": "export { createGitHubApp ... handlePREvent ... createBitbucketWebhookHandler ... createSlackApp ... }",
          "explanation": "Integrations package consolidates all third-party platform integrations (GitHub, Bitbucket, Slack) into a single package with sub-modules"
        }
      ],
      "constraints": [
        "All shared types and utilities must live in @archguard/core",
        "Cross-package dependencies must use the @archguard/ scoped package name, not relative paths",
        "Each package must export its public API through an index.ts barrel file",
        "New domain capabilities should be added as new packages, not bolted onto existing ones"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "monorepo",
        "pnpm-workspace",
        "domain-driven",
        "package-architecture"
      ]
    },
    {
      "id": "SXfBm162otEFf82vbpXui",
      "title": "Anthropic Claude as Exclusive LLM Provider with Operation-Based Model Selection",
      "description": "The system exclusively uses Anthropic's Claude models for all LLM operations, with different models selected per operation type: Opus for analysis (highest quality), Sonnet for review/MCP/summary (cost-efficient). The LLM client includes production-grade features: exponential backoff retry, cost tracking per call, in-memory response caching with TTL, Zod schema validation of responses, context window overflow prevention, and structured error types.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.98,
      "reasoning": "The entire LLM abstraction in core/src/llm.ts is built exclusively around the @anthropic-ai/sdk. There's no abstraction layer for swapping providers — the pricing table, API key validation (sk-ant- prefix), model names (claude-opus-4-6, claude-sonnet-4-6), and SDK types are all Anthropic-specific. The operation-based model routing (analyze→Opus, review→Sonnet) is explicitly configured. This is a very deliberate vendor commitment.",
      "evidence": [
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            1,
            30
          ],
          "snippet": "import Anthropic from '@anthropic-ai/sdk'; ... /** Per-operation model selection (analyze=Opus, review/mcp/summary=Sonnet) */",
          "explanation": "Direct Anthropic SDK import with documented per-operation model strategy"
        },
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            95,
            105
          ],
          "snippet": "const MODEL_PRICING: Record<string, { input: number; output: number }> = { 'claude-opus-4-6': { input: 15.0, output: 75.0 }, 'claude-sonnet-4-6': { input: 3.0, output: 15.0 }, ... }",
          "explanation": "Hardcoded Anthropic model pricing confirms vendor lock-in and cost-awareness"
        },
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            168,
            185
          ],
          "snippet": "export function requireApiKey(config: ArchGuardConfig): string { ... if (!apiKey.startsWith('sk-ant-')) { throw new LlmError('Invalid API key format...') } ... }",
          "explanation": "API key validation is Anthropic-specific (sk-ant- prefix), confirming single-vendor design"
        },
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            130,
            145
          ],
          "snippet": "export type LlmOperation = 'analyze' | 'review' | 'mcp' | 'summary' | 'sync'; ... export function getModelForOperation(config: ArchGuardConfig, operation: LlmOperation): string { return config.llm.models[operation]; }",
          "explanation": "Five distinct operation types each map to a configured model, enabling cost optimization"
        }
      ],
      "constraints": [
        "All LLM calls must go through analyzeWithLlm or analyzeWithLlmValidated — no direct SDK usage",
        "New LLM operations must be added to the LlmOperation type and configured in the model mapping",
        "Cost tracking is mandatory — every call updates the run cost accumulator",
        "Switching LLM providers would require rewriting the entire llm.ts module"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "anthropic",
        "claude",
        "llm",
        "vendor-lock-in",
        "cost-tracking",
        "retry-logic"
      ]
    },
    {
      "id": "x25uutnBa1TAuKbnSPjvG",
      "title": "Zod Schema Validation for LLM Response Contracts",
      "description": "All LLM responses are validated against Zod schemas before being used. The analyzeWithLlmValidated function wraps the raw LLM call with JSON extraction, Zod parsing, and automatic retry with refined prompts on validation failure (up to 2 retries). This pattern is used consistently across decision extraction, code review, and compliance checking.",
      "category": "api",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The pattern is deeply embedded in the core LLM module and used by every consumer. The decision-extractor.ts defines a full Zod schema (decisionsResponseSchema) for the decision extraction response. The llm-reviewer.ts defines violationSchema for review responses. The check-pattern.ts tool also uses Zod. The retry-with-refined-prompt mechanism in analyzeWithLlmValidated shows this is a deliberate reliability strategy, not just type checking.",
      "evidence": [
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            290,
            340
          ],
          "snippet": "export async function analyzeWithLlmValidated<T>(client, config, options, schema: ZodSchema<T>, operation): Promise<T> { ... const raw = await analyzeWithLlm(...); const jsonStr = extractJson(raw); ... const result = schema.parse(parsed); ... }",
          "explanation": "Generic validated LLM call with Zod schema, JSON extraction, and retry logic"
        },
        {
          "filePath": "packages/analyzer/src/decision-extractor.ts",
          "lineRange": [
            30,
            60
          ],
          "snippet": "const decisionSchema = z.object({ title: z.string().min(1), description: z.string().min(10), category: z.enum([...]), confidence: z.number().min(0).max(1), ... }); const decisionsResponseSchema = z.object({ decisions: z.array(decisionSchema) });",
          "explanation": "Full Zod schema for architectural decision extraction — enforces structure on LLM output"
        },
        {
          "filePath": "packages/reviewer/src/llm-reviewer.ts",
          "lineRange": [
            35,
            50
          ],
          "snippet": "const violationSchema = z.object({ rule: z.string(), severity: z.enum(['error', 'warning', 'info']), message: z.string(), ... }); const llmResponseSchema = z.array(violationSchema);",
          "explanation": "Zod schema for review violations — same pattern as decision extraction"
        }
      ],
      "constraints": [
        "All LLM responses that produce structured data must use analyzeWithLlmValidated with a Zod schema",
        "Zod schemas must define minimum lengths and enums to catch malformed LLM output",
        "JSON extraction must handle markdown code fences and truncated responses",
        "Validation failures trigger automatic retry with refined prompts before throwing"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "zod",
        "schema-validation",
        "llm-reliability",
        "type-safety",
        "json-extraction"
      ]
    },
    {
      "id": "VSQRcigWnJrg5D_WAN4jM",
      "title": "Hono as HTTP Framework for Server Package",
      "description": "The server package uses Hono as its HTTP framework, with a middleware chain pattern (auth, org-context, rate-limit, RBAC) and resource-based route organization. Routes are organized by domain resource (decisions, analysis, reviews, velocity, summaries, teams, repos, settings, sync, webhooks, SSE) each in their own file.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The server/src/index.ts imports from 'hono' and 'hono/cors', 'hono/logger'. All route files import { Hono } from 'hono'. The middleware files use Hono's Context and Next types. The SSE route uses hono/streaming. The hono-env.d.ts file extends Hono's ContextVariableMap for type-safe context variables. This is a comprehensive, intentional framework choice.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/sse.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import { Hono } from 'hono'; import { streamSSE } from 'hono/streaming'; import type { AuthUser } from '../auth/rbac.js';",
          "explanation": "SSE route using Hono's streaming capabilities"
        },
        {
          "filePath": "packages/server/src/middleware/rate-limit.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "import type { Context, Next } from 'hono';",
          "explanation": "Middleware uses Hono's native types"
        },
        {
          "filePath": "packages/server/src/hono-env.d.ts",
          "lineRange": [
            1,
            17
          ],
          "snippet": "interface ContextVariableMap { ... }",
          "explanation": "Type augmentation for Hono's context variables — deep framework integration"
        }
      ],
      "constraints": [
        "All HTTP routes must be created as Hono router instances",
        "Middleware must follow Hono's (Context, Next) => Promise<void> signature",
        "Context variables (user, orgId) must be typed via hono-env.d.ts",
        "Route files should export a factory function (createXRouter) that returns a Hono instance"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "hono",
        "http-framework",
        "middleware",
        "routing"
      ]
    },
    {
      "id": "vkS1GuusNtgEAkCsQgb4c",
      "title": "Role-Based Access Control (RBAC) with Four-Tier Role Hierarchy",
      "description": "The system implements RBAC with four roles (viewer, member, admin, owner) in a strict hierarchy. Permissions are grouped by resource (decisions, analysis, reviews, velocity, summaries, team, repos, settings, webhooks, integrations). Middleware functions (requirePermission, requireRole, requireAnyPermission) enforce access control on routes. The auth system supports multiple providers (email, OAuth, SAML/SSO).",
      "category": "security",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The roles.ts file explicitly defines ROLE_HIERARCHY, PERMISSIONS by resource, and ROLE_DESCRIPTIONS. The rbac.ts middleware provides three enforcement functions. The auth/index.ts handles session management. The saml.ts implements full SAML SSO. The core/src/auth.ts defines ROLE_PERMISSIONS mapping. This is a comprehensive, multi-layered auth system that was clearly designed upfront.",
      "evidence": [
        {
          "filePath": "packages/server/src/auth/roles.ts",
          "lineRange": [
            1,
            55
          ],
          "snippet": "export const PERMISSIONS = { decisions: ['decisions:read', 'decisions:write', ...], analysis: ['analysis:trigger', 'analysis:read'], ... }; export const ROLE_HIERARCHY: Role[] = ['viewer', 'member', 'admin', 'owner'];",
          "explanation": "Explicit role hierarchy and resource-based permission definitions"
        },
        {
          "filePath": "packages/server/src/auth/rbac.ts",
          "lineRange": [
            1,
            12
          ],
          "snippet": "export { requirePermission, requireRole, requireAnyPermission }",
          "explanation": "Three RBAC middleware functions for flexible access control enforcement"
        },
        {
          "filePath": "packages/server/src/auth/saml.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: SamlConfig, SamlAssertion, getSpEntityId, getAcsUrl, generateSpMetadata, buildSsoRedirectUrl",
          "explanation": "Full SAML SSO implementation indicates enterprise-grade auth requirements"
        }
      ],
      "constraints": [
        "Every API route must be protected by at least one RBAC middleware",
        "New permissions must be added to the PERMISSIONS constant and mapped to roles",
        "Role hierarchy must be maintained — higher roles inherit all lower role permissions",
        "Auth can be disabled for development via environment variable (isAuthDisabled check in rbac.ts)"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "rbac",
        "authentication",
        "authorization",
        "saml",
        "sso",
        "security"
      ]
    },
    {
      "id": "RxGAisERHnlDK71CCLB_0",
      "title": "SQLite with Drizzle ORM for Local/CLI Mode",
      "description": "The database layer uses SQLite (via better-sqlite3) with Drizzle ORM for the local/CLI mode. The schema is defined using Drizzle's sqlite-core primitives and initialized via raw SQL CREATE TABLE statements. WAL mode and foreign keys are enabled. The database path defaults to ~/.archguard/archguard.db. Drizzle ORM operators (eq, and, or, desc, asc, sql) are re-exported from core to avoid direct drizzle-orm dependencies in downstream packages.",
      "category": "data",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The db/index.ts explicitly creates a SQLite database with WAL mode, defines 16 tables via raw SQL, and wraps it with Drizzle ORM. The schema.ts uses drizzle-orm/sqlite-core. The re-export of Drizzle operators from core/index.ts shows intentional dependency management. The comment 'Returns a Drizzle ORM client backed by either SQLite (local/CLI mode) or PostgreSQL (server mode)' indicates a planned dual-database strategy.",
      "evidence": [
        {
          "filePath": "packages/core/src/db/index.ts",
          "lineRange": [
            1,
            30
          ],
          "snippet": "import { drizzle as drizzleSqlite } from 'drizzle-orm/better-sqlite3'; import Database from 'better-sqlite3'; ... sqlite.pragma('journal_mode = WAL'); sqlite.pragma('foreign_keys = ON');",
          "explanation": "SQLite with WAL mode and foreign keys — production-ready local database configuration"
        },
        {
          "filePath": "packages/core/src/db/index.ts",
          "lineRange": [
            245,
            257
          ],
          "snippet": "export { schema }; export { eq, and, or, desc, asc, sql } from 'drizzle-orm';",
          "explanation": "Re-exports Drizzle operators so downstream packages don't need direct drizzle-orm dependency"
        },
        {
          "filePath": "packages/core/src/db/schema.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "import { ... } from 'drizzle-orm/sqlite-core';",
          "explanation": "Schema defined using Drizzle's SQLite-specific column types"
        }
      ],
      "constraints": [
        "All database queries must use Drizzle ORM — no raw SQL in application code (except schema initialization)",
        "Downstream packages must import Drizzle operators from @archguard/core, not drizzle-orm directly",
        "Schema changes require updating both the Drizzle schema (schema.ts) and the CREATE TABLE statements (index.ts)",
        "The database path is configurable via ARCHGUARD_DATA_DIR environment variable"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "sqlite",
        "drizzle-orm",
        "database",
        "wal-mode",
        "local-first"
      ]
    },
    {
      "id": "RLpFJiBsl4tBmYEMLcDMa",
      "title": "BullMQ Job Queue with Redis for Async Server Operations",
      "description": "The server uses BullMQ backed by Redis (via ioredis) for asynchronous job processing. Five named queues handle different operation types: analysis, review, velocity calculation, summary generation, and context sync. Each queue has a dedicated worker file and typed job data interfaces.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The queue.ts file defines QUEUE_NAMES with five distinct queues, typed job data interfaces (AnalysisJobData, ReviewJobData, etc.), and helper functions for enqueueing and worker registration. Each job type has a dedicated worker file (analyze.job.ts, review.job.ts, etc.). The server/src/index.ts imports and registers all workers. This is a deliberate async processing architecture.",
      "evidence": [
        {
          "filePath": "packages/server/src/jobs/queue.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "import { ... } from 'bullmq'; import { ... } from 'ioredis'; ... export const QUEUE_NAMES = { ... }; export interface AnalysisJobData { ... }",
          "explanation": "BullMQ queue definitions with typed job data for five operation types"
        },
        {
          "filePath": "packages/server/src/jobs/analyze.job.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import { ... } from 'bullmq'; ... export function registerAnalysisWorker() { ... }",
          "explanation": "Dedicated worker for analysis jobs — one worker per queue pattern"
        },
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            1,
            30
          ],
          "snippet": "import { ... } from './jobs/analyze.job.js'; import { ... } from './jobs/review.job.js'; ...",
          "explanation": "Server entrypoint registers all job workers at startup"
        }
      ],
      "constraints": [
        "Long-running operations (analysis, review, velocity, summary, sync) must be enqueued as jobs, not run synchronously in request handlers",
        "Each job type must have a typed data interface in queue.ts",
        "Workers must be registered at server startup",
        "Redis connection is required for the server package to function"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "bullmq",
        "redis",
        "job-queue",
        "async-processing",
        "worker-pattern"
      ]
    },
    {
      "id": "qPjIwwK1gXuvqhv-cwxza",
      "title": "Server-Sent Events (SSE) for Real-Time Dashboard Updates",
      "description": "The system uses Server-Sent Events for pushing real-time updates from the server to the dashboard. The server maintains a client registry with organization-scoped broadcasting. The dashboard consumes SSE via custom React hooks (useSSE, useEventSource). Events include review completions, analysis progress, velocity updates, drift alerts, and more.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The SSE implementation is comprehensive: server-side (sse.ts) with client registry, heartbeat, org-scoped broadcasting, and broadcastEvent export; client-side with two SSE hooks (use-sse.ts, sse.ts) and a createSSEConnection utility. The event types are explicitly enumerated (SSEEventType). The broadcastEvent function is re-exported from server/src/index.ts for use by job workers.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/sse.ts",
          "lineRange": [
            1,
            165
          ],
          "snippet": "export type SSEEventType = 'review:completed' | 'analysis:completed' | 'analysis:progress' | 'velocity:updated' | 'drift:alert' | ... ; ... export function broadcastEvent(type: SSEEventType, data: unknown, orgId?: string): void { ... }",
          "explanation": "Full SSE server implementation with typed events, client registry, heartbeat, and org-scoped broadcasting"
        },
        {
          "filePath": "packages/dashboard/src/hooks/use-sse.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "export function useSSE(options: SSEOptions) { ... }",
          "explanation": "React hook for consuming SSE events in the dashboard"
        },
        {
          "filePath": "packages/dashboard/src/lib/api.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "export function createSSEConnection(...) { ... }",
          "explanation": "SSE connection factory in the API utility layer"
        }
      ],
      "constraints": [
        "Real-time updates must use SSE, not WebSockets or polling",
        "Events must be scoped to the user's organization",
        "Heartbeat must be sent every 30 seconds to keep connections alive",
        "New event types must be added to the SSEEventType union"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "sse",
        "real-time",
        "event-streaming",
        "push-notifications"
      ]
    },
    {
      "id": "MoAww_JWry3aspNYnYGLb",
      "title": "Next.js App Router for Dashboard with Route Group Organization",
      "description": "The dashboard uses Next.js with the App Router (app/ directory). Routes are organized using route groups: (app) for authenticated pages and (auth) for login/signup/SSO. The (app) group has a shared layout with sidebar and header. Pages follow Next.js conventions with page.tsx files and dynamic routes using [id] and [devId] segments.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The directory structure perfectly matches Next.js App Router conventions: app/ directory, (app) and (auth) route groups, layout.tsx files, page.tsx files, dynamic [id] segments. The presence of next.config.js, next-env.d.ts, tailwind.config.ts, and postcss.config.js confirms the Next.js + Tailwind CSS stack. The 'use client' directive in hooks confirms client/server component awareness.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/app/(app)/layout.tsx",
          "lineRange": [
            1,
            17
          ],
          "snippet": "import { Sidebar } from '@/components/layout/sidebar'; import { Header } from '@/components/layout/header'; ... export function AppLayout({ children }) { ... }",
          "explanation": "Shared layout for authenticated routes with sidebar and header"
        },
        {
          "filePath": "packages/dashboard/src/hooks/use-decisions.ts",
          "lineRange": [
            1,
            3
          ],
          "snippet": "'use client'; import { useCallback, useEffect, useState } from 'react';",
          "explanation": "'use client' directive confirms App Router client/server component model"
        },
        {
          "filePath": "packages/dashboard/next.config.js",
          "lineRange": [
            1,
            15
          ],
          "snippet": "// Next.js configuration",
          "explanation": "Next.js configuration file confirms framework choice"
        }
      ],
      "constraints": [
        "Authenticated pages must be under the (app) route group",
        "Auth pages must be under the (auth) route group",
        "Interactive components must use 'use client' directive",
        "Page components must be in page.tsx files following Next.js conventions",
        "Shared layouts must be in layout.tsx files"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "nextjs",
        "app-router",
        "route-groups",
        "react",
        "tailwind-css"
      ]
    },
    {
      "id": "ukDViloU5GMxDD2Q1On2j",
      "title": "Custom React Hooks for Data Fetching (No External State Library)",
      "description": "The dashboard uses custom React hooks (useDecisions, useReviews, useVelocity, useSSE) for data fetching and state management. Each hook encapsulates fetch logic, loading/error states, and action methods. There is no Redux, Zustand, React Query, or SWR — state is managed locally via useState/useCallback/useEffect.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.92,
      "reasoning": "All four data hooks follow the same pattern: useState for data/loading/error, useCallback for fetch functions, useEffect for initial load. The apiFetch utility handles the HTTP layer. There are no imports of any state management library (Redux, Zustand, Jotai, React Query, SWR) anywhere in the dashboard. This is either a deliberate simplicity choice or an early-stage decision that hasn't needed more sophisticated state management yet.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/hooks/use-decisions.ts",
          "lineRange": [
            55,
            85
          ],
          "snippet": "export function useDecisions(filters?: DecisionFilters) { const [decisions, setDecisions] = useState<Decision[]>([]); const [loading, setLoading] = useState(true); const [error, setError] = useState<string | null>(null); const fetchDecisions = useCallback(async () => { ... const data = await apiFetch<Decision[]>(`/decisions${query ? `?${query}` : ''}`); setDecisions(data); ... }, [...]); useEffect(() => { fetchDecisions(); }, [fetchDecisions]); return { decisions, loading, error, refetch: fetchDecisions }; }",
          "explanation": "Custom hook with useState/useCallback/useEffect pattern — no external state library"
        },
        {
          "filePath": "packages/dashboard/src/hooks/use-velocity.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import { useCallback, useEffect, useState } from 'react'; import { apiFetch } from '@/lib/api';",
          "explanation": "Same pattern across all hooks — only React primitives and apiFetch"
        }
      ],
      "constraints": [
        "Data fetching hooks must follow the { data, loading, error, refetch } return pattern",
        "All API calls must go through the apiFetch utility",
        "No external state management libraries should be introduced without migrating existing hooks",
        "Each domain entity (decisions, reviews, velocity) gets its own hook file"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "react-hooks",
        "custom-hooks",
        "state-management",
        "data-fetching",
        "no-external-library"
      ]
    },
    {
      "id": "df0IOTad8lpjxnH6TrHVJ",
      "title": "Multi-Platform Integration Architecture (GitHub, Bitbucket, Slack)",
      "description": "The integrations package provides parallel implementations for GitHub and Bitbucket (API clients, PR bots, webhook handlers) and Slack (app, commands, notifications, block builders). Each platform has its own subdirectory with consistent internal structure. The reviewer package has platform-specific formatters (github-pr, bitbucket-pr, terminal, json).",
      "category": "structural",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The integrations/src/ directory has github/, bitbucket/, and slack/ subdirectories, each with parallel structures (api.ts, pr-bot.ts for git platforms; app.ts, commands.ts, notifications.ts for Slack). The reviewer/src/formatters/ has github-pr.ts and bitbucket-pr.ts with platform-specific formatting. This is a deliberate multi-platform strategy.",
      "evidence": [
        {
          "filePath": "packages/integrations/src/github/api.ts",
          "lineRange": [
            1,
            357
          ],
          "snippet": "import { Octokit } from '@octokit/rest'; ... export function createGitHubClient(...) { ... getDiff, createComment, createReview, createCheckRun ... }",
          "explanation": "GitHub API client wrapping Octokit with ArchGuard-specific operations"
        },
        {
          "filePath": "packages/integrations/src/bitbucket/api.ts",
          "lineRange": [
            1,
            443
          ],
          "snippet": "export function createBitbucketClient(...) { ... getDiff, createComment, createBuildStatus ... }",
          "explanation": "Parallel Bitbucket API client with equivalent operations"
        },
        {
          "filePath": "packages/integrations/src/slack/notifications.ts",
          "lineRange": [
            1,
            50
          ],
          "snippet": "export async function sendViolationAlert(...) ... export async function sendDriftAlert(...) ... export async function sendVelocityDigest(...)",
          "explanation": "Slack notification functions for each type of ArchGuard event"
        }
      ],
      "constraints": [
        "Each git platform must have api.ts, pr-bot.ts, and webhook handler",
        "PR bot implementations must produce equivalent review experiences across platforms",
        "The reviewer must have platform-specific formatters for each supported git platform",
        "New platform integrations must follow the existing subdirectory structure"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "multi-platform",
        "github",
        "bitbucket",
        "slack",
        "integrations"
      ]
    },
    {
      "id": "UI9PR74s67CI5FesIKYQY",
      "title": "MCP Server with Multi-Transport Support (stdio, SSE, Streamable HTTP)",
      "description": "The MCP server implements the Model Context Protocol to expose architectural decisions, compliance checking, guidance, and dependency information to AI coding agents. It supports three transport modes: stdio (for Claude Code, Cursor), legacy SSE, and modern Streamable HTTP with session management and resumability. Tools and resources are registered declaratively with Zod input schemas.",
      "category": "api",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The mcp-server/src/index.ts imports from @modelcontextprotocol/sdk for all three transports. The server registers four tools (get_architectural_decisions, check_architectural_compliance, get_architectural_guidance, get_dependency_graph) and five resources. Each transport has its own startup function with proper session management and cleanup. This is a comprehensive MCP implementation.",
      "evidence": [
        {
          "filePath": "packages/mcp-server/src/index.ts",
          "lineRange": [
            1,
            30
          ],
          "snippet": "import { McpServer, ResourceTemplate } from '@modelcontextprotocol/sdk/server/mcp.js'; import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js'; import { SSEServerTransport } from '@modelcontextprotocol/sdk/server/sse.js'; import { StreamableHTTPServerTransport } from '@modelcontextprotocol/sdk/server/streamableHttp.js';",
          "explanation": "Three transport implementations from the official MCP SDK"
        },
        {
          "filePath": "packages/mcp-server/src/index.ts",
          "lineRange": [
            300,
            380
          ],
          "snippet": "server.tool('get_architectural_decisions', 'Retrieve architectural decisions...', { query: z.string(), category: z.enum([...]).optional() }, async (input) => { ... }); server.tool('check_architectural_compliance', ...);",
          "explanation": "Declarative tool registration with Zod schemas for input validation"
        }
      ],
      "constraints": [
        "All MCP tools must have Zod input schemas",
        "Tools must return { content: [{ type: 'text', text: ... }] } format",
        "Resources must use archguard:// URI scheme",
        "Session management is required for SSE and Streamable HTTP transports",
        "stdio is the default transport for CLI usage"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "mcp",
        "model-context-protocol",
        "ai-agents",
        "tools",
        "resources",
        "multi-transport"
      ]
    },
    {
      "id": "30kqteHuzcf1PublCdghT",
      "title": "XML-Tagged Structured Prompts with Few-Shot Examples (Anthropic Best Practices)",
      "description": "All LLM prompts follow Anthropic's recommended patterns: XML-tagged sections (<role>, <focus_areas>, <output_format>, <examples>, <task>, <architectural_context>, <changes>, etc.), few-shot examples with input/output pairs, chain-of-thought reasoning instructions, and explicit JSON-only output requirements. System prompts are separated from user prompts.",
      "category": "api",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "Both the decision-extractor.ts and llm-reviewer.ts use extensive XML-tagged prompt structures. The decision extractor includes <example_input>/<example_output> few-shot examples, <project_overview>, <directory_structure>, <code_analysis>, <dependency_analysis>, and <task> sections. The reviewer uses <role>, <focus_areas>, <output_format>, <examples>, <architectural_context>, <changes>, and <task>. This is a deliberate prompt engineering strategy following Anthropic's documentation.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/decision-extractor.ts",
          "lineRange": [
            85,
            120
          ],
          "snippet": "const SYSTEM_PROMPT = `You are a world-class software architect... <important_rules>...</important_rules> <categories>...</categories>`; const FEW_SHOT_EXAMPLE = `<example_input>...</example_input> <example_output>...</example_output>`;",
          "explanation": "System prompt with XML-tagged rules and categories, plus few-shot example"
        },
        {
          "filePath": "packages/reviewer/src/llm-reviewer.ts",
          "lineRange": [
            50,
            120
          ],
          "snippet": "const SYSTEM_PROMPT = `<role>You are an expert software architect...</role> <focus_areas>...</focus_areas> <output_format>...</output_format> <examples>...</examples>`;",
          "explanation": "Review system prompt with XML-tagged role, focus areas, output format, and examples"
        },
        {
          "filePath": "packages/reviewer/src/llm-reviewer.ts",
          "lineRange": [
            200,
            260
          ],
          "snippet": "function buildArchitecturalContextSection(decisions): string { ... '<architectural_context>\\n' + decisionBlocks.join('\\n\\n') + '\\n</architectural_context>' ... }",
          "explanation": "User prompt sections use XML tags for clear structure"
        }
      ],
      "constraints": [
        "All LLM prompts must use XML-tagged sections for structure",
        "System prompts must include output format specification with JSON schema",
        "Few-shot examples should be included for complex extraction tasks",
        "User prompts must separate context (data) from instructions (task)"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "prompt-engineering",
        "xml-tags",
        "few-shot",
        "anthropic-best-practices",
        "structured-prompts"
      ]
    },
    {
      "id": "wvrJqNF6d5sJ9BIlLMZg8",
      "title": "Multi-Language Static Analysis via Regex-Based Parsing",
      "description": "The scanner supports six programming languages (TypeScript, JavaScript, Python, Go, Rust, Java) using regex-based extraction for imports, exports, classes, functions, decorators, interfaces, abstract classes, and type aliases. Each extraction function has a switch statement with language-specific regex patterns. This is a deliberate choice of regex over AST parsing for simplicity and breadth of language support.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The scanner.ts has explicit switch statements for all six languages in every extraction function (extractImports, extractExports, extractClasses, etc.). The comment stripping function also handles Python vs C-style comments. The SupportedLanguage type is imported from core. This regex approach trades accuracy for breadth — supporting 6 languages with one file rather than requiring 6 AST parsers.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/scanner.ts",
          "lineRange": [
            140,
            220
          ],
          "snippet": "function extractImports(content: string, language: SupportedLanguage): string[] { ... switch (language) { case 'typescript': case 'javascript': { const esImportRegex = /import\\s+.../g; ... } case 'python': { ... } case 'go': { ... } case 'rust': { ... } case 'java': { ... } } }",
          "explanation": "Language-specific regex patterns for import extraction across 6 languages"
        },
        {
          "filePath": "packages/analyzer/src/scanner.ts",
          "lineRange": [
            110,
            135
          ],
          "snippet": "function stripComments(content: string, language: SupportedLanguage): string { switch (language) { case 'python': return content.replace(/#[^\\n]*/g, '').replace(/\"\"\"[\\s\\S]*?\"\"\"/g, '\"\"'); default: return content.replace(/\\/\\/[^\\n]*/g, '').replace(/\\/\\*[\\s\\S]*?\\*\\//g, ''); } }",
          "explanation": "Comment stripping handles Python vs C-style syntax"
        }
      ],
      "constraints": [
        "New language support requires adding cases to ALL extraction functions",
        "Regex patterns must handle edge cases (re-exports, dynamic imports, conditional imports)",
        "Comments must be stripped before extraction to avoid false matches",
        "The SupportedLanguage type in core must be updated when adding languages"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "multi-language",
        "regex-parsing",
        "static-analysis",
        "scanner",
        "six-languages"
      ]
    },
    {
      "id": "ZlS43KSGmkL5LpdHeujC7",
      "title": "Robert C. Martin Coupling Metrics for Dependency Analysis",
      "description": "The dependency analysis implements Robert C. Martin's package coupling metrics: afferent coupling (Ca), efferent coupling (Ce), instability (I = Ce/(Ca+Ce)), abstractness (A), and distance from the main sequence (D = |A+I-1|). These metrics are calculated per module and reported in both markdown and JSON formats.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The dependency-mapper.ts calculates CouplingMetrics with afferentCoupling, efferentCoupling, instability, abstractness, and distanceFromMainSequence. The markdown reporter explicitly labels these as 'Robert C. Martin' metrics and includes the formulas. The types.ts defines the CouplingMetrics interface. This is a deliberate adoption of established software engineering metrics.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/reporters/markdown.ts",
          "lineRange": [
            127,
            143
          ],
          "snippet": "lines.push('### Module Stability Metrics (Robert C. Martin)');\n    lines.push('');\n    lines.push('| Module | Ca | Ce | Instability | Abstractness | Distance |');\n    ...\n    lines.push('> Ca = Afferent (dependents), Ce = Efferent (dependencies), ');\n    lines.push('> Instability = Ce/(Ca+Ce), Distance = |Abstractness + Instability - 1|');",
          "explanation": "Markdown report explicitly names and explains Robert C. Martin metrics"
        },
        {
          "filePath": "packages/analyzer/src/dependency-mapper.ts",
          "lineRange": [
            1,
            733
          ],
          "snippet": "function calculateCouplingMetrics(...) { ... afferentCoupling ... efferentCoupling ... instability ... abstractness ... distanceFromMainSequence ... }",
          "explanation": "Full implementation of Martin's coupling metrics in the dependency mapper"
        }
      ],
      "constraints": [
        "Dependency analysis must calculate all five Martin metrics per module",
        "Metrics must be included in both markdown and JSON report formats",
        "Abstractness calculation must consider interfaces, abstract classes, and type aliases"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "coupling-metrics",
        "robert-c-martin",
        "instability",
        "abstractness",
        "dependency-analysis"
      ]
    },
    {
      "id": "kyjSGyzORMrPtkA8tsqCL",
      "title": "AI Context File Sync Engine with Multi-Format Generation",
      "description": "The context-sync package generates AI coding assistant context files from architectural decisions. It supports seven output formats: .cursorrules (Cursor), CLAUDE.md (Claude Code), .github/copilot-instructions.md (GitHub Copilot), agents.md, .windsurfrules (Windsurf), .kiro/steering.md (Kiro), and custom templates. Generation can be template-based or LLM-powered. The engine preserves user-added sections between archguard comment markers and supports watch mode with chokidar.",
      "category": "deployment",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The sync-engine.ts has explicit format-to-path mappings and a generator for each format. Seven generator files exist in generators/. The SyncFormat type is defined in core/types.ts. The engine supports both template and LLM generation modes, user section preservation, and file watching. This is a core product feature, not an afterthought.",
      "evidence": [
        {
          "filePath": "packages/context-sync/src/sync-engine.ts",
          "lineRange": [
            55,
            75
          ],
          "snippet": "function getOutputPath(format: SyncFormat, outputDir: string): string { switch (format) { case 'cursorrules': return path.join(outputDir, '.cursorrules'); case 'claude': return path.join(outputDir, 'CLAUDE.md'); case 'copilot': return path.join(outputDir, '.github', 'copilot-instructions.md'); ... } }",
          "explanation": "Seven format-to-path mappings for different AI coding assistants"
        },
        {
          "filePath": "packages/context-sync/src/sync-engine.ts",
          "lineRange": [
            150,
            175
          ],
          "snippet": "renderFormat(format: SyncFormat): string { switch (format) { case 'cursorrules': return generateCursorRules(this.decisions, this.config); case 'claude': return generateClaudeMd(this.decisions, this.config); ... } }",
          "explanation": "Template-based generation with dedicated generator per format"
        },
        {
          "filePath": "packages/context-sync/src/sync-engine.ts",
          "lineRange": [
            120,
            140
          ],
          "snippet": "if (this.config.sync.preserveUserSections) { const existingContent = this.readExistingFile(outputPath); if (existingContent) { const userContent = extractUserSections(existingContent); finalContent = insertUserSections(content, userContent); } }",
          "explanation": "User section preservation between regenerations"
        }
      ],
      "constraints": [
        "Each AI assistant format must have its own generator file in generators/",
        "Generated files must include archguard comment markers for user section preservation",
        "Watch mode must debounce at 5 seconds to avoid excessive regeneration",
        "New formats require adding to the SyncFormat type, getOutputPath, and renderFormat"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "context-sync",
        "ai-assistants",
        "cursor",
        "claude",
        "copilot",
        "code-generation"
      ]
    },
    {
      "id": "yxr5whXgyk23LsXkT0Pyt",
      "title": "In-Memory Rate Limiting with Preset Configurations",
      "description": "The server implements sliding-window rate limiting using an in-memory store with periodic cleanup. Three preset configurations are provided: standard (100/min for general API), strict (20/min for write operations), and analysis (5/min for expensive operations). Rate limit headers (X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset) are set on every response.",
      "category": "security",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The rate-limit.ts file is a complete, well-documented implementation with configurable options, custom key generators (IP or user-based), standard HTTP headers, and three presets. The comment 'In production, replace with a Redis-backed implementation' shows awareness of the limitation. The analysis route explicitly uses the analysisLimit preset.",
      "evidence": [
        {
          "filePath": "packages/server/src/middleware/rate-limit.ts",
          "lineRange": [
            1,
            130
          ],
          "snippet": "export const standardLimit = rateLimit({ max: 100, windowMs: 60_000 }); export const strictLimit = rateLimit({ max: 20, windowMs: 60_000 }); export const analysisLimit = rateLimit({ max: 5, windowMs: 60_000, message: 'Analysis trigger rate limit exceeded...' });",
          "explanation": "Three preset rate limit configurations for different operation types"
        },
        {
          "filePath": "packages/server/src/middleware/rate-limit.ts",
          "lineRange": [
            40,
            55
          ],
          "snippet": "function defaultKeyGenerator(c: Context): string { const user = c.get('user') as { id: string } | undefined; const ip = c.req.header('x-forwarded-for')?.split(',')[0]?.trim() ?? ...; return user ? `user:${user.id}` : `ip:${ip}`; }",
          "explanation": "Key generator uses user ID when authenticated, IP when anonymous"
        }
      ],
      "constraints": [
        "Rate limiting must be applied to all mutation and expensive endpoints",
        "Analysis triggers must use the strictest rate limit (5/min)",
        "Rate limit headers must be set on every response",
        "In-memory store must be replaced with Redis for multi-instance deployments"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "rate-limiting",
        "security",
        "middleware",
        "in-memory",
        "sliding-window"
      ]
    },
    {
      "id": "DSvd30eo-HGdfYaz1vUUR",
      "title": "Tiered File Content Strategy for LLM Analysis",
      "description": "The decision extractor uses a two-tier content strategy for LLM prompts: architecturally significant files (score >= 4) get their full source code sent to the LLM, while less significant files get only structural summaries (imports, exports, classes, functions, decorators). Files are scored using a multi-factor algorithm combining dependency graph topology (fan-in, fan-out, cross-boundary imports), structural role detection, code structure signals, and naming patterns. Content is batched to stay within token limits with bounded parallelism.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The calculateSignificance function in decision-extractor.ts has a detailed scoring algorithm with 15+ factors and a debuggable breakdown. The buildAnalysisPromptFromScored function explicitly separates full-content and summary files in the prompt. The batching logic with MAX_TOKENS_PER_BATCH and MAX_PARALLEL_BATCHES shows careful token budget management. This is a sophisticated optimization for LLM cost and quality.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/decision-extractor.ts",
          "lineRange": [
            340,
            440
          ],
          "snippet": "function calculateSignificance(file, graph): { score: number; breakdown: Record<string, number> } { ... b.fanIn = Math.min(fanIn, 15); ... b.crossBoundary = 8; ... b.config = 6; ... b.contracts = Math.min(interfaceCount * 2 + abstractCount * 3, 10); ... b.naming = namingScore; ... }",
          "explanation": "Multi-factor file significance scoring with 15+ weighted signals"
        },
        {
          "filePath": "packages/analyzer/src/decision-extractor.ts",
          "lineRange": [
            170,
            220
          ],
          "snippet": "let fullCandidates = allScored.filter((s) => s.score >= 4 && s.contentTokens > 0); ... const budgetPerCall = Math.max(Math.min(FILE_CONTENT_BUDGET_TOKENS, MAX_TOKENS_PER_BATCH) - perCallOverhead, 5_000);",
          "explanation": "Score threshold for full content and token budget calculation for batching"
        }
      ],
      "constraints": [
        "Files scoring >= 4 get full content; others get summaries only",
        "Token budget per batch must not exceed MAX_TOKENS_PER_BATCH (100K)",
        "Parallel LLM calls are bounded by MAX_PARALLEL_BATCHES (3)",
        "Results from multiple batches must be deduplicated by title"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "tiered-content",
        "token-optimization",
        "file-scoring",
        "batching",
        "llm-cost"
      ]
    },
    {
      "id": "KKpiBgRDp6mUfoIx0we6F",
      "title": "Comprehensive Dependency Resolution (tsconfig paths, pnpm workspaces, Python, Go)",
      "description": "The dependency mapper resolves imports across multiple resolution strategies: TypeScript path aliases (tsconfig.json compilerOptions.paths), pnpm workspace cross-package imports, Python relative imports (from . import X), Go module paths (via go.mod), and standard relative imports. Resolution tries multiple file extensions and index files. This enables accurate dependency graphs across polyglot monorepos.",
      "category": "data",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "The resolveImport function in dependency-mapper.ts chains five resolution strategies in a specific order. Each strategy has its own dedicated function (resolveTsConfigAlias, resolveWorkspaceImport, resolvePythonImport, resolveGoImport). The tsconfig.json parser handles comments and wildcard patterns. The workspace resolver reads pnpm-workspace.yaml and scans for package.json files. This is a significant engineering investment in accurate cross-language dependency resolution.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/dependency-mapper.ts",
          "lineRange": [
            350,
            400
          ],
          "snippet": "function resolveImport(fromFile, importPath, filesByPath, tsConfig, projectDir, workspacePackages): string | null { if (lang === 'python' && importPath.startsWith('.')) return resolvePythonImport(...); if (lang === 'go' && ...) return resolveGoImport(...); if (importPath.startsWith('.')) { ... } if (tsConfig) { const aliasResult = resolveTsConfigAlias(...); } if (workspacePackages.size > 0) { const wsResult = resolveWorkspaceImport(...); } ... }",
          "explanation": "Five-strategy import resolution chain with language-specific handling"
        },
        {
          "filePath": "packages/analyzer/src/dependency-mapper.ts",
          "lineRange": [
            200,
            260
          ],
          "snippet": "function resolveTsConfigAlias(importPath, tsConfig, projectDir, filesByPath): string | null { for (const [pattern, mappings] of Object.entries(tsConfig.paths)) { if (pattern.endsWith('/*')) { const prefix = pattern.slice(0, -1); if (importPath.startsWith(prefix)) { ... } } } }",
          "explanation": "TypeScript path alias resolution with wildcard pattern support"
        }
      ],
      "constraints": [
        "Import resolution must try all strategies in order: language-specific → relative → tsconfig → workspace → fallback",
        "File extension resolution must try .ts, .tsx, .js, .jsx, .py, .go, and /index variants",
        "tsconfig.json parsing must handle comments (non-standard JSON)",
        "Workspace resolution must read pnpm-workspace.yaml and scan package.json files"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "dependency-resolution",
        "tsconfig",
        "pnpm-workspace",
        "python",
        "go",
        "polyglot"
      ]
    },
    {
      "id": "cpS1xJPyDZ9uqAK7iW1oB",
      "title": "Structured Error Hierarchy for LLM Operations",
      "description": "The LLM module defines a structured error hierarchy: LlmError (base), LlmAuthError (missing/invalid API key with setup instructions), LlmRateLimitError (with retry-after), LlmValidationError (with raw response and Zod errors), and LlmCostLimitError (with current cost and limit). A getFailureReason function maps errors to human-readable messages for CLI output.",
      "category": "api",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "Five distinct error classes with specific metadata (retryAfterMs, rawResponse, zodErrors, currentCost) indicate deliberate error handling design. The getFailureReason function maps each error type to a user-friendly message. The retry logic in analyzeWithLlm handles each error type differently (don't retry auth errors, respect rate limits, retry transient errors). This is production-grade error handling.",
      "evidence": [
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            20,
            90
          ],
          "snippet": "export class LlmError extends Error { constructor(message: string, public readonly code: string) { ... } } export class LlmAuthError extends LlmError { constructor(apiKeyEnv: string) { super(`\\nAnthopic API key required...`) } } export class LlmRateLimitError extends LlmError { constructor(public readonly retryAfterMs: number) { ... } } export class LlmValidationError extends LlmError { constructor(message, public readonly rawResponse: string, public readonly zodErrors?: z.ZodError) { ... } }",
          "explanation": "Five error classes with specific metadata for each failure mode"
        },
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            70,
            85
          ],
          "snippet": "export function getFailureReason(error: unknown): string { if (error instanceof LlmAuthError) return 'API key invalid or missing'; if (error instanceof LlmRateLimitError) return 'API rate limited'; ... }",
          "explanation": "Error-to-message mapping for user-friendly CLI output"
        }
      ],
      "constraints": [
        "All LLM failures must throw a specific LlmError subclass, not generic Error",
        "Auth errors must include setup instructions with the environment variable name",
        "Validation errors must preserve the raw LLM response for debugging",
        "Rate limit errors must include the retry-after duration"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "error-handling",
        "error-hierarchy",
        "llm-errors",
        "structured-errors"
      ]
    },
    {
      "id": "ZUyKe7RxqRZ4vlzk4gfL9",
      "title": "Heuristic Pattern Detection as Pre-LLM Analysis Pass",
      "description": "The pattern-detector.ts implements nine heuristic pattern detectors (MVC, Repository, Dependency Injection, Event-Driven, Middleware Chain, API Versioning, State Management, Layered Architecture, Clean Architecture) that run before the LLM analysis. These use file path conventions, class/function naming, decorator presence, and import patterns to identify architectural patterns with confidence scores. Patterns below 0.3 confidence are filtered out.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.92,
      "reasoning": "The detectPatterns function orchestrates nine specialized detectors, each returning DetectedPattern objects with confidence scores and evidence. The 0.3 confidence threshold filter shows calibrated output. These heuristics complement the LLM analysis — they provide fast, deterministic pattern detection that the LLM can then validate and enrich. The pattern names match standard architectural vocabulary.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/pattern-detector.ts",
          "lineRange": [
            15,
            35
          ],
          "snippet": "export function detectPatterns(files, directoryTree): DetectedPattern[] { ... patterns.push(...detectMvcPattern(files)); patterns.push(...detectRepositoryPattern(files)); patterns.push(...detectDependencyInjection(files)); ... return patterns.filter((p) => p.confidence > 0.3); }",
          "explanation": "Nine pattern detectors with confidence threshold filtering"
        },
        {
          "filePath": "packages/analyzer/src/pattern-detector.ts",
          "lineRange": [
            100,
            140
          ],
          "snippet": "function detectDependencyInjection(files): DetectedPattern[] { const diFiles = files.filter((f) => f.decorators.some((d) => ['Injectable', 'Inject', 'Component', 'Service', 'Module'].includes(d)) || f.imports.some((i) => i.includes('inversify') || i.includes('tsyringe') || i.includes('@nestjs'))); ... }",
          "explanation": "DI detection uses decorator names and framework imports as signals"
        }
      ],
      "constraints": [
        "Pattern detectors must return confidence scores between 0 and 1",
        "Each detector must provide evidence with file paths",
        "Patterns below 0.3 confidence are automatically filtered",
        "New pattern detectors should follow the existing function signature pattern"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "pattern-detection",
        "heuristics",
        "architectural-patterns",
        "confidence-scoring"
      ]
    },
    {
      "id": "QKCs6Z3HVXECQmSpLFs2d",
      "title": "Truncated JSON Repair for LLM Response Robustness",
      "description": "The extractJson function in the LLM module includes a repairTruncatedJson fallback that attempts to fix JSON responses cut off by max_tokens limits. It strips trailing incomplete strings, removes trailing commas, counts unclosed braces/brackets, and appends closing characters. This handles a common failure mode where the LLM runs out of output tokens mid-response.",
      "category": "api",
      "status": "detected",
      "confidence": 0.91,
      "reasoning": "The repairTruncatedJson function is a dedicated recovery mechanism for a specific failure mode (max_tokens truncation). It's called as a last resort in extractJson after direct parsing, code fence extraction, and bracket-matching all fail. The function handles multiple truncation scenarios (cut-off strings, trailing commas, unclosed structures). This shows real-world experience with LLM output reliability issues.",
      "evidence": [
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            430,
            480
          ],
          "snippet": "function repairTruncatedJson(text: string): string | null { ... json = json.replace(/,\\s*\"[^\"]*$/s, ''); json = json.replace(/:\\s*\"[^\"]*$/s, ': \"\"'); json = json.replace(/,\\s*$/s, ''); ... let inString = false; const stack: string[] = []; ... json += stack.reverse().join(''); return json; }",
          "explanation": "Truncated JSON repair: strips incomplete strings, removes trailing commas, closes unclosed structures"
        },
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            400,
            430
          ],
          "snippet": "// Last resort: try to repair truncated JSON by closing open braces/brackets // This handles responses cut off by max_tokens const repaired = repairTruncatedJson(trimmed); if (repaired) { try { JSON.parse(repaired); return repaired; } catch { /* Repair wasn't enough */ } }",
          "explanation": "Repair is the last fallback in the JSON extraction chain"
        }
      ],
      "constraints": [
        "JSON repair is a last resort — direct parsing and bracket matching are tried first",
        "Repair must handle unclosed strings, trailing commas, and unclosed braces/brackets",
        "Repaired JSON must still pass JSON.parse validation",
        "This does not guarantee semantic correctness — Zod validation catches structural issues"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "json-repair",
        "llm-robustness",
        "truncation-handling",
        "error-recovery"
      ]
    },
    {
      "id": "GalFYURNKEFyQhz8VmnMn",
      "title": "Velocity Scoring with Multi-Dimensional Developer Metrics",
      "description": "The velocity package implements a comprehensive developer productivity scoring system with multiple dimensions: git stats (commits, lines changed), PR metrics (opened, merged, size distribution, violation rates), complexity analysis (cyclomatic, cognitive), effort modeling (weighted by complexity), impact scoring (architectural boundary crossings), and blocker detection (stalled PRs, long-lived branches, review bottlenecks, high violation rates). Scores are calculated per developer per period with trend analysis.",
      "category": "data",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The velocity package has a clear internal architecture: collectors/ (git-stats, complexity, pr-metrics, issue-tracker), scoring/ (effort-model, impact-score, velocity-calculator), and blockers/ (detector, alerts). The VelocityScore type in core/types.ts has 12+ fields. The velocity-calculator.ts combines all dimensions with configurable weights. The blocker detector has four detection strategies. This is a well-designed metrics system.",
      "evidence": [
        {
          "filePath": "packages/velocity/src/blockers/detector.ts",
          "lineRange": [
            60,
            85
          ],
          "snippet": "export function detectBlockers(openPrs, prMetrics, config): Blocker[] { ... blockers.push(...detectStalledPrs(openPrs, thresholds.stalePrDays, now)); blockers.push(...detectLongLivedBranches(openPrs, thresholds.longBranchDays, now)); blockers.push(...detectReviewBottlenecks(openPrs, thresholds.reviewBottleneckThreshold)); blockers.push(...detectHighViolationRates(prMetrics, openPrs, thresholds.highViolationRate)); return blockers; }",
          "explanation": "Four blocker detection strategies with configurable thresholds"
        },
        {
          "filePath": "packages/velocity/src/scoring/velocity-calculator.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "exports: VelocityInput, calculateDeveloperVelocityScores, calculateTeamVelocity, determineTrend ... functions: calculateDeveloperVelocityScores, weightedEffort, architecturalImpact, ...",
          "explanation": "Velocity calculator combines effort, impact, and review contribution into a single score"
        }
      ],
      "constraints": [
        "Velocity scores must be calculated per developer per period",
        "All scoring dimensions must be independently configurable via weights",
        "Blocker detection thresholds must be configurable via ArchGuardConfig",
        "Trend determination requires historical data points"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:13:07.450Z",
      "tags": [
        "velocity",
        "developer-metrics",
        "productivity",
        "blocker-detection",
        "scoring"
      ]
    },
    {
      "id": "EWsaZQrJEt2GlXznu4RvO",
      "title": "Monorepo with Domain-Oriented Package Structure",
      "description": "The codebase is organized as a monorepo under `packages/` with each package representing a distinct domain capability: analyzer, cli, context-sync, core, dashboard, integrations, mcp-server, reviewer, server, velocity, and work-summary. Each package has its own `src/` directory and exports via an `index.ts` barrel file.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The directory structure clearly shows 11 packages under `packages/`, each with a focused domain responsibility. Every package has a barrel `index.ts` that re-exports its public API. The `core` package serves as a shared foundation imported by all others. This is a deliberate modular monorepo design, not an accident — the packages have clean boundaries and well-defined public APIs.",
      "evidence": [
        {
          "filePath": "packages/core/src/index.ts",
          "lineRange": [
            1,
            106
          ],
          "snippet": "export { loadConfig, writeDefaultConfig, getDefaultConfig } from './config.js';\nexport { createSqliteClient, initializeDatabase, schema, ... } from './db/index.js';",
          "explanation": "Core package barrel file re-exports all shared utilities, DB, LLM, auth, git, and types — serving as the foundation for all other packages"
        },
        {
          "filePath": "packages/context-sync/src/index.ts",
          "lineRange": [
            1,
            49
          ],
          "snippet": "export { generateCursorRules } from './generators/cursorrules.js';\nexport { generateClaudeMd } from './generators/claude-md.js';",
          "explanation": "Each package has a clean barrel export showing its focused domain responsibility"
        },
        {
          "filePath": "packages/velocity/src/index.ts",
          "lineRange": [
            1,
            263
          ],
          "snippet": "export { collectGitStats, ... } from './collectors/git-stats.js';\nexport { calculateEffortScores, ... } from './scoring/effort-model.js';",
          "explanation": "Velocity package re-exports collectors, scoring, and blockers — a self-contained domain module"
        }
      ],
      "constraints": [
        "New features should be added to the appropriate domain package or a new package if they represent a new domain",
        "Cross-package dependencies should flow through the core package or explicit package imports",
        "Each package must maintain a barrel index.ts that defines its public API"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "monorepo",
        "domain-driven",
        "modular-architecture",
        "package-structure"
      ]
    },
    {
      "id": "FsqqUWl3v5DTHNGxKWmDc",
      "title": "Hono as HTTP Framework for API Server",
      "description": "The server package uses Hono as the HTTP framework instead of Express or Fastify. Routes are organized as factory functions that return Hono router instances, composed in the main server entrypoint. Middleware follows Hono's (c, next) pattern.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.98,
      "reasoning": "The server/src/index.ts explicitly imports from 'hono', 'hono/cors', 'hono/logger', and '@hono/node-server'. All route files export factory functions returning `Hono` instances. Middleware files use Hono's Context and Next types. The hono-env.d.ts file extends Hono's type system. This is clearly an intentional framework choice.",
      "evidence": [
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            14,
            22
          ],
          "snippet": "import { Hono } from 'hono';\nimport { cors } from 'hono/cors';\nimport { logger } from 'hono/logger';\nimport { serve } from '@hono/node-server';",
          "explanation": "Main server entrypoint uses Hono as the HTTP framework"
        },
        {
          "filePath": "packages/server/src/auth/rbac.ts",
          "lineRange": [
            8,
            9
          ],
          "snippet": "import type { Context, Next } from 'hono';",
          "explanation": "Middleware uses Hono's Context and Next types"
        },
        {
          "filePath": "packages/server/src/hono-env.d.ts",
          "lineRange": [
            1,
            17
          ],
          "snippet": "interface ContextVariableMap",
          "explanation": "Custom type declarations extending Hono's context variable map for type-safe context access"
        }
      ],
      "constraints": [
        "All server middleware must conform to Hono's (Context, Next) signature",
        "Route handlers receive Hono Context objects, not Express req/res",
        "Server-side rendering is not handled by Hono — the dashboard is a separate Next.js app"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "hono",
        "http-framework",
        "server",
        "middleware"
      ]
    },
    {
      "id": "NmM-3w3uvv_Ep6dn50UvY",
      "title": "Role-Based Access Control (RBAC) with Hierarchical Roles",
      "description": "The system implements a 4-tier RBAC model (owner > admin > member > viewer) with granular resource:action permissions. Permissions are defined centrally in core/auth.ts and enforced via Hono middleware in the server. An escape hatch (ARCHGUARD_DISABLE_AUTH) exists for local CLI mode.",
      "category": "security",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The ROLE_PERMISSIONS map in core/auth.ts defines explicit permissions per role. The owner role has wildcard '*' access. Scoped permissions like 'velocity:read:own' allow members to see only their own data. The server has dedicated middleware (requirePermission, requireRole, requireAnyPermission) that checks these permissions. The ARCHGUARD_DISABLE_AUTH env var is checked first in every middleware, indicating dual CLI/server usage.",
      "evidence": [
        {
          "filePath": "packages/core/src/auth.ts",
          "lineRange": [
            10,
            52
          ],
          "snippet": "export const ROLE_PERMISSIONS: Record<Role, Permission[]> = {\n  owner: ['*'],\n  admin: ['decisions:read', 'decisions:write', ...],\n  member: ['decisions:read', 'decisions:write', 'velocity:read:own', ...],\n  viewer: ['decisions:read', 'reviews:read', 'repos:read'],\n};",
          "explanation": "Central permission definitions with hierarchical roles and scoped permissions"
        },
        {
          "filePath": "packages/server/src/auth/rbac.ts",
          "lineRange": [
            33,
            60
          ],
          "snippet": "export function requirePermission(permission: Permission, options?: { ownerIdParam?: string }) {\n  return async (c: Context, next: Next) => {\n    if (isAuthDisabled()) { await next(); return; }\n    const user = c.get('user') as AuthUser | undefined;\n    ...\n    const allowed = hasPermission(user.role, permission, ownerId, user.id);",
          "explanation": "Middleware factory that creates permission-checking middleware with owner-scoping support"
        },
        {
          "filePath": "packages/server/src/routes/velocity.ts",
          "lineRange": [
            1,
            30
          ],
          "snippet": "router.get('/team', requirePermission('velocity:read'), async (c) => {",
          "explanation": "Routes use requirePermission middleware to enforce access control"
        }
      ],
      "constraints": [
        "All protected API routes must use requirePermission or requireRole middleware",
        "New permissions must be added to ROLE_PERMISSIONS in core/auth.ts",
        "Scoped permissions (`:own` suffix) require passing ownerId for comparison",
        "CLI mode bypasses auth via ARCHGUARD_DISABLE_AUTH environment variable"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "rbac",
        "authorization",
        "security",
        "middleware",
        "permissions"
      ]
    },
    {
      "id": "jb-fapsB3nz2fAOVRe8z5",
      "title": "Multi-Tenant Organization Context via Middleware",
      "description": "The server implements multi-tenancy through an organization context middleware that resolves the current org from the authenticated user's session and attaches it to the Hono context. All data queries are scoped by orgId.",
      "category": "security",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The orgContextMiddleware in org-context.ts loads the full organization record from the database using the user's orgId, then sets 'org' and 'orgId' on the Hono context. Route handlers consistently read orgId from context (c.get('orgId')) to scope database queries. The database schema has orgId foreign keys on most tables (repositories, developers, workSummaries, etc.).",
      "evidence": [
        {
          "filePath": "packages/server/src/middleware/org-context.ts",
          "lineRange": [
            37,
            95
          ],
          "snippet": "export function orgContextMiddleware(db: DbClient) {\n  return async (c: Context, next: Next) => {\n    const user = c.get('user') as AuthUser | undefined;\n    ...\n    c.set('org', orgContext);\n    c.set('orgId', org.id);\n    await next();\n  };\n}",
          "explanation": "Middleware resolves org from authenticated user and attaches to context"
        },
        {
          "filePath": "packages/server/src/routes/velocity.ts",
          "lineRange": [
            22,
            25
          ],
          "snippet": "const orgId = c.get('orgId') as string;\n...\nconst devRows = await db.select().from(schema.developers).where(eq(schema.developers.orgId, orgId));",
          "explanation": "Route handlers scope all queries by orgId from context"
        },
        {
          "filePath": "packages/core/src/db/schema.ts",
          "lineRange": [
            59,
            63
          ],
          "snippet": "export const repositories = sqliteTable('repositories', {\n  ...\n  orgId: text('org_id').notNull().references(() => organizations.id),",
          "explanation": "Database schema enforces org-level data isolation via foreign keys"
        }
      ],
      "constraints": [
        "All data-accessing routes must be placed after orgContextMiddleware in the middleware chain",
        "Database queries must filter by orgId to maintain tenant isolation",
        "New database tables with tenant-scoped data must include an orgId foreign key"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "multi-tenancy",
        "organization-context",
        "middleware",
        "data-isolation"
      ]
    },
    {
      "id": "O6dLmi5ti5Fj2kfAy5e-0",
      "title": "BullMQ Job Queue for Async Processing",
      "description": "The server uses BullMQ with Redis for asynchronous job processing. Five named queues handle analysis, review, velocity calculation, summary generation, and context sync. Jobs are enqueued from route handlers and webhook receivers, then processed by registered workers.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The jobs/queue.ts defines QUEUE_NAMES with 5 queues and provides enqueue functions. Each job type has a dedicated worker file (analyze.job.ts, review.job.ts, etc.). The server index.ts conditionally registers workers based on ENABLE_WORKERS env var. Webhook handlers enqueue jobs rather than processing inline. This is a deliberate architectural choice for decoupling request handling from heavy processing.",
      "evidence": [
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            155,
            172
          ],
          "snippet": "if (ENABLE_WORKERS) {\n  try {\n    registerAnalysisWorker();\n    registerReviewWorker();\n    registerVelocityWorker();\n    registerSummaryWorker();\n    registerSyncWorker();\n    console.log('[jobs] All workers registered');",
          "explanation": "Server conditionally registers all job workers at startup"
        },
        {
          "filePath": "packages/server/src/routes/webhooks.ts",
          "lineRange": [
            79,
            90
          ],
          "snippet": "await enqueueReview({\n  repoId: repo.id,\n  orgId: repo.orgId,\n  prNumber,\n  ref: headRef,\n  triggeredBy: 'webhook',\n});",
          "explanation": "Webhook handlers enqueue jobs rather than processing inline"
        }
      ],
      "constraints": [
        "Redis must be available for job queue functionality",
        "Heavy processing (LLM calls, git analysis) must be done in job workers, not route handlers",
        "Workers can be disabled via ENABLE_WORKERS=false for environments without Redis",
        "Job data must be serializable to JSON for Redis storage"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "bullmq",
        "job-queue",
        "redis",
        "async-processing",
        "workers"
      ]
    },
    {
      "id": "QHFDATQetJH6kUsodZDmc",
      "title": "Next.js App Router with Route Groups for Dashboard",
      "description": "The dashboard uses Next.js with the App Router pattern, employing route groups `(app)` and `(auth)` to separate authenticated and unauthenticated layouts. All pages are client components ('use client'). The app uses standalone output mode for containerized deployment.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The directory structure shows `(app)` and `(auth)` route groups with separate layouts. All page files use 'use client' directive. The next.config.js sets `output: 'standalone'` and `transpilePackages` for monorepo support. The `(app)/layout.tsx` wraps pages with Sidebar and Header components.",
      "evidence": [
        {
          "filePath": "packages/dashboard/next.config.js",
          "lineRange": [
            1,
            15
          ],
          "snippet": "const nextConfig = {\n  output: 'standalone',\n  transpilePackages: ['@archguard/core', '@archguard/api', '@archguard/shared'],\n  experimental: { serverActions: true },\n};",
          "explanation": "Standalone output for containerization, transpilePackages for monorepo support"
        },
        {
          "filePath": "packages/dashboard/src/app/(app)/layout.tsx",
          "lineRange": [
            1,
            17
          ],
          "snippet": "import { Sidebar } from '@/components/layout/sidebar';\nimport { Header } from '@/components/layout/header';",
          "explanation": "App route group layout wraps authenticated pages with navigation chrome"
        },
        {
          "filePath": "packages/dashboard/src/app/(app)/dashboard/page.tsx",
          "lineRange": [
            1,
            1
          ],
          "snippet": "'use client';",
          "explanation": "All dashboard pages are client components"
        }
      ],
      "constraints": [
        "Authenticated pages must be placed under (app)/ route group",
        "Auth pages (login, signup, SSO) must be placed under (auth)/ route group",
        "Dashboard pages should use 'use client' directive for client-side interactivity",
        "Shared monorepo packages must be listed in transpilePackages"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "nextjs",
        "app-router",
        "route-groups",
        "client-components",
        "standalone"
      ]
    },
    {
      "id": "1MrJ7Z7O3BVGm2pI0ggJK",
      "title": "Centralized API Client with Bearer Token Auth",
      "description": "The dashboard uses a centralized API client (lib/api.ts) that wraps fetch with automatic Bearer token injection from localStorage, consistent error handling via ApiError class, and typed HTTP method helpers (apiGet, apiPost, apiPut, apiDelete).",
      "category": "api",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The api.ts file defines a single apiFetch function that all HTTP methods delegate to. It reads the auth token from localStorage ('archguard_session'), adds Authorization headers, and throws ApiError with status codes. All dashboard pages and hooks use these helpers consistently (apiFetch, apiGet, etc.).",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/lib/api.ts",
          "lineRange": [
            1,
            127
          ],
          "snippet": "export async function apiFetch<T>(path: string, options?: RequestInit): Promise<T> {\n  const token = getAuthToken();\n  const headers: Record<string, string> = {\n    'Content-Type': 'application/json',\n    ...(token ? { Authorization: `Bearer ${token}` } : {}),\n  };",
          "explanation": "Centralized fetch wrapper with automatic auth token injection and error handling"
        },
        {
          "filePath": "packages/dashboard/src/app/(app)/dependencies/page.tsx",
          "lineRange": [
            38,
            42
          ],
          "snippet": "const result = await apiFetch<DependencyData>('/dependencies');",
          "explanation": "Pages consistently use the centralized API client"
        }
      ],
      "constraints": [
        "All API calls from the dashboard must go through apiFetch or its method helpers",
        "Auth tokens are stored in localStorage under 'archguard_session'",
        "API errors are represented as ApiError instances with status codes",
        "All requests include Content-Type: application/json by default"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "api-client",
        "bearer-auth",
        "fetch-wrapper",
        "error-handling"
      ]
    },
    {
      "id": "COcbgiBHYrlnuuHK-ZqKg",
      "title": "LLM-First Architecture with Anthropic Claude",
      "description": "The system is built around LLM-powered analysis using Anthropic's Claude API as the primary AI provider. LLM interactions are centralized in core/llm.ts with operation-specific model routing (different models for different tasks), cost tracking, caching, and structured JSON extraction with validation.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The core/llm.ts imports @anthropic-ai/sdk and provides createLlmClient, analyzeWithLlm, analyzeWithLlmValidated, and extractJson. The getModelForOperation function routes different operations to different models. Multiple packages depend on this: analyzer (decision extraction), reviewer (LLM review), work-summary (summary generation), context-sync (LLM sync), and mcp-server (pattern checking). The summarizer.ts explicitly states 'LLM is always required — there are no fallback paths.'",
      "evidence": [
        {
          "filePath": "packages/work-summary/src/summarizer.ts",
          "lineRange": [
            1,
            12
          ],
          "snippet": "/**\n * LLM-powered work summary generation.\n * ...\n * LLM is always required — there are no fallback paths.\n */\nimport { createLlmClient, analyzeWithLlm, ... } from '@archguard/core';",
          "explanation": "Explicit statement that LLM is always required with no fallback"
        },
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            1,
            14
          ],
          "snippet": "import Anthropic from '@anthropic-ai/sdk';",
          "explanation": "Core LLM module uses Anthropic SDK as the sole AI provider"
        },
        {
          "filePath": "packages/analyzer/src/decision-extractor.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import { ... } from '@archguard/core';\nimport Anthropic from '@anthropic-ai/sdk';",
          "explanation": "Decision extraction uses LLM for architectural analysis"
        }
      ],
      "constraints": [
        "An Anthropic API key is required for core functionality (analysis, review, summaries)",
        "All LLM interactions must go through core/llm.ts functions",
        "LLM responses must be validated/parsed using extractJson or analyzeWithLlmValidated",
        "Cost tracking is mandatory — all LLM calls are recorded"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "llm",
        "anthropic",
        "claude",
        "ai-first",
        "cost-tracking"
      ]
    },
    {
      "id": "jv15e4aRH4lutnbDnbxED",
      "title": "Webhook-Driven CI/CD Integration with GitHub and Bitbucket",
      "description": "The system integrates with GitHub and Bitbucket via webhooks that trigger architectural reviews on PRs and analysis on pushes to default branches. Webhook endpoints are public but signature-verified, and they dispatch work to the job queue rather than processing inline.",
      "category": "deployment",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The webhooks.ts router handles both GitHub and Bitbucket webhook events. It verifies signatures, looks up repositories in the database, and enqueues appropriate jobs (review for PRs, analysis+sync for pushes). The integrations package has dedicated modules for GitHub (app.ts, pr-bot.ts, check-run.ts) and Bitbucket (webhook.ts, pr-bot.ts) with full PR comment and check run support.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/webhooks.ts",
          "lineRange": [
            22,
            30
          ],
          "snippet": "export function createWebhooksRouter(db: DbClient): Hono {\n  const router = new Hono();\n  router.post('/github', async (c) => {\n    const event = c.req.header('X-GitHub-Event');\n    const signature = c.req.header('X-Hub-Signature-256');",
          "explanation": "Webhook routes handle both GitHub and Bitbucket events with signature verification"
        },
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            97,
            98
          ],
          "snippet": "// Webhook endpoints are public (no auth middleware) but verified by signatures\napp.route('/api/webhooks', createWebhooksRouter(db));",
          "explanation": "Webhooks are mounted before auth middleware, relying on signature verification instead"
        },
        {
          "filePath": "packages/server/src/routes/webhooks.ts",
          "lineRange": [
            74,
            92
          ],
          "snippet": "await enqueueReview({ repoId: repo.id, orgId: repo.orgId, prNumber, ref: headRef, triggeredBy: 'webhook' });\n...\nawait enqueueAnalysis({ repoId: repo.id, orgId: repo.orgId, triggeredBy: 'webhook' });\nawait enqueueSync({ repoId: repo.id, orgId: repo.orgId });",
          "explanation": "Webhooks enqueue jobs rather than processing inline"
        }
      ],
      "constraints": [
        "Webhook endpoints must remain public (before auth middleware) but verify signatures",
        "Webhook processing must be async via job queues, not synchronous",
        "Both GitHub and Bitbucket webhook formats must be supported",
        "Repository webhook secrets must be stored in the database for signature verification"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "webhooks",
        "github",
        "bitbucket",
        "ci-cd",
        "pr-review",
        "async"
      ]
    },
    {
      "id": "xY2feMSw2idRojFuBrqGp",
      "title": "Multi-Format Context Sync for AI Coding Assistants",
      "description": "The context-sync package generates context files for 7+ AI coding assistants (Cursor, Claude Code, GitHub Copilot, Agents, Windsurf, Kiro, and custom Handlebars templates) from architectural decisions. Each generator follows the same pattern: take decisions + config, produce formatted output. A SyncEngine orchestrates generation with file watching support.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The context-sync package has 7 generator files under generators/, each exporting a single generate function. The index.ts re-exports all generators. The SyncEngine class in sync-engine.ts orchestrates multi-format generation. The templates.ts provides shared Handlebars helpers. The custom.ts generator allows user-defined templates. This is a deliberate strategy pattern for multi-target output.",
      "evidence": [
        {
          "filePath": "packages/context-sync/src/index.ts",
          "lineRange": [
            1,
            25
          ],
          "snippet": "export { generateCursorRules } from './generators/cursorrules.js';\nexport { generateClaudeMd } from './generators/claude-md.js';\nexport { generateAgentsMd } from './generators/agents-md.js';\nexport { generateCopilotInstructions } from './generators/copilot.js';\nexport { generateWindsurfRules } from './generators/windsurf.js';\nexport { generateKiroSteering } from './generators/kiro.js';\nexport { generateCustom, DEFAULT_CUSTOM_TEMPLATE } from './generators/custom.js';",
          "explanation": "7 generators for different AI coding assistants"
        },
        {
          "filePath": "packages/context-sync/src/generators/custom.ts",
          "lineRange": [
            42,
            100
          ],
          "snippet": "export function generateCustom(\n  decisions: ArchDecision[],\n  config: ArchGuardConfig,\n  options: CustomTemplateOptions\n): string {\n  const hbs = registerHelpers();\n  ...\n  const template = hbs.compile(options.template);\n  return template(context);\n}",
          "explanation": "Custom generator uses Handlebars for user-defined templates"
        },
        {
          "filePath": "packages/context-sync/src/templates.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import Handlebars from 'handlebars';\nimport type { ArchDecision, ArchCategory } from '@archguard/core';",
          "explanation": "Shared Handlebars template infrastructure used by all generators"
        }
      ],
      "constraints": [
        "New AI assistant formats should be added as new generator files under generators/",
        "All generators must accept (decisions, config) and return a string",
        "Shared template helpers must be registered in templates.ts",
        "User sections (<!-- archguard:user-start/end -->) must be preserved across regeneration"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "context-sync",
        "ai-assistants",
        "code-generation",
        "handlebars",
        "strategy-pattern"
      ]
    },
    {
      "id": "Ji5IM9lVjRrD0duAFggSL",
      "title": "Incremental Analysis with File-Hash-Based Caching",
      "description": "The analyzer implements incremental analysis by caching results keyed on SHA-256 file content hashes. On subsequent runs, only changed files are re-analyzed, and cached decisions are merged with new ones. The cache has a configurable TTL and is stored in .archguard/cache.json.",
      "category": "data",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The cache.ts file implements a complete caching system: hashFiles computes per-file SHA-256 hashes, identifyChangedFiles diffs current vs cached hashes, loadCache validates TTL, and mergeDecisions intelligently combines cached and new decisions (removing cached decisions whose evidence files changed). This is a deliberate optimization to avoid redundant LLM calls.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/cache.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * Analysis cache management with file hashing and TTL.\n * Caches analysis results to avoid redundant LLM calls when files haven't changed.\n * Uses SHA-256 hashing of file contents to detect changes.\n */",
          "explanation": "Explicit documentation of caching purpose: avoiding redundant LLM calls"
        },
        {
          "filePath": "packages/analyzer/src/cache.ts",
          "lineRange": [
            182,
            230
          ],
          "snippet": "export function mergeDecisions(\n  cachedDecisions: ArchDecision[],\n  newDecisions: ArchDecision[],\n  changedFiles: string[],\n  deletedFiles: string[]\n): ArchDecision[] {\n  ...\n  const hasChangedEvidence = evidenceFiles.some((f) => changedSet.has(f));\n  if (hasChangedEvidence) { return false; }",
          "explanation": "Intelligent merge: removes cached decisions whose evidence files changed, keeps others"
        }
      ],
      "constraints": [
        "Cache is invalidated when file content changes (SHA-256 hash mismatch)",
        "Cache has a configurable TTL in hours",
        "Cached decisions are removed if their evidence files are modified or deleted",
        "Cache is stored at .archguard/cache.json in the project directory"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "caching",
        "incremental-analysis",
        "sha256",
        "llm-optimization",
        "file-hashing"
      ]
    },
    {
      "id": "Dh0kcWyPUS_sdhBEZIqQh",
      "title": "Composite Velocity Scoring with Configurable Weights",
      "description": "Developer velocity is calculated as a weighted composite of four dimensions: complexity-weighted effort, architectural impact, review contribution, and refactoring ratio. Weights are configurable via .archguard.yml and auto-normalized to sum to 1.0. Scores are normalized to 0-100 with rolling trend detection.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The velocity-calculator.ts explicitly defines DEFAULT_WEIGHTS for four dimensions, extracts configurable weights from config, normalizes them if they don't sum to 1.0, and combines them into a single velocity score. The determineTrend function uses a sliding window of previous scores. Each dimension has its own dedicated scoring module (effort-model.ts, impact-score.ts).",
      "evidence": [
        {
          "filePath": "packages/velocity/src/scoring/velocity-calculator.ts",
          "lineRange": [
            22,
            28
          ],
          "snippet": "const DEFAULT_WEIGHTS = {\n  complexityWeight: 0.4,\n  archImpactWeight: 0.3,\n  reviewWeight: 0.15,\n  refactoringWeight: 0.15,\n};",
          "explanation": "Default weights for the four velocity dimensions"
        },
        {
          "filePath": "packages/velocity/src/scoring/velocity-calculator.ts",
          "lineRange": [
            85,
            100
          ],
          "snippet": "const weightedEffort = (effort?.normalizedScore ?? 0) * weights.complexityWeight;\nconst architecturalImpact = (impact?.normalizedScore ?? 0) * weights.archImpactWeight;\nconst reviewContribution = calculateReviewScore(pr) * weights.reviewWeight;\nconst refactoringScore = refactoringRatio * 100 * weights.refactoringWeight;\nconst velocityScoreRaw = weightedEffort + architecturalImpact + reviewContribution + refactoringScore;",
          "explanation": "Composite scoring formula combining four weighted dimensions"
        },
        {
          "filePath": "packages/velocity/src/scoring/velocity-calculator.ts",
          "lineRange": [
            210,
            240
          ],
          "snippet": "function extractWeights(config?: ArchGuardConfig) {\n  ...\n  if (Math.abs(total - 1.0) > 0.01) {\n    return { complexityWeight: v.complexityWeight / total, ... };\n  }",
          "explanation": "Weights are auto-normalized to sum to 1.0 if config values don't"
        }
      ],
      "constraints": [
        "Velocity weights must sum to 1.0 (auto-normalized if they don't)",
        "All scores are normalized to 0-100 scale",
        "Trend detection requires at least 2 previous data points",
        "New velocity dimensions require updating the weight configuration schema"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "velocity-scoring",
        "composite-metrics",
        "configurable-weights",
        "trend-detection"
      ]
    },
    {
      "id": "02cF13qtQmOzC732EhEcL",
      "title": "Structured XML Prompts for LLM Interactions",
      "description": "LLM prompts are constructed using XML-tagged structured formats rather than plain text. The work-summary summarizer builds prompts with tags like <summary_request>, <metadata>, <activity_data>, <commits>, <pull_requests>, <velocity_metrics>, etc. This provides clear structure for the LLM to parse.",
      "category": "api",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The summarizer.ts builds elaborate XML-structured prompts with dedicated builder functions (buildCommitXml, buildPullRequestXml, buildVelocityXml, etc.). Each section is wrapped in semantic XML tags with attributes. An escapeXml helper ensures safe embedding. This is a deliberate prompt engineering pattern for Claude, which handles XML well.",
      "evidence": [
        {
          "filePath": "packages/work-summary/src/summarizer.ts",
          "lineRange": [
            170,
            210
          ],
          "snippet": "return `<summary_request>\n<metadata>\n  <developer_name>${escapeXml(developerName)}</developer_name>\n  <summary_type>${type}</summary_type>\n  ...\n</metadata>\n<activity_data>\n${commitXml}\n${prXml}\n${velocityXml}\n...\n</activity_data>\n<format_instructions>\n${templatePrompt.userPrompt}\n</format_instructions>",
          "explanation": "Full XML-structured prompt with semantic sections for LLM consumption"
        },
        {
          "filePath": "packages/work-summary/src/summarizer.ts",
          "lineRange": [
            230,
            260
          ],
          "snippet": "function buildCommitXml(data: CollectedData): string {\n  ...\n  return `<commits count=\"${data.commits.length}\" showing=\"${...}\">\n${commitEntries}\n</commits>`;",
          "explanation": "Individual XML section builders for each data type"
        }
      ],
      "constraints": [
        "LLM prompts should use XML tags for structured data sections",
        "All user-provided content must be XML-escaped before embedding in prompts",
        "Each XML section should have a dedicated builder function",
        "System prompts should include output guidelines in XML format"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "prompt-engineering",
        "xml-prompts",
        "llm-interaction",
        "structured-prompts"
      ]
    },
    {
      "id": "ej1fWboYmKwk3Qwte-nPJ",
      "title": "Router Factory Pattern for Server Routes",
      "description": "All server routes are defined as factory functions that accept a database client and return a Hono router instance. This pattern enables dependency injection of the database and consistent route composition in the main server file.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "Every route file (decisions.ts, analysis.ts, reviews.ts, velocity.ts, etc.) exports a `create*Router(db: DbClient): Hono` function. The server index.ts calls each factory and mounts the returned router. This is a consistent, deliberate pattern across all 11 route files.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/velocity.ts",
          "lineRange": [
            17,
            20
          ],
          "snippet": "export function createVelocityRouter(db: DbClient): Hono {\n  const router = new Hono();",
          "explanation": "Route factory pattern: function takes db, returns Hono router"
        },
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            103,
            114
          ],
          "snippet": "app.route('/api/decisions', createDecisionsRouter(db));\napp.route('/api/analysis', createAnalysisRouter(db));\napp.route('/api/reviews', createReviewsRouter(db));\napp.route('/api/velocity', createVelocityRouter(db));\napp.route('/api/summaries', createSummariesRouter(db));",
          "explanation": "Main server composes all route factories with the shared db client"
        }
      ],
      "constraints": [
        "All route modules must export a factory function that accepts DbClient and returns Hono",
        "Route factories should not create their own database connections",
        "Routes are mounted under /api/ prefix in the main server"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "factory-pattern",
        "dependency-injection",
        "route-composition",
        "hono"
      ]
    },
    {
      "id": "ULsCgKR5tduAzUlTb18SG",
      "title": "Middleware Chain: Rate Limiting → Auth → Org Context",
      "description": "The server applies middleware in a specific order: rate limiting first, then authentication, then organization context resolution. Public routes (webhooks, health) are mounted before the middleware chain. This ordering ensures rate limiting protects auth endpoints and org context is only resolved for authenticated users.",
      "category": "security",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The server index.ts clearly shows the ordering: health check and webhooks are mounted first, then rate limiting (`app.use('/api/*', standardLimit)`), then auth middleware, then org context middleware. The org-context.ts comment says 'Must be placed AFTER auth middleware in the middleware chain.' This is a deliberate security-conscious ordering.",
      "evidence": [
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            85,
            102
          ],
          "snippet": "// Webhook Routes (public, signature-verified)\napp.route('/api/webhooks', createWebhooksRouter(db));\n\n// Apply rate limiting to all API routes\napp.use('/api/*', standardLimit);\n\n// Apply auth middleware\napp.use('/api/*', authMiddleware(db));\n\n// Apply org context middleware\napp.use('/api/*', orgContextMiddleware(db));",
          "explanation": "Explicit middleware ordering: public routes → rate limit → auth → org context"
        },
        {
          "filePath": "packages/server/src/middleware/org-context.ts",
          "lineRange": [
            32,
            35
          ],
          "snippet": "/**\n * Must be placed AFTER auth middleware in the middleware chain.\n */",
          "explanation": "Documentation explicitly states middleware ordering requirement"
        }
      ],
      "constraints": [
        "Webhook and health routes must be mounted before the auth middleware",
        "Rate limiting must be applied before auth to protect against brute force",
        "Org context middleware must come after auth middleware",
        "New public routes must be mounted before the middleware chain"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "middleware-chain",
        "security",
        "rate-limiting",
        "auth",
        "ordering"
      ]
    },
    {
      "id": "mfxlQ6YP4ph41jx1c7Rmp",
      "title": "Recharts for Dashboard Data Visualization",
      "description": "The dashboard uses Recharts as its charting library for all data visualizations: velocity charts (LineChart), drift timelines (AreaChart), contribution charts (BarChart), violation breakdowns (BarChart/PieChart), and complexity heatmaps (custom). All chart components follow a consistent pattern with ResponsiveContainer, consistent styling, and empty state handling.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "All five chart components under components/charts/ import from 'recharts'. They share consistent styling patterns (gray axis lines, rounded tooltips, consistent font sizes). Each handles empty data with a centered message. The complexity heatmap is a custom implementation using CSS grid rather than Recharts, showing the team chose Recharts for standard charts but custom rendering for specialized visualizations.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/components/charts/velocity-chart.tsx",
          "lineRange": [
            3,
            12
          ],
          "snippet": "import { CartesianGrid, Legend, Line, LineChart, ResponsiveContainer, Tooltip, XAxis, YAxis } from 'recharts';",
          "explanation": "Velocity chart uses Recharts LineChart"
        },
        {
          "filePath": "packages/dashboard/src/components/charts/drift-timeline.tsx",
          "lineRange": [
            3,
            12
          ],
          "snippet": "import { Area, AreaChart, CartesianGrid, ReferenceLine, ResponsiveContainer, Tooltip, XAxis, YAxis } from 'recharts';",
          "explanation": "Drift timeline uses Recharts AreaChart"
        },
        {
          "filePath": "packages/dashboard/src/components/charts/violation-breakdown.tsx",
          "lineRange": [
            3,
            13
          ],
          "snippet": "import { Bar, BarChart, Cell, Legend, Pie, PieChart, ResponsiveContainer, Tooltip, XAxis, YAxis } from 'recharts';",
          "explanation": "Violation breakdown supports both BarChart and PieChart variants"
        }
      ],
      "constraints": [
        "Standard charts should use Recharts components",
        "All charts must handle empty data states gracefully",
        "Chart styling should follow the established pattern (gray axes, rounded tooltips, consistent fonts)",
        "Charts must be wrapped in ResponsiveContainer for responsive sizing"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "recharts",
        "data-visualization",
        "charts",
        "dashboard"
      ]
    },
    {
      "id": "3hiboFlYXrLM4hyCtojGf",
      "title": "Custom React Hooks for Data Fetching with Loading/Error States",
      "description": "The dashboard implements custom React hooks (useDecisions, useReviews, useVelocity, useSSE) that encapsulate API calls with consistent loading, error, and data state management. Each hook returns a standardized shape with data, loading, error, and refetch capabilities.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The hooks/ directory contains 4 custom hooks that all follow the same pattern: useState for data/loading/error, useCallback for fetch functions, useEffect for initial load, and a consistent return shape. This is a deliberate data-fetching abstraction layer rather than using a library like React Query.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/hooks/use-velocity.ts",
          "lineRange": [
            1,
            113
          ],
          "snippet": "export function useTeamVelocity() {\n  const [data, setData] = useState<TeamVelocityData | null>(null);\n  const [loading, setLoading] = useState(true);\n  const [error, setError] = useState<string | null>(null);",
          "explanation": "Custom hook with consistent loading/error/data state pattern"
        },
        {
          "filePath": "packages/dashboard/src/hooks/use-decisions.ts",
          "lineRange": [
            1,
            122
          ],
          "snippet": "export function useDecisions(filters?: DecisionFilters) { ... }\nexport function useDecision(id: string) { ... }",
          "explanation": "Decisions hook provides both list and detail fetching"
        }
      ],
      "constraints": [
        "Data fetching should be encapsulated in custom hooks under hooks/",
        "Hooks must manage loading, error, and data states consistently",
        "No external data-fetching library (React Query, SWR) is used — hooks are hand-rolled",
        "Hooks should use the centralized API client from lib/api.ts"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "react-hooks",
        "data-fetching",
        "state-management",
        "dashboard"
      ]
    },
    {
      "id": "Mmgi6fZ8YJ2Te-ry3VStE",
      "title": "Structured Logging with File Output and Global Singleton",
      "description": "The system uses a custom structured logger (core/logger.ts) that writes JSON-formatted log entries to .archguard/logs/ with timestamped filenames. It supports specialized log methods for LLM operations, scan progress, and JSON parse failures. A global singleton pattern with a Proxy-based no-op fallback ensures safe usage across library code.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "The Logger class writes to both an in-memory array and a file stream. It has specialized methods (llmRequest, llmResponse, llmError, jsonParseFailure, scanProgress) indicating it was designed specifically for this application's needs. The getLogger() function returns a Proxy-based no-op stub when no logger is initialized, allowing library code to log safely without initialization.",
      "evidence": [
        {
          "filePath": "packages/core/src/logger.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * Structured logger for ArchGuard.\n * Writes debug logs to `.archguard/logs/` automatically so users can\n * share log files when filing issues.\n */",
          "explanation": "Logger designed for user-facing debugging and issue reporting"
        },
        {
          "filePath": "packages/core/src/logger.ts",
          "lineRange": [
            240,
            265
          ],
          "snippet": "export function getLogger(): Logger {\n  if (!globalLogger) {\n    return new Proxy({} as Logger, {\n      get(_target, prop) {\n        if (prop === 'filePath') return '';\n        if (prop === 'allEntries') return [];\n        if (prop === 'close') return () => {};\n        return () => {};\n      },\n    }) as Logger;\n  }\n  return globalLogger;\n}",
          "explanation": "Proxy-based no-op fallback for safe logging in library code without initialization"
        },
        {
          "filePath": "packages/core/src/logger.ts",
          "lineRange": [
            115,
            155
          ],
          "snippet": "llmRequest(opts: { operation: string; model: string; inputTokens: number; ... }): void { ... }\nllmResponse(opts: { ... latencyMs: number; cost: number; cacheHit: boolean; }): void { ... }\nllmError(opts: { ... statusCode?: number; rawResponse?: string; ... }): void { ... }",
          "explanation": "Specialized logging methods for LLM operations with structured data"
        }
      ],
      "constraints": [
        "Logger must be initialized via initLogger() at CLI startup",
        "Library code should use getLogger() which returns a safe no-op if not initialized",
        "Log files are written to .archguard/logs/ with timestamped filenames",
        "LLM operations should use the specialized llmRequest/llmResponse/llmError methods"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "logging",
        "structured-logging",
        "singleton",
        "debugging",
        "file-output"
      ]
    },
    {
      "id": "ji_ca-wLBpKVMdKHnlKhm",
      "title": "MCP Server with Tools and Resources Pattern",
      "description": "The system implements a Model Context Protocol (MCP) server that exposes architectural knowledge as tools (get-decisions, check-pattern, suggest-approach, get-dependencies) and resources (decisions, patterns). This enables AI agents to query architectural decisions and check compliance programmatically.",
      "category": "api",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "The mcp-server package imports from @modelcontextprotocol/sdk and organizes its functionality into tools/ and resources/ directories. Each tool has an input schema (JSON Schema format) and an execute function. The index.ts registers tools and resources with the MCP server and supports multiple transport types (stdio, SSE, HTTP). This is a deliberate integration point for AI agent ecosystems.",
      "evidence": [
        {
          "filePath": "packages/mcp-server/src/tools/get-dependencies.ts",
          "lineRange": [
            1,
            40
          ],
          "snippet": "export interface GetDependenciesInput { target: string; depth?: number; }\nexport const getDependenciesInputSchema = {\n  type: 'object' as const,\n  properties: {\n    target: { type: 'string' as const, description: '...' },\n    depth: { type: 'number' as const, ... },\n  },\n  required: ['target'] as const,\n};",
          "explanation": "MCP tool with JSON Schema input definition"
        },
        {
          "filePath": "packages/mcp-server/src/index.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';\nimport { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';",
          "explanation": "Uses official MCP SDK with multiple transport support"
        }
      ],
      "constraints": [
        "MCP tools must define JSON Schema input schemas",
        "Tools must have execute functions that return structured results",
        "Resources must be read-only data providers",
        "Multiple transport types (stdio, SSE, HTTP) must be supported"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "mcp",
        "model-context-protocol",
        "ai-agents",
        "tools",
        "resources"
      ]
    },
    {
      "id": "s_ZKLtt0XZJk1rXR0s38B",
      "title": "Cron-Based Scheduled Summary Generation",
      "description": "Work summaries are generated on configurable cron schedules via the SummaryScheduler class. It supports four summary types (standup, one_on_one, sprint_review, progress_report) with automatic period computation. Jobs can be dynamically added/removed and manually triggered.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The SummaryScheduler class uses the 'cron' library to manage scheduled jobs. It reads schedules from .archguard.yml config, creates CronJob instances for each, and provides lifecycle management (start, stop, addJob, removeJob, triggerNow). The computePeriod function automatically determines the time range based on summary type. This is a deliberate scheduling system, not ad-hoc.",
      "evidence": [
        {
          "filePath": "packages/work-summary/src/scheduler.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * Cron-based auto-generation scheduler for work summaries.\n * Uses the cron library to manage scheduled summary generation\n * based on configuration from the .archguard.yml summaries section.\n */\nimport { CronJob } from 'cron';",
          "explanation": "Cron-based scheduler for automated summary generation"
        },
        {
          "filePath": "packages/work-summary/src/scheduler.ts",
          "lineRange": [
            260,
            326
          ],
          "snippet": "function computePeriod(type: SummaryType, sprintLengthDays = 14) {\n  switch (type) {\n    case 'standup': { ... yesterday ... }\n    case 'one_on_one': { ... weekAgo ... }\n    case 'sprint_review': { ... sprintLengthDays ... }\n    case 'progress_report': { ... monthAgo ... }",
          "explanation": "Automatic period computation based on summary type"
        }
      ],
      "constraints": [
        "Summary schedules are configured in .archguard.yml under summaries.schedules",
        "Each schedule must specify a summary type and cron expression",
        "Sprint length is configurable via summaries.sprintLengthDays",
        "Scheduler requires an LLM client for summary generation"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "cron",
        "scheduling",
        "work-summaries",
        "automation"
      ]
    },
    {
      "id": "_ISR2lvq030K_rwvMrRlL",
      "title": "Tiered Rate Limiting with In-Memory Store",
      "description": "The server implements rate limiting with multiple tiers (standard, strict, analysis) using an in-memory sliding window approach. Rate limit headers (X-RateLimit-*) are exposed via CORS. Different endpoints get different limits based on their computational cost.",
      "category": "security",
      "status": "detected",
      "confidence": 0.92,
      "reasoning": "The rate-limit.ts exports three pre-configured limiters: standardLimit, strictLimit, and analysisLimit. The server index.ts applies standardLimit globally and exposes rate limit headers in CORS config. Route files like reviews.ts and analysis.ts apply stricter limits to expensive endpoints. The implementation uses an in-memory Map with periodic cleanup.",
      "evidence": [
        {
          "filePath": "packages/server/src/middleware/rate-limit.ts",
          "lineRange": [
            1,
            130
          ],
          "snippet": "export const standardLimit = rateLimit(...);\nexport const strictLimit = rateLimit(...);\nexport const analysisLimit = rateLimit(...);",
          "explanation": "Three rate limit tiers for different endpoint categories"
        },
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            67,
            73
          ],
          "snippet": "exposeHeaders: ['X-RateLimit-Limit', 'X-RateLimit-Remaining', 'X-RateLimit-Reset'],",
          "explanation": "CORS config exposes rate limit headers to the dashboard"
        }
      ],
      "constraints": [
        "All API routes have at least standard rate limiting",
        "Expensive endpoints (analysis, review triggers) must use stricter limits",
        "Rate limit state is in-memory and resets on server restart",
        "Rate limit headers must be exposed via CORS for client-side handling"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "rate-limiting",
        "security",
        "middleware",
        "tiered-limits"
      ]
    },
    {
      "id": "nqKR76pU1dcy17FGZeJfg",
      "title": "SAML SSO Support for Enterprise Authentication",
      "description": "The server implements SAML-based Single Sign-On with per-organization SAML configuration stored in the database. It supports SP metadata generation, SSO redirect URL building, and SAML assertion handling. SAML configs include IdP entity ID, SSO URL, certificate, and a default role for new users.",
      "category": "security",
      "status": "detected",
      "confidence": 0.91,
      "reasoning": "The auth/saml.ts file implements full SAML SSO flow with SP metadata generation, SSO redirect, and callback handling. The database schema has a dedicated samlConfigs table with IdP configuration fields. The server mounts SAML routes at /api/auth/saml/:orgSlug/. The dashboard has a dedicated SSO page. This is clearly an intentional enterprise feature.",
      "evidence": [
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            89,
            91
          ],
          "snippet": "app.get('/api/auth/saml/:orgSlug/login', (c) => handleSamlLogin(c, db));\napp.get('/api/auth/saml/:orgSlug/metadata', (c) => handleSamlMetadata(c));",
          "explanation": "SAML routes mounted as public endpoints with org-specific paths"
        },
        {
          "filePath": "packages/core/src/db/schema.ts",
          "lineRange": [
            218,
            236
          ],
          "snippet": "export const samlConfigs = sqliteTable('saml_configs', {\n  ...\n  idpEntityId: text('idp_entity_id').notNull(),\n  idpSsoUrl: text('idp_sso_url').notNull(),\n  idpCertificate: text('idp_certificate').notNull(),\n  spEntityId: text('sp_entity_id').notNull(),\n  defaultRole: text('default_role').notNull().default('member'),\n  enabled: integer('enabled', { mode: 'boolean' }).notNull().default(false),",
          "explanation": "Dedicated SAML configuration table with per-org IdP settings"
        }
      ],
      "constraints": [
        "SAML configuration is per-organization",
        "New SAML users are assigned the defaultRole from the org's SAML config",
        "SAML routes must remain public (before auth middleware)",
        "SP metadata must be generated dynamically based on the server's base URL"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "saml",
        "sso",
        "enterprise-auth",
        "identity-provider"
      ]
    },
    {
      "id": "FiZJ78YkIr06ardeps9D9",
      "title": "Slack Integration with Block Kit UI and Slash Commands",
      "description": "The system integrates with Slack via @slack/bolt for app events and @slack/web-api for notifications. It provides slash commands (/archguard status, decisions, review, summary, blockers) and sends rich Block Kit formatted messages for violations, drift alerts, velocity digests, and blocker notifications.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The integrations/slack/ directory has 4 files: app.ts (Bolt app setup), commands.ts (slash command handler), blocks.ts (Block Kit builders with 692 lines), and notifications.ts (message sending). The blocks.ts file has 7 different block builder functions for different notification types. The commands.ts parses subcommands and routes to handlers. This is a comprehensive, intentional Slack integration.",
      "evidence": [
        {
          "filePath": "packages/integrations/src/slack/app.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "import { App } from '@slack/bolt';\nimport { ... } from './commands.js';",
          "explanation": "Slack Bolt app with command handler integration"
        },
        {
          "filePath": "packages/integrations/src/slack/blocks.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "export function buildViolationAlertBlocks(...)\nexport function buildDriftAlertBlocks(...)\nexport function buildVelocityDigestBlocks(...)\nexport function buildWorkSummaryBlocks(...)\nexport function buildBlockerAlertBlocks(...)",
          "explanation": "7 Block Kit builder functions for different notification types"
        }
      ],
      "constraints": [
        "Slack messages must use Block Kit format for rich formatting",
        "Slash commands follow the /archguard <subcommand> pattern",
        "Notification functions require a Slack Web API client",
        "Block builders must handle empty data gracefully"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "slack",
        "block-kit",
        "slash-commands",
        "notifications",
        "integrations"
      ]
    },
    {
      "id": "Ph0Uo_oRW8BeEQSzBgLLO",
      "title": "Multi-Format Review Output (Terminal, GitHub PR, Bitbucket PR, JSON)",
      "description": "The reviewer package implements a formatter strategy pattern with four output formats: terminal (colored CLI output), GitHub PR (inline comments + check annotations), Bitbucket PR (code insights + annotations), and JSON (structured machine-readable output). Each formatter is a separate module under formatters/.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "The reviewer/formatters/ directory has 4 files, each exporting format functions for a specific target. The reviewer/index.ts re-exports all formatters. The CLI commands use formatForTerminal, webhook handlers use formatForGitHubPr/formatForBitbucketPr, and the API uses formatForJson. This is a deliberate strategy pattern for multi-target output.",
      "evidence": [
        {
          "filePath": "packages/reviewer/src/index.ts",
          "lineRange": [
            1,
            50
          ],
          "snippet": "export { formatForTerminal } from './formatters/terminal.js';\nexport { formatForGitHubPr, formatForGitHubFull, ... } from './formatters/github-pr.js';\nexport { formatForBitbucketPr, formatForBitbucketFull, ... } from './formatters/bitbucket-pr.js';\nexport { formatForJson, buildJsonOutput, ... } from './formatters/json.js';",
          "explanation": "Four formatter modules re-exported from the reviewer package"
        }
      ],
      "constraints": [
        "New output formats should be added as new formatter modules",
        "All formatters must accept ReviewResult and produce their target format",
        "GitHub and Bitbucket formatters must produce platform-specific structures (inline comments, annotations)",
        "Terminal formatter must handle color output for CLI usage"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "formatter-pattern",
        "multi-format",
        "strategy-pattern",
        "code-review"
      ]
    },
    {
      "id": "9Zg7n635OaXA4LVOkzo77",
      "title": "User Section Preservation in Generated Context Files",
      "description": "Generated context files (for AI assistants) include HTML comment markers (<!-- archguard:user-start --> / <!-- archguard:user-end -->) that delimit user-editable sections. On regeneration, user content between these markers is preserved and re-inserted into the new output.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The templates.ts file defines USER_SECTION_START and USER_SECTION_END constants, with extractUserSections and insertUserSections functions. extractUserSections parses existing content to find user sections, and insertUserSections appends them to newly generated content. This is a deliberate UX decision to prevent users from losing manual additions when files are regenerated.",
      "evidence": [
        {
          "filePath": "packages/context-sync/src/templates.ts",
          "lineRange": [
            188,
            237
          ],
          "snippet": "const USER_SECTION_START = '<!-- archguard:user-start -->';\nconst USER_SECTION_END = '<!-- archguard:user-end -->';\n\nexport function extractUserSections(content: string): string | null {\n  const startIdx = content.indexOf(USER_SECTION_START);\n  ...\n}\n\nexport function insertUserSections(generatedContent: string, userContent: string | null): string {\n  ...\n}",
          "explanation": "User section extraction and insertion for preserving manual edits across regeneration"
        }
      ],
      "constraints": [
        "Generated context files must include user section markers",
        "Regeneration must extract and re-insert user sections from existing files",
        "User section markers must not be modified or removed by generators",
        "Content between markers is opaque to the generation system"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "user-sections",
        "content-preservation",
        "regeneration",
        "context-files"
      ]
    },
    {
      "id": "Y4T_MirGytOt8FxXEcn2M",
      "title": "Graceful Server Shutdown with Resource Cleanup",
      "description": "The server implements graceful shutdown handling for SIGTERM and SIGINT signals, closing job queues/workers first, then the HTTP server, with a 10-second forced exit timeout as a safety net.",
      "category": "deployment",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The server index.ts defines a shutdown function that sequentially closes job queues (shutdownQueues), then the HTTP server, with a 10-second timeout for forced exit. Both SIGTERM and SIGINT are handled. This is a deliberate production-readiness pattern for containerized deployments.",
      "evidence": [
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            195,
            220
          ],
          "snippet": "async function shutdown(signal: string): Promise<void> {\n  console.log(`\\n[server] Received ${signal}, shutting down gracefully...`);\n  try {\n    await shutdownQueues();\n  } catch (error) { ... }\n  server.close(() => { process.exit(0); });\n  setTimeout(() => { process.exit(1); }, 10_000);\n}\nprocess.on('SIGTERM', () => shutdown('SIGTERM'));\nprocess.on('SIGINT', () => shutdown('SIGINT'));",
          "explanation": "Graceful shutdown with queue cleanup, server close, and forced exit timeout"
        }
      ],
      "constraints": [
        "Job queues must be closed before the HTTP server",
        "Forced exit after 10 seconds prevents hanging on shutdown",
        "Both SIGTERM and SIGINT must be handled for container and CLI usage"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "graceful-shutdown",
        "signal-handling",
        "production-readiness",
        "containers"
      ]
    },
    {
      "id": "I7Z6j0ityxp5G0jed7zOj",
      "title": "Robert C. Martin Coupling Metrics in Dependency Analysis",
      "description": "The dependency mapper calculates coupling metrics based on Robert C. Martin's package metrics: afferent coupling (Ca), efferent coupling (Ce), instability (I = Ce/(Ca+Ce)), abstractness (A), and distance from the main sequence (D = |A+I-1|). These metrics are used in reports and impact scoring.",
      "category": "data",
      "status": "detected",
      "confidence": 0.92,
      "reasoning": "The dependency-mapper.ts exports DependencyGraph with couplingMetrics (Map of CouplingMetrics), and the JSON report includes avgInstability, avgDistance, and moduleMetrics. The core types.ts defines CouplingMetrics with afferentCoupling, efferentCoupling, instability, abstractness, and distanceFromMainSequence. This is a deliberate choice to use well-established software engineering metrics.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/reporters/json.ts",
          "lineRange": [
            26,
            35
          ],
          "snippet": "dependencies: {\n  totalModules: number;\n  circularDeps: number;\n  avgCoupling: number;\n  avgInstability: number;\n  avgDistance: number;\n  couplingHotspots: Array<{ file: string; score: number }>;\n  moduleMetrics: Array<{ file: string; metrics: CouplingMetrics }>;",
          "explanation": "JSON report includes Martin metrics: instability, distance, and per-module coupling metrics"
        },
        {
          "filePath": "packages/analyzer/src/reporters/json.ts",
          "lineRange": [
            60,
            68
          ],
          "snippet": "const moduleMetrics = Array.from(graph.couplingMetrics.entries())\n  .sort(([, a], [, b]) => b.distanceFromMainSequence - a.distanceFromMainSequence)\n  .map(([file, metrics]) => ({ file, metrics }));",
          "explanation": "Module metrics sorted by distance from main sequence"
        }
      ],
      "constraints": [
        "Coupling metrics follow Robert C. Martin's package metrics definitions",
        "Instability is calculated as Ce/(Ca+Ce)",
        "Distance from main sequence is |A+I-1|",
        "Metrics are available per-module in the dependency graph"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:18:14.473Z",
      "tags": [
        "coupling-metrics",
        "robert-martin",
        "software-metrics",
        "dependency-analysis"
      ]
    },
    {
      "id": "krOlP1zOIicc5TessOVEc",
      "title": "Hono as HTTP Framework with Factory Router Pattern",
      "description": "The server package uses Hono as the HTTP framework. Each route module exports a factory function (e.g., createDecisionsRouter, createTeamsRouter) that receives a database client and returns a configured Hono router instance. These are composed in the main server index.ts.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "Every route file follows the exact same pattern: import Hono, export a createXxxRouter(db: DbClient): Hono function, create a new Hono() instance, define routes, and return the router. This is consistent across all 11 route files, indicating a deliberate architectural convention. The factory pattern enables dependency injection of the DB client.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/decisions.ts",
          "lineRange": [
            27,
            30
          ],
          "snippet": "export function createDecisionsRouter(db: DbClient): Hono {\n  const router = new Hono();",
          "explanation": "Factory function pattern for decisions router - receives DB client, returns configured Hono router"
        },
        {
          "filePath": "packages/server/src/routes/teams.ts",
          "lineRange": [
            21,
            24
          ],
          "snippet": "export function createTeamsRouter(db: DbClient): Hono {\n  const router = new Hono();",
          "explanation": "Same factory pattern for teams router"
        },
        {
          "filePath": "packages/server/src/routes/reviews.ts",
          "lineRange": [
            22,
            25
          ],
          "snippet": "export function createReviewsRouter(db: DbClient): Hono {\n  const router = new Hono();",
          "explanation": "Same factory pattern for reviews router"
        },
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            1,
            230
          ],
          "snippet": "import { createDecisionsRouter } from './routes/decisions.js'; ... import { createTeamsRouter } from './routes/teams.js';",
          "explanation": "Main server file imports and composes all router factories"
        }
      ],
      "constraints": [
        "All route modules must export a factory function that accepts DbClient",
        "Route handlers must not create their own database connections",
        "New route modules must follow the createXxxRouter naming convention",
        "Hono is the sole HTTP framework - no Express or Fastify"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.600Z",
      "tags": [
        "hono",
        "factory-pattern",
        "dependency-injection",
        "router-composition"
      ]
    },
    {
      "id": "cBYGD3swL7NGRjziN9AWO",
      "title": "Permission-Based RBAC Middleware for API Authorization",
      "description": "The server implements a role-based access control system where each API endpoint is protected by a requirePermission() middleware that checks fine-grained permissions (e.g., 'decisions:read', 'team:invite', 'settings:write'). Roles (owner, admin, member, viewer) map to permission sets, and role hierarchy is enforced for operations like inviting or removing members.",
      "category": "security",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "Every single route handler in the server uses requirePermission() as middleware with specific permission strings. The auth module defines ROLE_PERMISSIONS mapping, role hierarchy, and the RBAC middleware. The teams route even enforces that you can't invite someone with a higher role than your own. This is a comprehensive, intentional security architecture.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/decisions.ts",
          "lineRange": [
            33,
            33
          ],
          "snippet": "router.get('/', requirePermission('decisions:read'), async (c) => {",
          "explanation": "Every decisions endpoint uses requirePermission with specific permission strings"
        },
        {
          "filePath": "packages/server/src/routes/teams.ts",
          "lineRange": [
            85,
            92
          ],
          "snippet": "if (!isRoleAtLeast(user.role, role)) {\n      return c.json({ error: 'Cannot invite a user with a higher role than your own' }, 403);\n    }",
          "explanation": "Role hierarchy enforcement - users can't escalate privileges beyond their own level"
        },
        {
          "filePath": "packages/server/src/auth/rbac.ts",
          "lineRange": [
            1,
            106
          ],
          "snippet": "export function requirePermission(...) { ... } export function requireRole(...) { ... } export function requireAnyPermission(...) { ... }",
          "explanation": "RBAC module provides three middleware variants: single permission, role check, and any-of-permissions"
        },
        {
          "filePath": "packages/server/src/auth/roles.ts",
          "lineRange": [
            1,
            55
          ],
          "snippet": "export const PERMISSIONS ... export const ROLE_HIERARCHY ... export function isRoleAtLeast(...)",
          "explanation": "Centralized role and permission definitions with hierarchy comparison"
        }
      ],
      "constraints": [
        "Every API endpoint must use requirePermission() or requireRole() middleware",
        "New permissions must be added to ROLE_PERMISSIONS mapping in the auth module",
        "Role hierarchy must be respected for all privilege-escalation operations",
        "Permission strings follow the 'resource:action' naming convention"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.600Z",
      "tags": [
        "rbac",
        "authorization",
        "middleware",
        "role-hierarchy",
        "fine-grained-permissions"
      ]
    },
    {
      "id": "EfzVuLOIewFjTPfrEODft",
      "title": "Multi-Tenant Organization-Scoped Data Access",
      "description": "All server routes enforce organization-level data isolation. The orgId is extracted from the authenticated user's context and used to scope all database queries. Routes verify that resources (repos, decisions, reviews) belong to the requesting user's organization before allowing access.",
      "category": "security",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "Every route handler extracts orgId from context (c.get('orgId')) and uses it to filter queries. The repos route checks repoRows[0].orgId !== orgId before allowing access. The org-context middleware resolves the organization context. This is a systematic, intentional multi-tenancy pattern applied consistently across all routes.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/repos.ts",
          "lineRange": [
            34,
            37
          ],
          "snippet": "const orgId = c.get('orgId') as string;\n\n    const repoRows = await db\n      .select()\n      .from(schema.repositories)\n      .where(eq(schema.repositories.orgId, orgId))",
          "explanation": "Repos are always scoped to the authenticated user's organization"
        },
        {
          "filePath": "packages/server/src/routes/reviews.ts",
          "lineRange": [
            30,
            37
          ],
          "snippet": "const orgId = c.get('orgId') as string;\n    ...\n    const orgRepos = await db\n      .select({ id: schema.repositories.id })\n      .from(schema.repositories)\n      .where(eq(schema.repositories.orgId, orgId));",
          "explanation": "Reviews are filtered through org-scoped repositories"
        },
        {
          "filePath": "packages/server/src/middleware/org-context.ts",
          "lineRange": [
            1,
            103
          ],
          "snippet": "export function orgContextMiddleware(...) { ... } export function getOrgContext(...) { ... }",
          "explanation": "Dedicated middleware for resolving and attaching organization context to requests"
        },
        {
          "filePath": "packages/server/src/routes/settings.ts",
          "lineRange": [
            27,
            30
          ],
          "snippet": "const orgId = c.get('orgId') as string;\n\n    const orgRows = await db\n      .select()\n      .from(schema.organizations)\n      .where(eq(schema.organizations.id, orgId))",
          "explanation": "Settings are scoped to the authenticated organization"
        }
      ],
      "constraints": [
        "All database queries must be scoped to the authenticated user's orgId",
        "Cross-organization data access is never permitted",
        "Resource ownership must be verified before mutation operations",
        "The orgId must come from the authenticated session, never from user input"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.600Z",
      "tags": [
        "multi-tenancy",
        "data-isolation",
        "organization-scoping",
        "security"
      ]
    },
    {
      "id": "kTcbmm_epeC_EMkf2oYaz",
      "title": "Drizzle ORM with SQLite for Data Persistence",
      "description": "The application uses Drizzle ORM with better-sqlite3 as the database. The schema is defined declaratively in core/src/db/schema.ts with 16 tables. All route handlers use Drizzle's query builder (eq, and, desc, etc.) for type-safe database operations. JSON fields are stored as text and parsed/stringified at the application layer.",
      "category": "data",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The core/src/db/ directory contains schema.ts (Drizzle table definitions), index.ts (SQLite client creation), and seed.ts. All route handlers import from drizzle-orm and use its query builder. JSON fields like constraints, tags, and settings are stored as text and manually parsed with JSON.parse(). This is a deliberate choice of SQLite + Drizzle for simplicity.",
      "evidence": [
        {
          "filePath": "packages/core/src/db/schema.ts",
          "lineRange": [
            1,
            236
          ],
          "snippet": "import { sqliteTable, text, integer, real } from 'drizzle-orm/sqlite-core'; ... export const organizations = ... export const decisions = ... export const reviews = ...",
          "explanation": "16 tables defined using Drizzle's SQLite schema builder"
        },
        {
          "filePath": "packages/core/src/db/index.ts",
          "lineRange": [
            1,
            257
          ],
          "snippet": "import { drizzle } from 'drizzle-orm/better-sqlite3'; import Database from 'better-sqlite3'; ... export function initializeDatabase(...)",
          "explanation": "SQLite database initialization with better-sqlite3 driver"
        },
        {
          "filePath": "packages/server/src/routes/decisions.ts",
          "lineRange": [
            95,
            99
          ],
          "snippet": "const decisions = paginated.map((d) => ({\n      ...d,\n      constraints: JSON.parse(d.constraints ?? '[]'),\n      relatedDecisions: JSON.parse(d.relatedDecisions ?? '[]'),\n      tags: JSON.parse(d.tags ?? '[]'),\n    }));",
          "explanation": "JSON fields stored as text in SQLite, parsed at application layer"
        }
      ],
      "constraints": [
        "All database schema changes must go through Drizzle schema definitions",
        "JSON/array fields must be serialized to text for SQLite storage",
        "Database queries must use Drizzle's type-safe query builder",
        "SQLite is the only supported database engine"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "drizzle-orm",
        "sqlite",
        "better-sqlite3",
        "type-safe-queries"
      ]
    },
    {
      "id": "PQe1tUSfBuWwkvyra1tmb",
      "title": "Multi-Format AI Context File Generation (Context Sync)",
      "description": "The context-sync package generates AI assistant context files in 7+ formats: .cursorrules (Cursor), CLAUDE.md (Claude Code), agents.md, .github/copilot-instructions.md (GitHub Copilot), .windsurfrules (Windsurf), .kiro/steering.md (Kiro), and custom templates. Each generator follows the same interface pattern (decisions + config → string) and can optionally use LLM-powered intelligent compression.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "Seven dedicated generator files in context-sync/src/generators/ all follow the identical pattern: import ArchDecision and ArchGuardConfig types, import shared template utilities, export a single generate function. The SyncEngine orchestrates them. The llm-sync.ts provides an alternative LLM-powered generation path. This is clearly a deliberate strategy to support the entire AI coding assistant ecosystem.",
      "evidence": [
        {
          "filePath": "packages/context-sync/src/generators/claude-md.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * Generator for CLAUDE.md files.\n * Produces markdown optimized for Claude Code's project context understanding.\n * CLAUDE.md is read automatically by Claude Code when working in a repository.\n */",
          "explanation": "Each generator is documented with its target AI tool and file format"
        },
        {
          "filePath": "packages/context-sync/src/generators/kiro.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * Generator for .kiro/steering.md files.\n * Produces markdown optimized for Kiro IDE's steering file format.\n */",
          "explanation": "Even newer AI tools like Kiro have dedicated generators, showing active maintenance of this strategy"
        },
        {
          "filePath": "packages/context-sync/src/llm-sync.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "/**\n * LLM-powered context file generation.\n *\n * Instead of mechanically dumping every decision into a template,\n * sends all decisions to Opus which intelligently compresses,\n * prioritizes, and organizes them into an optimally dense context\n * file that fits within the configured token budget.\n */",
          "explanation": "LLM-powered alternative to template-based generation, showing two-tier approach"
        }
      ],
      "constraints": [
        "Each AI tool format must have its own dedicated generator file in generators/",
        "All generators must accept (decisions: ArchDecision[], config: ArchGuardConfig) and return string",
        "Generators must use shared template utilities from templates.ts for consistency",
        "LLM-powered sync is optional and controlled by config.sync.useLlm",
        "Generated files must include 'do not edit' markers and preserve user sections"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "context-sync",
        "ai-assistants",
        "code-generation",
        "multi-format",
        "cursor",
        "copilot",
        "claude-code"
      ]
    },
    {
      "id": "_3LxLQg8dVq-lQk09Bt44",
      "title": "Tailwind CSS with Custom Brand Design System",
      "description": "The dashboard uses Tailwind CSS with a custom 'brand' color palette (indigo-based, 50-950 shades), CSS custom properties for sidebar theming, custom animations (fade-in, slide-in, slide-up), and consistent utility class patterns (btn-primary, btn-secondary, btn-ghost, input-field, card, card-padded). Components use the cn() utility (clsx + tailwind-merge) for conditional class composition.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The tailwind.config.ts defines a comprehensive brand color palette, sidebar CSS variables, custom font sizes (2xs), and animations. Every component uses cn() for class composition and consistent utility class names like btn-primary, card-padded, input-field. The brand colors are used extensively throughout all dashboard components.",
      "evidence": [
        {
          "filePath": "packages/dashboard/tailwind.config.ts",
          "lineRange": [
            10,
            40
          ],
          "snippet": "brand: {\n          50: '#eef2ff',\n          ...\n          950: '#1e1b4b',\n        },\n      },\n      ...\n      animation: {\n        'fade-in': 'fadeIn 0.3s ease-in-out',\n        'slide-in': 'slideIn 0.3s ease-out',\n        'slide-up': 'slideUp 0.2s ease-out',\n      },",
          "explanation": "Custom brand palette and animation system defined in Tailwind config"
        },
        {
          "filePath": "packages/dashboard/src/lib/utils.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import { clsx } from 'clsx'; import { twMerge } from 'tailwind-merge'; export function cn(...inputs) { return twMerge(clsx(inputs)); }",
          "explanation": "cn() utility combining clsx and tailwind-merge for conditional class composition"
        },
        {
          "filePath": "packages/dashboard/src/components/layout/header.tsx",
          "lineRange": [
            55,
            65
          ],
          "snippet": "searchFocused ? 'border-brand-300 bg-white ring-2 ring-brand-100' : 'border-gray-200 hover:border-gray-300'",
          "explanation": "Consistent use of brand colors and cn() for conditional styling throughout components"
        }
      ],
      "constraints": [
        "All dashboard styling must use Tailwind utility classes",
        "Brand colors must be used instead of raw color values",
        "Conditional class composition must use the cn() utility",
        "Custom component classes (btn-primary, card, etc.) must be used for consistency"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "tailwind-css",
        "design-system",
        "brand-colors",
        "utility-classes"
      ]
    },
    {
      "id": "WBMEHZQQHDGN6PmhzRAo0",
      "title": "Rate Limiting Middleware for Sensitive API Endpoints",
      "description": "The server implements a custom rate limiting middleware that is selectively applied to expensive or abuse-prone endpoints like analysis triggers and review triggers. The middleware supports configurable max requests, time windows, and custom messages, with pre-built presets (standardLimit, strictLimit, analysisLimit).",
      "category": "security",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The rate-limit.ts middleware is imported and applied specifically to the /trigger endpoints for analysis (max 5/min) and reviews (max 10/min). It's not applied globally but selectively, indicating intentional protection of expensive operations. The middleware exports presets for different use cases.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/analysis.ts",
          "lineRange": [
            32,
            34
          ],
          "snippet": "router.post(\n    '/trigger',\n    requirePermission('analysis:trigger'),\n    rateLimit({ max: 5, windowMs: 60_000, message: 'Analysis trigger rate limited' }),",
          "explanation": "Analysis trigger rate limited to 5 requests per minute"
        },
        {
          "filePath": "packages/server/src/routes/reviews.ts",
          "lineRange": [
            108,
            110
          ],
          "snippet": "router.post(\n    '/trigger',\n    requirePermission('reviews:trigger'),\n    rateLimit({ max: 10, windowMs: 60_000, message: 'Review trigger rate limited' }),",
          "explanation": "Review trigger rate limited to 10 requests per minute"
        },
        {
          "filePath": "packages/server/src/middleware/rate-limit.ts",
          "lineRange": [
            1,
            130
          ],
          "snippet": "export function rateLimit(options: RateLimitOptions) { ... } export const standardLimit = ... export const strictLimit = ... export const analysisLimit = ...",
          "explanation": "Custom rate limiting middleware with configurable presets"
        }
      ],
      "constraints": [
        "Expensive or abuse-prone endpoints must have rate limiting applied",
        "Rate limits should be configured per-endpoint based on operation cost",
        "Rate limit middleware must be composable with other middleware (auth, RBAC)"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "rate-limiting",
        "api-protection",
        "middleware",
        "abuse-prevention"
      ]
    },
    {
      "id": "nVvqYIivup5-CNveAkyDD",
      "title": "Anthropic Claude as the LLM Provider",
      "description": "The codebase exclusively uses Anthropic's Claude API for all LLM-powered features: decision extraction, code review, summary generation, and context sync. The core/src/llm.ts module wraps the @anthropic-ai/sdk with cost tracking, caching, rate limit handling, and model selection per operation type.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The core llm.ts imports @anthropic-ai/sdk exclusively. The analyzer's decision-extractor.ts imports from @anthropic-ai/sdk. The LLM module includes custom error classes (LlmRateLimitError, LlmCostLimitError), cost tracking (resetRunCost, getRunCost), and operation-specific model selection (getModelForOperation). There's no abstraction for multiple LLM providers.",
      "evidence": [
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            1,
            650
          ],
          "snippet": "import { Anthropic } from '@anthropic-ai/sdk'; ... export function createLlmClient() ... export function getModelForOperation(op: LlmOperation) ... export class LlmCostLimitError ...",
          "explanation": "LLM module exclusively wraps Anthropic SDK with cost tracking and model selection"
        },
        {
          "filePath": "packages/analyzer/src/decision-extractor.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "import { Anthropic } from '@anthropic-ai/sdk';",
          "explanation": "Decision extractor directly uses Anthropic SDK"
        }
      ],
      "constraints": [
        "All LLM calls must go through the core llm.ts module for cost tracking",
        "Switching LLM providers would require significant refactoring",
        "Cost limits must be enforced via LlmCostLimitError",
        "Different operations may use different Claude model tiers"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "anthropic",
        "claude",
        "llm",
        "ai",
        "cost-tracking"
      ]
    },
    {
      "id": "Vo_ucJxsu7lQsHTMFE9TQ",
      "title": "Custom React Hooks for Data Fetching in Dashboard",
      "description": "The dashboard implements custom React hooks (useDecisions, useReviews, useVelocity, useSSE) that encapsulate API fetching, loading/error state management, and data transformation. Page components consume these hooks rather than making direct API calls, creating a clean separation between data access and presentation.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "The hooks/ directory contains 4 custom hooks, each following the same pattern: useState for data/loading/error, useEffect for fetching via apiFetch, and returning typed data. Page components like decisions/page.tsx use useDecisions() and repos/[id]/page.tsx uses useDecisions({ repoId }). Some pages also use direct apiFetch for simpler cases, but the hook pattern is the primary approach.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/hooks/use-decisions.ts",
          "lineRange": [
            1,
            122
          ],
          "snippet": "export function useDecisions(filters?: DecisionFilters) { ... } export function useDecision(id: string) { ... }",
          "explanation": "Custom hook for fetching decisions with filter support and single-item variant"
        },
        {
          "filePath": "packages/dashboard/src/hooks/use-velocity.ts",
          "lineRange": [
            1,
            113
          ],
          "snippet": "export function useTeamVelocity() { ... } export function useDeveloperVelocity(devId: string) { ... }",
          "explanation": "Custom hooks for team and individual velocity data"
        },
        {
          "filePath": "packages/dashboard/src/app/(app)/repos/[id]/page.tsx",
          "lineRange": [
            42,
            42
          ],
          "snippet": "const { decisions, loading: decisionsLoading } = useDecisions({ repoId: params.id });",
          "explanation": "Page component consuming useDecisions hook with filter parameter"
        }
      ],
      "constraints": [
        "Reusable data fetching should be encapsulated in custom hooks under hooks/",
        "Hooks must manage loading and error states internally",
        "Hooks must use apiFetch from lib/api.ts for API calls",
        "Page components should prefer hooks over direct API calls for shared data"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "react-hooks",
        "data-fetching",
        "state-management",
        "separation-of-concerns"
      ]
    },
    {
      "id": "ajdtMJLPfhvDRuyWIP4Qk",
      "title": "Centralized API Client with Auth Token Injection",
      "description": "The dashboard uses a centralized apiFetch function in lib/api.ts that wraps fetch with automatic auth token injection, base URL configuration, JSON content-type headers, and error handling via a custom ApiError class. All API calls from hooks and pages go through this single function.",
      "category": "api",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The lib/api.ts exports apiFetch and convenience wrappers (apiGet, apiPost, apiPut, apiDelete). Every hook and page component imports apiFetch for API calls. The function handles auth token retrieval, error response parsing, and provides a consistent interface. This is a deliberate API client abstraction.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/lib/api.ts",
          "lineRange": [
            1,
            127
          ],
          "snippet": "export class ApiError extends Error { ... } function getAuthToken() { ... } export async function apiFetch<T>(path: string, options?: RequestInit): Promise<T> { ... }",
          "explanation": "Centralized API client with auth injection, error handling, and typed responses"
        },
        {
          "filePath": "packages/dashboard/src/components/decisions/decision-editor.tsx",
          "lineRange": [
            5,
            5
          ],
          "snippet": "import { apiFetch } from '@/lib/api';",
          "explanation": "Components import apiFetch for all API interactions"
        },
        {
          "filePath": "packages/dashboard/src/app/(app)/team/page.tsx",
          "lineRange": [
            12,
            12
          ],
          "snippet": "import { apiFetch } from '@/lib/api';",
          "explanation": "Page components also use apiFetch consistently"
        }
      ],
      "constraints": [
        "All dashboard API calls must go through apiFetch",
        "Auth tokens are automatically injected - components should not handle auth headers",
        "API errors are thrown as ApiError instances with status codes",
        "The base URL is configured centrally in the api module"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "api-client",
        "auth-injection",
        "centralized-fetch",
        "error-handling"
      ]
    },
    {
      "id": "ef_xnZVZ05pTs7bj6X6Wp",
      "title": "MCP Server for AI Agent Integration",
      "description": "The mcp-server package implements the Model Context Protocol (MCP) specification, exposing architectural decisions, patterns, and dependencies as resources, and providing tools (get-decisions, check-pattern, suggest-approach, get-dependencies) for AI agents. It supports multiple transport types: stdio, SSE, and streamable HTTP.",
      "category": "api",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The mcp-server uses @modelcontextprotocol/sdk with explicit tool and resource registration. The tools/ and resources/ directories contain focused modules. The index.ts supports three transport types. This is a deliberate integration point for AI coding assistants to query architectural knowledge.",
      "evidence": [
        {
          "filePath": "packages/mcp-server/src/index.ts",
          "lineRange": [
            1,
            565
          ],
          "snippet": "import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js'; ... function registerTools(server) { ... } function registerResources(server) { ... } function startStdioServer() ... function startSseServer() ... function startStreamableHttpServer() ...",
          "explanation": "MCP server with tool/resource registration and multi-transport support"
        },
        {
          "filePath": "packages/mcp-server/src/tools/check-pattern.ts",
          "lineRange": [
            1,
            284
          ],
          "snippet": "export function executeCheckPattern(input: CheckPatternInput) { ... }",
          "explanation": "Tool for AI agents to check if code follows established patterns"
        },
        {
          "filePath": "packages/mcp-server/src/tools/suggest-approach.ts",
          "lineRange": [
            1,
            296
          ],
          "snippet": "export function executeSuggestApproach(input: SuggestApproachInput) { ... }",
          "explanation": "Tool for AI agents to get architecture-aware suggestions for tasks"
        }
      ],
      "constraints": [
        "MCP tools must follow the MCP SDK tool registration pattern with Zod schemas",
        "Resources must provide read-only access to architectural data",
        "Multiple transport types must be supported for different deployment scenarios",
        "Tools should leverage existing analyzer and core packages for data"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "mcp",
        "model-context-protocol",
        "ai-agents",
        "tools",
        "resources"
      ]
    },
    {
      "id": "PEav31ONKUSuNQw6pV8JM",
      "title": "Velocity Scoring with Weighted Multi-Factor Model",
      "description": "Developer velocity is calculated using a weighted multi-factor model combining: complexity-weighted effort (git stats + complexity analysis), architectural impact (boundary crossings, core module changes), review throughput, and refactoring ratio. The weights are configurable (default: complexity 0.4, arch impact 0.3, review 0.15, refactoring 0.15). Blockers are detected from stalled PRs, long-lived branches, review bottlenecks, and high violation rates.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "The velocity package has a clear internal architecture: collectors/ (git-stats, complexity, pr-metrics, issue-tracker), scoring/ (effort-model, impact-score, velocity-calculator), and blockers/ (detector, alerts). The settings route exposes configurable weights. The velocity-calculator combines all factors with configurable weights. This is a sophisticated, intentional scoring system.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/settings.ts",
          "lineRange": [
            80,
            89
          ],
          "snippet": "velocity: {\n          enabled: settings.velocityEnabled ?? true,\n          calculationSchedule: settings.calculationSchedule ?? '0 0 * * *',\n          complexityWeight: settings.complexityWeight ?? 0.4,\n          archImpactWeight: settings.archImpactWeight ?? 0.3,\n          reviewWeight: settings.reviewWeight ?? 0.15,\n          refactoringWeight: settings.refactoringWeight ?? 0.15,",
          "explanation": "Configurable velocity weights exposed through settings API"
        },
        {
          "filePath": "packages/velocity/src/collectors/complexity.ts",
          "lineRange": [
            1,
            50
          ],
          "snippet": "export function calculateFunctionComplexity(...) ... export function calculateFileComplexity(...) ... export function calculateComplexityDeltas(...) ... export function calculateRefactoringRatio(...)",
          "explanation": "Complexity analysis with cyclomatic and cognitive complexity, plus refactoring ratio calculation"
        },
        {
          "filePath": "packages/velocity/src/scoring/velocity-calculator.ts",
          "lineRange": [
            1,
            391
          ],
          "snippet": "export function calculateDeveloperVelocityScores(...) ... export function calculateTeamVelocity(...) ... export function determineTrend(...)",
          "explanation": "Velocity calculator combining all factors with configurable weights"
        }
      ],
      "constraints": [
        "Velocity scores must combine all four factors with configurable weights",
        "Weights must sum to 1.0",
        "Blocker detection must cover stalled PRs, long branches, review bottlenecks, and violations",
        "Velocity trends must be calculated from historical data points"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "velocity",
        "developer-metrics",
        "weighted-scoring",
        "complexity-analysis",
        "blockers"
      ]
    },
    {
      "id": "2FUf_gA2cLHoLTiXEBZ0O",
      "title": "OAuth + Email Authentication with SAML SSO Support",
      "description": "The authentication system supports three methods: email/password login, OAuth (GitHub, Google), and SAML 2.0 SSO for enterprise customers. The auth module handles session management with token-based authentication. The dashboard provides dedicated UI flows for each method. Auth can be disabled entirely for local/CLI usage.",
      "category": "security",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The login page shows OAuth buttons for GitHub and Google alongside email/password form. The SSO page handles SAML-based login. The server has auth/saml.ts for SAML configuration and callback handling. The auth middleware checks ARCHGUARD_DISABLE_AUTH for local development. The settings/sso page provides full SAML configuration UI.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/app/(auth)/login/page.tsx",
          "lineRange": [
            96,
            120
          ],
          "snippet": "<button onClick={() => initiateOAuthLogin('github')} className=\"btn-secondary gap-2\">\n              <Github className=\"h-4 w-4\" />\n              GitHub\n            </button>\n            <button onClick={() => initiateOAuthLogin('google')} ...",
          "explanation": "Login page with OAuth (GitHub, Google) and email/password options"
        },
        {
          "filePath": "packages/server/src/middleware/auth.ts",
          "lineRange": [
            40,
            45
          ],
          "snippet": "if (process.env.ARCHGUARD_DISABLE_AUTH === 'true') {\n      await next();\n      return;\n    }",
          "explanation": "Auth can be disabled for local development via environment variable"
        },
        {
          "filePath": "packages/server/src/auth/saml.ts",
          "lineRange": [
            1,
            361
          ],
          "snippet": "export function buildSsoRedirectUrl(...) ... function handleSamlCallback(...) ... function handleSamlLogin(...) ... function handleSamlMetadata(...)",
          "explanation": "Full SAML 2.0 SSO implementation with SP metadata, redirect, and callback handling"
        }
      ],
      "constraints": [
        "All three auth methods must be supported: email, OAuth, SAML SSO",
        "Session tokens must be validated on every authenticated request",
        "Auth must be disableable for local/CLI usage",
        "SAML SSO configuration must be per-organization"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "authentication",
        "oauth",
        "saml-sso",
        "session-management",
        "multi-auth"
      ]
    },
    {
      "id": "sAHAAKxwvSigINKlkeC6E",
      "title": "Consistent REST API Design with Pagination and Filtering",
      "description": "All list endpoints follow a consistent pattern: query parameters for filtering (category, status, search, repoId), pagination via limit/offset with defaults (limit=20, offset=0), and responses containing the data array, total count, and pagination metadata. Detail endpoints return 404 with { error: 'X not found' }. Create endpoints return 201, async operations return 202.",
      "category": "api",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "Every list route (decisions, reviews, summaries, repos, teams, sync, analysis/history) uses the same limit/offset pagination pattern with identical default values. Error responses consistently use { error: string } format. Status codes are consistent: 200 for reads, 201 for creates, 202 for async, 400 for validation, 403 for authorization, 404 for not found, 409 for conflicts.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/decisions.ts",
          "lineRange": [
            38,
            42
          ],
          "snippet": "const limit = parseInt(c.req.query('limit') ?? '50', 10);\n    const offset = parseInt(c.req.query('offset') ?? '0', 10);",
          "explanation": "Consistent pagination pattern with limit/offset and defaults"
        },
        {
          "filePath": "packages/server/src/routes/summaries.ts",
          "lineRange": [
            33,
            35
          ],
          "snippet": "const limit = parseInt(c.req.query('limit') ?? '20', 10);\n    const offset = parseInt(c.req.query('offset') ?? '0', 10);",
          "explanation": "Same pagination pattern in summaries route"
        },
        {
          "filePath": "packages/server/src/routes/repos.ts",
          "lineRange": [
            93,
            95
          ],
          "snippet": "return c.json({ error: 'provider, fullName, and cloneUrl are required' }, 400);",
          "explanation": "Consistent error response format with { error: string } and appropriate status codes"
        },
        {
          "filePath": "packages/server/src/routes/reviews.ts",
          "lineRange": [
            138,
            145
          ],
          "snippet": "return c.json(\n        {\n          jobId,\n          status: 'queued',\n          message: 'Review job has been queued',\n        },\n        202\n      );",
          "explanation": "Async operations consistently return 202 with jobId and status"
        }
      ],
      "constraints": [
        "List endpoints must support limit/offset pagination",
        "Error responses must use { error: string } format",
        "Create operations return 201, async operations return 202",
        "All list responses must include total count alongside the data array"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "rest-api",
        "pagination",
        "error-handling",
        "http-status-codes",
        "api-conventions"
      ]
    },
    {
      "id": "rqDIGHqATLSeGZuTmuGCJ",
      "title": "Edited Content Preservation Pattern for AI-Generated Summaries",
      "description": "Work summaries store both the original AI-generated content and user-edited content separately. The editedContent field is stored alongside the original content, and the API returns a displayContent field that prefers edited content over original. This preserves the AI-generated baseline while allowing human refinement.",
      "category": "data",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The summaries route explicitly stores editedContent separately from content, returns both fields plus a computed displayContent, and the list endpoint uses editedContent ?? content for display. This is a deliberate pattern for human-in-the-loop AI content.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/summaries.ts",
          "lineRange": [
            60,
            65
          ],
          "snippet": "content: s.editedContent ?? s.content,\n      dataPoints: JSON.parse(s.dataPoints ?? '{}'),\n      isEdited: !!s.editedContent,",
          "explanation": "List endpoint prefers edited content and flags whether content was edited"
        },
        {
          "filePath": "packages/server/src/routes/summaries.ts",
          "lineRange": [
            85,
            92
          ],
          "snippet": "content: summary.content,\n      editedContent: summary.editedContent,\n      displayContent: summary.editedContent ?? summary.content,\n      ...\n      isEdited: !!summary.editedContent,",
          "explanation": "Detail endpoint returns both original and edited content with computed display field"
        },
        {
          "filePath": "packages/server/src/routes/summaries.ts",
          "lineRange": [
            163,
            166
          ],
          "snippet": "await db\n      .update(schema.workSummaries)\n      .set({ editedContent: body.content })\n      .where(eq(schema.workSummaries.id, id));",
          "explanation": "Edit operation stores in editedContent, preserving original"
        }
      ],
      "constraints": [
        "AI-generated content must never be overwritten by user edits",
        "User edits must be stored in a separate editedContent field",
        "Display logic must prefer editedContent over original content",
        "The isEdited flag must be computed and returned to the client"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "human-in-the-loop",
        "content-preservation",
        "ai-generated",
        "editing"
      ]
    },
    {
      "id": "hCp99kHzSI3w0STPGRlI7",
      "title": "CLI Command Pattern with Commander.js and Tapir Branding",
      "description": "The CLI uses Commander.js with each command in its own module under commands/, following a registerXxxCommand(program) pattern. The CLI has a distinctive tapir mascot branding with custom ASCII art spinner animations, tapir-themed activity phrases, and a consistent output style using chalk for colors and ora for spinners.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "The cli/src/index.ts imports and registers 12 command modules, each following the registerXxxCommand pattern. The tapir-spinner.ts contains elaborate ASCII art, animation frames, and 20 tapir-themed phrases. This is clearly an intentional branding decision with significant creative investment.",
      "evidence": [
        {
          "filePath": "packages/cli/src/index.ts",
          "lineRange": [
            1,
            98
          ],
          "snippet": "import { registerInitCommand } from './commands/init.js'; ... import { registerAnalyzeCommand } from './commands/analyze.js'; ... registerInitCommand(program); registerAnalyzeCommand(program); ...",
          "explanation": "Main CLI entry point registers all 12 commands using consistent pattern"
        },
        {
          "filePath": "packages/cli/src/tapir-spinner.ts",
          "lineRange": [
            1,
            80
          ],
          "snippet": "const TAPIR_FRAMES = [...]; const TAPIR_RUN_FRAMES = [...]; export const TAPIR_PHRASES = [\n  'Snouting through the codebase',\n  'Foraging for architectural patterns',\n  'Booping the dependency graph',\n  ...\n];",
          "explanation": "Elaborate tapir-themed branding with ASCII art frames and 20 activity phrases"
        },
        {
          "filePath": "packages/cli/src/commands/server.ts",
          "lineRange": [
            14,
            17
          ],
          "snippet": "export function registerServerCommand(program: Command): void {\n  const server = program\n    .command('server')\n    .description('Manage the ArchGuard API server');",
          "explanation": "Consistent registerXxxCommand pattern with Commander.js"
        }
      ],
      "constraints": [
        "Each CLI command must be in its own module under commands/",
        "Commands must follow the registerXxxCommand(program) pattern",
        "CLI output must use chalk for colors and ora for spinners",
        "The tapir branding should be used for loading/progress indicators"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "cli",
        "commander-js",
        "tapir-branding",
        "command-pattern"
      ]
    },
    {
      "id": "2kDLJvfG0oEICxnIm5Kgf",
      "title": "Cascading Delete Pattern for Repository Disconnection",
      "description": "When a repository is disconnected, all associated data is deleted in a specific order respecting foreign key relationships: evidence → decisions, drift_events → arch_snapshots, dependencies, reviews, sync_history → repository. This manual cascade ensures data integrity without relying on database-level cascade constraints.",
      "category": "data",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The repos DELETE handler explicitly deletes related records in dependency order with comments explaining the sequence. This is necessary because SQLite with Drizzle may not have cascade deletes configured, so the application handles it manually. The code includes inline comments documenting the deletion order.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/repos.ts",
          "lineRange": [
            155,
            195
          ],
          "snippet": "// Delete in order: evidence -> decisions, drift_events -> arch_snapshots,\n    // dependencies, reviews, velocity_scores, sync_history -> repository\n\n    // Delete evidence for all decisions in this repo\n    const decisionRows = await db\n      .select({ id: schema.decisions.id })\n      .from(schema.decisions)\n      .where(eq(schema.decisions.repoId, repoId));\n\n    for (const d of decisionRows) {\n      await db.delete(schema.evidence).where(eq(schema.evidence.decisionId, d.id));\n    }\n\n    // Delete decisions\n    await db.delete(schema.decisions).where(eq(schema.decisions.repoId, repoId));",
          "explanation": "Manual cascading delete with explicit ordering and comments documenting the dependency chain"
        }
      ],
      "constraints": [
        "Repository deletion must cascade to all related records in dependency order",
        "Evidence must be deleted before decisions (foreign key)",
        "Drift events must be deleted before snapshots",
        "The deletion order must be maintained when new related tables are added"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "cascading-delete",
        "data-integrity",
        "foreign-keys",
        "sqlite"
      ]
    },
    {
      "id": "8obMyPakhKVQrVEYzl0_9",
      "title": "Dual-Mode Operation: Local CLI and Cloud Server",
      "description": "The system is designed to operate in two modes: as a local CLI tool (no auth, SQLite, no Redis/workers) and as a cloud server (full auth, job queues, multi-tenant). The server command supports --no-auth and --workers flags. Routes handle missing orgId gracefully for local mode. Auth middleware checks ARCHGUARD_DISABLE_AUTH.",
      "category": "deployment",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The server command explicitly supports --no-auth and --workers flags with defaults for local usage. The auth middleware has an environment variable bypass. The decisions route handles the case where orgId is undefined (local mode). Workers are disabled by default. This dual-mode design is clearly intentional.",
      "evidence": [
        {
          "filePath": "packages/cli/src/commands/server.ts",
          "lineRange": [
            35,
            40
          ],
          "snippet": ".option('--port <number>', 'Port to listen on', '3200')\n    .option('--host <host>', 'Host to bind to', '127.0.0.1')\n    .option('--workers', 'Enable BullMQ workers (requires Redis)', false)\n    .option('--no-auth', 'Disable authentication (for local development)')",
          "explanation": "Server command with local-friendly defaults: localhost, no workers, optional auth"
        },
        {
          "filePath": "packages/server/src/routes/decisions.ts",
          "lineRange": [
            55,
            70
          ],
          "snippet": "if (repoId) {\n      // Filter by specific repo\n    } else if (orgId) {\n      // Multi-tenant: scope to org's repos\n    } else {\n      // Local mode (no org context): return all decisions\n      allDecisions = await db\n        .select()\n        .from(schema.decisions)\n        .orderBy(desc(schema.decisions.detectedAt));\n    }",
          "explanation": "Decisions route gracefully handles local mode (no org context) by returning all decisions"
        },
        {
          "filePath": "packages/server/src/middleware/auth.ts",
          "lineRange": [
            40,
            45
          ],
          "snippet": "if (process.env.ARCHGUARD_DISABLE_AUTH === 'true') {\n      await next();\n      return;\n    }",
          "explanation": "Auth bypass for local development mode"
        }
      ],
      "constraints": [
        "All features must work in both local and cloud modes",
        "Auth must be bypassable for local development",
        "Routes must handle missing orgId gracefully for local mode",
        "Workers/Redis must be optional for local usage"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:45.601Z",
      "tags": [
        "dual-mode",
        "local-first",
        "cloud-server",
        "deployment-flexibility"
      ]
    },
    {
      "id": "9xVwaoo3HZO987K-yiteO",
      "title": "LLM-First Architecture with Anthropic Claude as Core Product",
      "description": "The LLM is not an optional enhancement but the core product capability. Analysis, review, compliance checking, summary generation, and context sync all require Claude API calls. The system uses different Claude models for different operations (Opus for analysis, Sonnet for review/MCP, configurable per operation) with built-in cost tracking, caching, and cost limits.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.98,
      "reasoning": "Multiple files explicitly state 'the LLM IS the product' in comments. The requireApiKey() function is called at the start of every major operation. The costs command, per-operation model selection, cost tracking with LlmCallRecord, and cache TTL configuration all demonstrate this is a deeply intentional architectural choice, not an afterthought.",
      "evidence": [
        {
          "filePath": "packages/cli/src/commands/analyze.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * `archguard analyze` command.\n *\n * Runs a full codebase analysis using Claude (Opus by default).\n * Requires an Anthropic API key — the LLM IS the product.\n */",
          "explanation": "Explicit documentation that the LLM is the product, not optional"
        },
        {
          "filePath": "packages/cli/src/commands/costs.ts",
          "lineRange": [
            15,
            30
          ],
          "snippet": "const MODEL_PRICING: Record<string, { input: number; output: number; label: string }> = {\n  'claude-opus-4-6': { input: 15.0, output: 75.0, label: 'Opus 4.6' },\n  'claude-sonnet-4-6': { input: 3.0, output: 15.0, label: 'Sonnet 4.6' },\n  'claude-haiku-4-5-20251001': { input: 0.80, output: 4.0, label: 'Haiku 4.5' },\n};",
          "explanation": "Dedicated cost tracking with per-model pricing shows LLM usage is a first-class concern"
        },
        {
          "filePath": "packages/mcp-server/src/tools/check-pattern.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * MCP Tool: check_architectural_compliance\n * Checks code against architectural decisions and constraints using LLM-powered\n * semantic analysis via Claude Sonnet for fast, accurate compliance checking.\n */",
          "explanation": "Even compliance checking uses LLM semantic analysis rather than static rules alone"
        }
      ],
      "constraints": [
        "An Anthropic API key is required for all core operations (analyze, review, summary, compliance check)",
        "Different operations must use appropriate model tiers (Opus for deep analysis, Sonnet for fast checks)",
        "All LLM calls must track cost via LlmCallRecord for transparency",
        "LLM responses must be validated against Zod schemas where structured output is expected",
        "Cost limits (max_cost_per_run) must be respected to prevent surprise bills"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "llm-first",
        "anthropic",
        "claude",
        "cost-tracking",
        "model-routing"
      ]
    },
    {
      "id": "eNAAXfXXn9Dd9Zs_vWHQb",
      "title": "Role-Based Access Control (RBAC) with Permission System",
      "description": "The server implements a hierarchical RBAC system with roles (owner, admin, member, viewer) mapped to granular permissions. Middleware functions (requirePermission, requireRole, requireAnyPermission) enforce access control on routes. The auth system supports session-based authentication with SAML SSO for enterprise customers.",
      "category": "security",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The auth/ directory contains four files: index.ts (session management), rbac.ts (middleware), roles.ts (role definitions), and saml.ts (SSO). The core package also exports ROLE_PERMISSIONS and permission checking utilities. The dashboard has dedicated SSO pages. This is a comprehensive, intentional security architecture.",
      "evidence": [
        {
          "filePath": "packages/server/src/auth/rbac.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "export function requirePermission(permission: Permission) { ... }\nexport function requireRole(role: Role) { ... }\nexport function requireAnyPermission(...permissions: Permission[]) { ... }",
          "explanation": "Three middleware functions for different access control patterns"
        },
        {
          "filePath": "packages/core/src/auth.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "export const ROLE_PERMISSIONS: Record<Role, Permission[]> = { ... };\nexport function hasPermission(role: Role, permission: Permission): boolean { ... }",
          "explanation": "Permission definitions in core package so they can be shared across server and other packages"
        },
        {
          "filePath": "packages/dashboard/src/app/(auth)/sso/page.tsx",
          "lineRange": [
            1,
            20
          ],
          "snippet": "export default function SSOPage() { ... initiateSSOLogin(slug); ... }",
          "explanation": "Dedicated SSO login page in the dashboard for enterprise SAML authentication"
        }
      ],
      "constraints": [
        "All API routes must be protected by appropriate RBAC middleware",
        "Permission definitions must live in @archguard/core for cross-package sharing",
        "Role hierarchy must be respected (owner > admin > member > viewer)",
        "SAML SSO must be supported for enterprise customers",
        "Auth can be disabled for development (isAuthDisabled check in rbac.ts)"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "rbac",
        "permissions",
        "authentication",
        "saml",
        "sso",
        "enterprise"
      ]
    },
    {
      "id": "axcDJXvWnE7da4Lnza4OR",
      "title": "Next.js App Router with Route Groups for Auth/App Separation",
      "description": "The dashboard uses Next.js with the App Router. Route groups (app) and (auth) separate authenticated application pages from public authentication pages. The (app) group has a shared layout with sidebar and header, while (auth) pages have their own minimal layout. Dynamic routes use [id] and [devId] segments.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The directory structure under dashboard/src/app/ clearly shows (app)/ and (auth)/ route groups — a Next.js App Router convention. The (app)/layout.tsx wraps children with Sidebar and Header components, while auth pages are standalone. This is a textbook Next.js architectural pattern applied intentionally.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/app/(app)/layout.tsx",
          "lineRange": [
            1,
            17
          ],
          "snippet": "export default function AppLayout({ children }: { children: React.ReactNode }) {\n  return (\n    <div className=\"flex h-screen overflow-hidden\">\n      <Sidebar />\n      <div className=\"flex flex-1 flex-col overflow-hidden\">\n        <Header orgName=\"Acme Corp\" />\n        <main className=\"flex-1 overflow-y-auto bg-gray-50 p-6\">{children}</main>\n      </div>\n    </div>\n  );\n}",
          "explanation": "App layout wraps all authenticated pages with sidebar + header shell"
        },
        {
          "filePath": "packages/dashboard/src/app/(auth)/sso/page.tsx",
          "lineRange": [
            1,
            5
          ],
          "snippet": "'use client';\nimport Link from 'next/link';",
          "explanation": "Auth pages are standalone without the app shell layout"
        },
        {
          "filePath": "packages/dashboard/src/app/layout.tsx",
          "lineRange": [
            1,
            47
          ],
          "snippet": "export default function RootLayout({ children }: { children: React.ReactNode }) {\n  return (\n    <html lang=\"en\" className={`${inter.variable} ${jetbrainsMono.variable}`}>\n      <body className=\"min-h-screen bg-slate-50 font-sans antialiased\">\n        {children}\n      </body>\n    </html>\n  );\n}",
          "explanation": "Root layout provides font variables and base styling, route groups handle auth vs app separation"
        }
      ],
      "constraints": [
        "Authenticated pages must be placed under (app)/ route group",
        "Authentication pages must be placed under (auth)/ route group",
        "The (app) layout must include Sidebar and Header components",
        "Dynamic routes must use Next.js [param] convention",
        "All dashboard pages must use 'use client' directive for interactivity"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "nextjs",
        "app-router",
        "route-groups",
        "layout-pattern"
      ]
    },
    {
      "id": "ZO0_d8ZSyB2Vy9xH7KKlQ",
      "title": "Tailwind CSS with Custom Design System Tokens",
      "description": "The dashboard uses Tailwind CSS with custom design tokens including brand colors, sidebar-specific colors, and custom utility classes (card, card-padded, btn-primary, btn-secondary, input-field, sidebar-link). The cn() utility combines clsx and tailwind-merge for conditional class composition.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The tailwind.config.ts extends the theme with custom colors. The cn() utility in lib/utils.ts is imported by virtually every component. Custom class names like 'card', 'card-padded', 'btn-primary', 'sidebar-link', 'sidebar-link-active' appear consistently across all dashboard components, indicating a deliberate design system.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/lib/utils.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import { type ClassValue, clsx } from 'clsx';\nimport { twMerge } from 'tailwind-merge';\n\nexport function cn(...inputs: ClassValue[]): string {\n  return twMerge(clsx(inputs));\n}",
          "explanation": "Standard cn() utility pattern for Tailwind class composition"
        },
        {
          "filePath": "packages/dashboard/src/components/layout/sidebar.tsx",
          "lineRange": [
            90,
            100
          ],
          "snippet": "className={cn(\n  'sidebar-link group relative',\n  isActive ? 'sidebar-link-active' : 'sidebar-link-inactive',\n  collapsed && 'justify-center px-2',\n)}",
          "explanation": "Custom sidebar-link classes used consistently, indicating a design system"
        },
        {
          "filePath": "packages/dashboard/src/components/decisions/decision-card.tsx",
          "lineRange": [
            55,
            60
          ],
          "snippet": "<div className=\"card p-5 hover:shadow-md transition-shadow cursor-pointer\">",
          "explanation": "Custom 'card' class used across multiple component types"
        }
      ],
      "constraints": [
        "All conditional class composition must use the cn() utility",
        "Custom component classes (card, btn-primary, etc.) must be defined in global CSS",
        "Brand colors must use the brand-* token namespace",
        "Sidebar-specific styles must use sidebar-* token namespace"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "tailwind",
        "design-system",
        "css",
        "utility-classes"
      ]
    },
    {
      "id": "2E-FPt25ujkT0IzFWb-RU",
      "title": "Model Context Protocol (MCP) Server for AI Agent Integration",
      "description": "The mcp-server package implements a Model Context Protocol server that exposes architectural decisions, patterns, and dependencies as MCP resources and tools. Tools include get_architectural_decisions, check_architectural_compliance, get_architectural_guidance, and get_dependencies. Resources include archguard://decisions, archguard://patterns, and archguard://dependencies/{module}. Supports stdio, SSE, and streamable HTTP transports.",
      "category": "api",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The mcp-server package has a clear structure with tools/ and resources/ directories. It imports from @modelcontextprotocol/sdk and implements the MCP protocol with multiple transport options. Each tool has a typed input schema and dedicated execution function. This is a deliberate integration point for AI coding agents.",
      "evidence": [
        {
          "filePath": "packages/mcp-server/src/tools/check-pattern.ts",
          "lineRange": [
            1,
            15
          ],
          "snippet": "/**\n * MCP Tool: check_architectural_compliance\n * Checks code against architectural decisions and constraints using LLM-powered\n * semantic analysis via Claude Sonnet for fast, accurate compliance checking.\n */",
          "explanation": "MCP tool with LLM-powered semantic compliance checking"
        },
        {
          "filePath": "packages/mcp-server/src/tools/suggest-approach.ts",
          "lineRange": [
            1,
            15
          ],
          "snippet": "/**\n * MCP Tool: get_architectural_guidance\n * Returns architectural guidance with relevant decisions, constraints, and examples.\n * Helps AI coding agents understand the project's architectural conventions.\n */",
          "explanation": "Tool specifically designed to help AI agents understand architecture"
        },
        {
          "filePath": "packages/mcp-server/src/resources/patterns.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * MCP Resources for detected patterns and dependency information.\n *\n * Exposes:\n *   archguard://patterns               - Detected patterns summary\n *   archguard://dependencies/{module}   - Dependency info for a module\n */",
          "explanation": "Custom URI scheme for MCP resources"
        }
      ],
      "constraints": [
        "MCP tools must have typed input schemas with JSON Schema definitions",
        "MCP resources must use the archguard:// URI scheme",
        "The MCP server must support multiple transports (stdio, SSE, HTTP)",
        "Compliance checking must use LLM semantic analysis, not just pattern matching",
        "All MCP tools must load decisions from the database, not from files"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "mcp",
        "model-context-protocol",
        "ai-agents",
        "tools",
        "resources"
      ]
    },
    {
      "id": "S4z6XFlQgIq5YgXWWR8nY",
      "title": "SQLite with Drizzle ORM for Local-First Data Persistence",
      "description": "The application uses SQLite via better-sqlite3 with Drizzle ORM for data persistence. The schema defines 16 tables covering organizations, users, repositories, decisions, evidence, snapshots, drift events, dependencies, reviews, velocity scores, work summaries, sync history, and SAML configs. The database is initialized lazily and supports both server and CLI usage.",
      "category": "data",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The core/src/db/ directory contains schema.ts (16 tables), index.ts (initialization with better-sqlite3), and seed.ts. Drizzle ORM operators (eq, and, or, desc, asc, sql) are re-exported from core. Every job file and route handler calls initializeDatabase() and uses Drizzle query builders. The CLI's analyze command also persists to the local database.",
      "evidence": [
        {
          "filePath": "packages/core/src/db/index.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import { drizzle } from 'drizzle-orm/better-sqlite3';\nimport Database from 'better-sqlite3';",
          "explanation": "SQLite via better-sqlite3 with Drizzle ORM adapter"
        },
        {
          "filePath": "packages/core/src/db/schema.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "import { sqliteTable, text, integer, real } from 'drizzle-orm/sqlite-core';",
          "explanation": "Schema defined using Drizzle's SQLite-specific table builders"
        },
        {
          "filePath": "packages/cli/src/commands/analyze.ts",
          "lineRange": [
            200,
            230
          ],
          "snippet": "const db = initializeDatabase();\n// ... persist decisions to local database so `archguard sync` can use them",
          "explanation": "CLI persists analysis results to local SQLite for subsequent sync operations"
        }
      ],
      "constraints": [
        "All database access must go through Drizzle ORM, not raw SQL",
        "Schema changes must be made in core/src/db/schema.ts",
        "Database initialization must be lazy (initializeDatabase())",
        "The database must work for both server (multi-user) and CLI (local) modes",
        "JSON fields must be stored as text and parsed with JSON.parse/JSON.stringify"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "sqlite",
        "drizzle-orm",
        "local-first",
        "better-sqlite3",
        "schema"
      ]
    },
    {
      "id": "mdkrQniXIPpfZa_N_ktuk",
      "title": "Architectural Drift Detection via Snapshot Comparison",
      "description": "The system tracks architectural drift by comparing current analysis results against historical snapshots. It detects: lost decisions, new decisions, weakened decisions (confidence drops), new circular dependencies, coupling increases, instability increases, and layer violations. A composite drift score (0-100) is calculated with severity-weighted events.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The drift-detector.ts is a comprehensive 235-line module with well-defined event types (decision_lost, decision_emerged, decision_weakened, circular_dep_introduced, new_violation_trend, layer_violation_introduced). The scoring algorithm uses severity weights and decision loss ratios. The database schema has archSnapshots and driftEvents tables. This is a core product feature, not incidental.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/drift-detector.ts",
          "lineRange": [
            1,
            30
          ],
          "snippet": "/**\n * Architectural drift detection.\n * Compares current analysis results against historical snapshots\n * to identify architectural drift over time.\n *\n * Tracks: decision changes, coupling trends, circular deps,\n * instability shifts, and layer violation trends.\n */",
          "explanation": "Comprehensive drift detection with multiple tracked dimensions"
        },
        {
          "filePath": "packages/analyzer/src/drift-detector.ts",
          "lineRange": [
            195,
            235
          ],
          "snippet": "function calculateDriftScore(events, currentDecisions, previousSnapshot): number {\n  const severityWeights = { high: 15, medium: 8, low: 3 };\n  // ... penalty for decision loss relative to total\n  score += (lostDecisions / totalPrevious) * 30;\n  return Math.min(Math.round(score), 100);\n}",
          "explanation": "Weighted drift scoring algorithm with decision loss penalty"
        }
      ],
      "constraints": [
        "Every analysis must produce a snapshot for future drift comparison",
        "Drift events must be categorized by type and severity",
        "The drift score must be 0-100 with severity-weighted calculation",
        "First analysis creates a baseline with drift score 0",
        "Confidence drops > 15% must be flagged as decision weakening"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "drift-detection",
        "snapshots",
        "architectural-health",
        "monitoring"
      ]
    },
    {
      "id": "87mDL-mDdB2qCy8pgCK4p",
      "title": "Strategy Pattern for Review Output Formatting",
      "description": "The reviewer package implements a strategy pattern for formatting review results across multiple output targets: terminal (ANSI colors), GitHub PR (markdown + inline comments + check annotations), Bitbucket PR (code insights + annotations), and JSON. Each formatter is a separate module with a consistent interface.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "Four formatter files in reviewer/src/formatters/ each export a format function. The CLI review command switches between them based on --format flag. The GitHub and Bitbucket formatters produce platform-specific structures (check annotations, inline comments, build status). The severity.ts module provides shared utilities used by all formatters.",
      "evidence": [
        {
          "filePath": "packages/reviewer/src/formatters/terminal.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "/**\n * Terminal output formatter for architectural review results.\n * Uses ANSI escape codes for colored output.\n */\nexport function formatForTerminal(result: ReviewResult): string { ... }",
          "explanation": "Terminal formatter with ANSI color codes"
        },
        {
          "filePath": "packages/cli/src/commands/review.ts",
          "lineRange": [
            170,
            190
          ],
          "snippet": "switch (options.format) {\n  case 'json': output = JSON.stringify(result, null, 2); break;\n  case 'github': output = formatGitHub(result); break;\n  case 'bitbucket': output = formatBitbucket(result); break;\n  case 'terminal': default: ...\n}",
          "explanation": "CLI switches between formatters based on --format flag"
        }
      ],
      "constraints": [
        "Each output format must have its own formatter module",
        "All formatters must accept ReviewResult and produce string output",
        "Severity utilities must be shared via severity.ts, not duplicated",
        "Platform-specific formatters must produce structures compatible with their APIs (GitHub check annotations, Bitbucket code insights)"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "strategy-pattern",
        "formatters",
        "multi-output",
        "review"
      ]
    },
    {
      "id": "ohp66fdx_xQaXEkhL0Hy8",
      "title": "Provider Interface Pattern for External Data Sources",
      "description": "External data sources are abstracted behind provider interfaces with no-op defaults. The IssueTrackerProvider interface defines fetchIssues(), fetchIssuesForDeveloper(), and isAvailable() methods, with a createNoopIssueTracker() factory for when no tracker is configured. This pattern allows optional integrations without breaking the core pipeline.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.92,
      "reasoning": "The IssueTrackerProvider interface in velocity/src/collectors/issue-tracker.ts is a textbook provider pattern with a noop implementation. The comment explicitly states 'Implementations should be provided by the integrations package for specific platforms.' This graceful degradation pattern is intentional for optional integrations.",
      "evidence": [
        {
          "filePath": "packages/velocity/src/collectors/issue-tracker.ts",
          "lineRange": [
            20,
            60
          ],
          "snippet": "export interface IssueTrackerProvider {\n  readonly name: string;\n  fetchIssues(projectKey: string, since: string, until: string): Promise<IssueData[]>;\n  fetchIssuesForDeveloper(assignee: string, since: string, until: string): Promise<IssueData[]>;\n  isAvailable(): Promise<boolean>;\n}",
          "explanation": "Clean provider interface with availability check"
        },
        {
          "filePath": "packages/velocity/src/collectors/issue-tracker.ts",
          "lineRange": [
            185,
            212
          ],
          "snippet": "export function createNoopIssueTracker(): IssueTrackerProvider {\n  return {\n    name: 'noop',\n    async fetchIssues(): Promise<IssueData[]> { return []; },\n    async fetchIssuesForDeveloper(): Promise<IssueData[]> { return []; },\n    async isAvailable(): Promise<boolean> { return false; },\n  };\n}",
          "explanation": "No-op implementation for graceful degradation when no tracker is configured"
        }
      ],
      "constraints": [
        "External data sources must be abstracted behind provider interfaces",
        "Provider interfaces must include an isAvailable() method for runtime capability detection",
        "A no-op/null implementation must be provided for optional integrations",
        "Implementations should be in the integrations package, not in the consuming package"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "provider-pattern",
        "interface-abstraction",
        "graceful-degradation",
        "null-object"
      ]
    },
    {
      "id": "o_8xHadRwKBcFgD8Ry3y_",
      "title": "Comprehensive Type System with Shared Domain Types",
      "description": "The core/src/types.ts file defines 541 lines of shared domain types covering all major concepts: architectural decisions (ArchDecision, Evidence, ArchCategory), drift (DriftEvent, ArchSnapshot), dependencies (DependencyNode, CouplingMetrics), reviews (Violation, ReviewResult), velocity (VelocityScore, Blocker), summaries (WorkSummary), auth (User, Organization, Role), and configuration (ArchGuardConfig). All packages import these types from @archguard/core.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "The types.ts file is 541 lines with 50+ exported types and interfaces. Every other package imports types from @archguard/core. The types are well-organized by domain area and use TypeScript union types for enums (ArchCategory, DecisionStatus, ViolationSeverity). This centralized type system is clearly intentional.",
      "evidence": [
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "export type ArchCategory = 'structural' | 'behavioral' | 'deployment' | 'data' | 'api' | 'testing' | 'security';\nexport type DecisionStatus = 'detected' | 'confirmed' | 'deprecated' | 'superseded';",
          "explanation": "Union types for domain enums ensuring type safety across packages"
        },
        {
          "filePath": "packages/analyzer/src/drift-detector.ts",
          "lineRange": [
            10,
            20
          ],
          "snippet": "import {\n  generateId, now,\n  type ArchDecision, type ArchSnapshot, type DriftEvent,\n  type DriftEventType, type LayerViolation,\n} from '@archguard/core';",
          "explanation": "Analyzer imports domain types from core, not defining its own"
        }
      ],
      "constraints": [
        "All shared domain types must be defined in core/src/types.ts",
        "Packages must import types from @archguard/core, not redefine them",
        "Enum-like values must use TypeScript union types, not enums",
        "Types must be exported from core's barrel index.ts"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "type-system",
        "shared-types",
        "domain-model",
        "typescript"
      ]
    },
    {
      "id": "v3yl2i6pv4iLaDraVksPq",
      "title": "Dynamic Imports to Avoid Circular Dependencies at Startup",
      "description": "Job processors use dynamic imports (await import()) to load heavy packages like @archguard/analyzer, @archguard/reviewer, and @archguard/context-sync at runtime rather than at module load time. This prevents circular dependency issues and reduces startup time for the server.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.92,
      "reasoning": "Multiple job files use the pattern `const { X } = await import('@archguard/Y')` with explicit comments explaining why. The analyze.job.ts comments 'Dynamically import analyzer to avoid circular dependencies at startup'. This is a deliberate workaround for a known monorepo challenge.",
      "evidence": [
        {
          "filePath": "packages/server/src/jobs/analyze.job.ts",
          "lineRange": [
            65,
            70
          ],
          "snippet": "// Dynamically import analyzer to avoid circular dependencies at startup\nconst { runAnalysis } = await import('@archguard/analyzer');",
          "explanation": "Explicit comment explaining the dynamic import rationale"
        },
        {
          "filePath": "packages/server/src/jobs/review.job.ts",
          "lineRange": [
            75,
            80
          ],
          "snippet": "const { checkRules } = await import('@archguard/reviewer');",
          "explanation": "Same pattern in review job"
        },
        {
          "filePath": "packages/server/src/jobs/sync.job.ts",
          "lineRange": [
            95,
            100
          ],
          "snippet": "const { SyncEngine } = await import('@archguard/context-sync');",
          "explanation": "Same pattern in sync job"
        }
      ],
      "constraints": [
        "Heavy package imports in job processors must use dynamic import()",
        "Dynamic imports must be documented with a comment explaining why",
        "Only job processors should need dynamic imports — direct package dependencies are fine elsewhere"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "dynamic-imports",
        "circular-dependencies",
        "lazy-loading",
        "startup-optimization"
      ]
    },
    {
      "id": "dqSVPFO1ArWq6zLoNeRcC",
      "title": "Zod Schema Validation for LLM Response Parsing",
      "description": "LLM responses that require structured output are validated against Zod schemas using analyzeWithLlmValidated(). The check-pattern tool defines a complianceAnalysisSchema with z.object(), and the decision-extractor uses similar patterns. Failed validation produces LlmValidationError with zodErrors for debugging.",
      "category": "api",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "The core/src/llm.ts exports analyzeWithLlmValidated which accepts a Zod schema. The check-pattern.ts defines a detailed Zod schema for compliance analysis. The CLI's analyze command catches LlmValidationError and displays zodErrors. This is a deliberate reliability pattern for LLM integration.",
      "evidence": [
        {
          "filePath": "packages/mcp-server/src/tools/check-pattern.ts",
          "lineRange": [
            60,
            80
          ],
          "snippet": "const complianceAnalysisSchema = z.object({\n  compliant: z.boolean(),\n  violations: z.array(llmViolationSchema),\n  reasoning: z.string(),\n});",
          "explanation": "Zod schema for validating LLM compliance check responses"
        },
        {
          "filePath": "packages/cli/src/commands/analyze.ts",
          "lineRange": [
            300,
            320
          ],
          "snippet": "if (error instanceof LlmValidationError && error.zodErrors) {\n  console.error(chalk.gray(`\\n  Schema validation errors:`));\n  for (const issue of error.zodErrors.issues.slice(0, 5)) {\n    console.error(chalk.gray(`    ${issue.path.join('.')}: ${issue.message}`));\n  }\n}",
          "explanation": "CLI handles Zod validation errors from LLM responses with detailed error display"
        }
      ],
      "constraints": [
        "All structured LLM responses must be validated against Zod schemas",
        "LlmValidationError must include both raw response and Zod errors for debugging",
        "Schemas must be defined close to their usage (in the tool/extractor that uses them)",
        "Temperature should be lowered (0.2) for compliance checking to improve consistency"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "zod",
        "schema-validation",
        "llm-reliability",
        "structured-output"
      ]
    },
    {
      "id": "kQfDPJByhHzouhW62-5W9",
      "title": "Multi-Tier Error Handling with Typed Error Classes",
      "description": "The LLM subsystem defines a hierarchy of typed error classes: LlmError (base), LlmAuthError, LlmRateLimitError, LlmValidationError (with rawResponse and zodErrors), and LlmCostLimitError. The getFailureReason() function maps errors to human-readable messages. The CLI catches these specifically to provide targeted user guidance.",
      "category": "api",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "Five error classes are exported from core/src/llm.ts. The CLI's analyze command has specific catch blocks for LlmAuthError and LlmValidationError with different handling. getFailureReason() is a dedicated error-to-message mapper. This is a deliberate error handling strategy, not ad-hoc try/catch.",
      "evidence": [
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "export class LlmError extends Error { ... }\nexport class LlmAuthError extends LlmError { ... }\nexport class LlmRateLimitError extends LlmError { ... }\nexport class LlmValidationError extends LlmError { rawResponse?: string; zodErrors?: z.ZodError; }\nexport class LlmCostLimitError extends LlmError { ... }",
          "explanation": "Typed error hierarchy for different LLM failure modes"
        },
        {
          "filePath": "packages/cli/src/commands/analyze.ts",
          "lineRange": [
            55,
            65
          ],
          "snippet": "try {\n  requireApiKey(config);\n} catch (error) {\n  if (error instanceof LlmAuthError) {\n    console.error(chalk.red(error.message));\n    process.exit(1);\n  }\n  throw error;\n}",
          "explanation": "Specific error type handling for auth failures vs other errors"
        }
      ],
      "constraints": [
        "LLM errors must use the typed error class hierarchy",
        "LlmValidationError must carry rawResponse and zodErrors for debugging",
        "getFailureReason() must be used for user-facing error messages",
        "CLI must catch specific error types and provide targeted guidance"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "error-handling",
        "typed-errors",
        "error-hierarchy",
        "user-experience"
      ]
    },
    {
      "id": "bKeSgymMJP486gbhwBmnP",
      "title": "Analysis Caching with Content-Based Cache Keys",
      "description": "The analyzer implements a caching layer that hashes file contents to detect changes. The cache stores previous analysis results and can identify which files changed since the last run. Decisions from cached and fresh analysis are merged. Cache has a configurable TTL (cacheTtlHours) and can be bypassed with --force.",
      "category": "data",
      "status": "detected",
      "confidence": 0.91,
      "reasoning": "The analyzer/src/cache.ts exports hashFiles, identifyChangedFiles, loadCache, saveCache, clearCache, and mergeDecisions. The CLI's analyze command has a --force flag to bypass cache. The config has llm.cacheTtlHours. This is a deliberate optimization to reduce LLM costs on repeated analyses.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/cache.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "export interface AnalysisCache { ... }\nexport function hashFiles(...): string { ... }\nexport function identifyChangedFiles(...): string[] { ... }\nexport function loadCache(...): AnalysisCache | null { ... }\nexport function saveCache(...): void { ... }\nexport function mergeDecisions(...): ArchDecision[] { ... }",
          "explanation": "Full caching infrastructure with content hashing and decision merging"
        },
        {
          "filePath": "packages/cli/src/commands/analyze.ts",
          "lineRange": [
            40,
            50
          ],
          "snippet": ".option('--force', 'Bypass cache and run full analysis')",
          "explanation": "CLI flag to bypass cache when needed"
        }
      ],
      "constraints": [
        "Cache keys must be based on file content hashes, not timestamps",
        "Cached decisions must be merged with fresh analysis results",
        "Cache must have a configurable TTL",
        "The --force flag must bypass all caching"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "caching",
        "content-hashing",
        "cost-optimization",
        "incremental-analysis"
      ]
    },
    {
      "id": "wE27mfFLwkRWglLYhOkyG",
      "title": "Structured Logging with File Output and Verbose Console Mode",
      "description": "The core package provides a Logger class that always writes to .archguard/logs/ files and optionally outputs to console in verbose mode. Log entries are structured with level, category, message, and optional data. The CLI's --verbose flag enables real-time console output via an onLog callback.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.9,
      "reasoning": "The core/src/logger.ts exports Logger, initLogger, getLogger with LogEntry interface. The CLI's analyze command initializes the logger with projectDir and verbose flag, and always shows the log file path. The verbose console handler writes to stderr to avoid interfering with --json stdout output.",
      "evidence": [
        {
          "filePath": "packages/cli/src/commands/analyze.ts",
          "lineRange": [
            70,
            85
          ],
          "snippet": "const logger = initLogger({\n  projectDir,\n  verbose,\n  onLog: verbose ? verboseConsoleHandler : undefined,\n});",
          "explanation": "Logger initialization with optional verbose console output"
        },
        {
          "filePath": "packages/cli/src/commands/analyze.ts",
          "lineRange": [
            360,
            398
          ],
          "snippet": "function verboseConsoleHandler(entry: LogEntry): void {\n  // Use stderr so it doesn't interfere with --json stdout output\n  process.stderr.write(line + '\\n');\n}",
          "explanation": "Verbose output goes to stderr to preserve stdout for JSON output"
        }
      ],
      "constraints": [
        "Logs must always be written to .archguard/logs/ files",
        "Console output in verbose mode must go to stderr, not stdout",
        "Log entries must be structured with level, category, message, and optional data",
        "Log file path must always be displayed to users for debugging"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "logging",
        "structured-logging",
        "verbose-mode",
        "debug"
      ]
    },
    {
      "id": "jO1e1VoWaDV_1s5AQ46iZ",
      "title": "Commander.js CLI with Subcommand Pattern",
      "description": "The CLI uses Commander.js with a subcommand architecture. Each command (analyze, review, sync, watch, serve, velocity, summary, decisions, login, init, server, costs) is defined in its own file under commands/ and registered via a registerXCommand(program) function. Commands share common patterns: chalk for colors, ora for spinners, and @archguard/core for config loading.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "12 command files in cli/src/commands/ all export a registerXCommand function that takes a Commander program instance. The main cli/src/index.ts imports and calls each registration function. All commands use chalk, ora, and loadConfig consistently.",
      "evidence": [
        {
          "filePath": "packages/cli/src/commands/analyze.ts",
          "lineRange": [
            30,
            40
          ],
          "snippet": "export function registerAnalyzeCommand(program: Command): void {\n  program\n    .command('analyze')\n    .description('Analyze the codebase for architectural decisions, patterns, and drift')\n    .option('--path <dir>', 'Project directory to analyze', '.')",
          "explanation": "Standard command registration pattern with options"
        },
        {
          "filePath": "packages/cli/src/index.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "import { registerAnalyzeCommand } from './commands/analyze.js';\nimport { registerReviewCommand } from './commands/review.js';\n// ... all 12 commands imported and registered",
          "explanation": "Main entry point registers all commands"
        }
      ],
      "constraints": [
        "Each CLI command must be in its own file under commands/",
        "Commands must export a registerXCommand(program: Command) function",
        "Commands must use chalk for colored output and ora for spinners",
        "Commands must load config via loadConfig() from @archguard/core",
        "Commands must validate API key upfront with requireApiKey() where LLM is needed"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "commander",
        "cli",
        "subcommands",
        "chalk",
        "ora"
      ]
    },
    {
      "id": "bEsQ2j_hIYm-hyztSPewD",
      "title": "Organization-Scoped Multi-Tenancy",
      "description": "The server implements organization-scoped multi-tenancy. The org-context middleware resolves the current organization from the authenticated user and injects it into the request context. All data queries are scoped by orgId. The dashboard has an org-switcher component. The database schema has organizations, orgMembers, and org-scoped foreign keys.",
      "category": "security",
      "status": "detected",
      "confidence": 0.92,
      "reasoning": "The middleware/org-context.ts exports orgContextMiddleware and getOrgContext. Job data interfaces include orgId. The dashboard has an OrgSwitcher component. The database schema has organizations and orgMembers tables. All route handlers query with org-scoped filters.",
      "evidence": [
        {
          "filePath": "packages/server/src/middleware/org-context.ts",
          "lineRange": [
            1,
            15
          ],
          "snippet": "export interface OrgContext { ... }\nexport function orgContextMiddleware() { ... }\nexport function getOrgContext(c: Context): OrgContext { ... }",
          "explanation": "Middleware that resolves and injects organization context"
        },
        {
          "filePath": "packages/server/src/jobs/velocity.job.ts",
          "lineRange": [
            30,
            35
          ],
          "snippet": "const { orgId, repoId, period } = job.data;\n// ...\nconst devRows = await db.select().from(schema.developers).where(eq(schema.developers.orgId, orgId));",
          "explanation": "Job data includes orgId and queries are scoped to it"
        },
        {
          "filePath": "packages/dashboard/src/components/layout/org-switcher.tsx",
          "lineRange": [
            1,
            10
          ],
          "snippet": "export function OrgSwitcher() { ... }",
          "explanation": "Dashboard component for switching between organizations"
        }
      ],
      "constraints": [
        "All data queries must be scoped by organization ID",
        "The org-context middleware must run after authentication",
        "Job data must include orgId for proper data isolation",
        "Users can belong to multiple organizations via orgMembers"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "multi-tenancy",
        "organization-scoped",
        "data-isolation"
      ]
    },
    {
      "id": "OlIaONZkJ6oaQ0UwPNIVR",
      "title": "XML-Structured LLM Prompts with Explicit Role/Task Separation",
      "description": "LLM prompts throughout the codebase use XML-like tags to structure content: <role>, <guidelines>, <important_rules>, <code_to_check>, <architectural_decisions>, <decision>, <task>, <summary_request>, <activity_data>, <format_instructions>. System prompts define the role and rules, while user prompts provide structured data and task instructions.",
      "category": "api",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "Multiple files use XML tags in LLM prompts: check-pattern.ts uses <code_to_check>, <architectural_decisions>, <decision>, <task>. summary.job.ts uses <role>, <guidelines>. llm-sync.ts uses <project>, <decisions>, <decision>. progress-report.ts uses structured sections. This is a consistent prompt engineering pattern across the codebase.",
      "evidence": [
        {
          "filePath": "packages/mcp-server/src/tools/check-pattern.ts",
          "lineRange": [
            230,
            270
          ],
          "snippet": "sections.push(`<code_to_check>\nFile: ${filePath}\n...\n</code_to_check>`);\n\nsections.push(`<architectural_decisions>...\n<decision>\n  <title>${decision.title}</title>\n  <category>${decision.category}</category>\n  ...\n</decision>`);",
          "explanation": "XML-structured prompt with semantic tags for code and decisions"
        },
        {
          "filePath": "packages/server/src/jobs/summary.job.ts",
          "lineRange": [
            115,
            130
          ],
          "snippet": "const SUMMARY_SYSTEM_PROMPT = `<role>\nYou are an expert technical writing assistant...\n</role>\n\n<guidelines>\n- Use markdown formatting...\n</guidelines>`;",
          "explanation": "System prompt uses <role> and <guidelines> XML tags"
        },
        {
          "filePath": "packages/context-sync/src/llm-sync.ts",
          "lineRange": [
            90,
            120
          ],
          "snippet": "const userPrompt = `<project>\n  <languages>${config.analysis.languages.join(', ')}</languages>\n  <total_decisions>${active.length}</total_decisions>\n  <token_budget>${maxTokens}</token_budget>\n</project>\n\n<decisions>\n${decisionsXml}\n</decisions>`;",
          "explanation": "Structured XML for project context and decisions in sync prompts"
        }
      ],
      "constraints": [
        "LLM prompts must use XML-like tags to structure content sections",
        "System prompts must define role and rules separately from data",
        "User prompts must provide structured data in tagged sections",
        "Response format instructions must be explicit in the prompt"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:58.901Z",
      "tags": [
        "prompt-engineering",
        "xml-structured-prompts",
        "llm-prompts",
        "claude"
      ]
    },
    {
      "id": "1enUJ9afc6dTRCzhtQIDx",
      "title": "Core Package as Shared Foundation Layer",
      "description": "The @archguard/core package serves as the foundational shared layer containing types, configuration, database access, LLM client, git operations, authentication primitives, logging, and utility functions. All other packages depend on core but core depends on no other @archguard packages.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.96,
      "reasoning": "Every non-core package imports from @archguard/core. The core package exports types (541 lines of type definitions), config loading, database client, LLM client, git client, auth helpers, logger, and utilities. This is a deliberate shared kernel pattern. The dependency flow analysis confirms core has no dependencies on other @archguard packages.",
      "evidence": [
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: ArchCategory, DecisionStatus, Evidence, ArchDecision, ArchSnapshot, DriftEventType, DriftEvent, Dependency, DependencyNode, ... (541 lines)",
          "explanation": "Massive shared type definitions file establishing the domain vocabulary for the entire system"
        },
        {
          "filePath": "packages/core/src/index.ts",
          "lineRange": [
            1,
            106
          ],
          "snippet": "exports: loadConfig, createSqliteClient, createLlmClient, createGitClient, Logger, generateId, hasPermission, ...",
          "explanation": "Core barrel export aggregates all shared infrastructure: config, db, llm, git, auth, logger, utils"
        },
        {
          "filePath": "packages/analyzer/src/layer-detector.ts",
          "lineRange": [
            14,
            15
          ],
          "snippet": "import type { ParsedFile, LayerDefinition, LayerViolation } from '@archguard/core';",
          "explanation": "Analyzer package importing types from core, demonstrating the dependency direction"
        }
      ],
      "constraints": [
        "Core must not depend on any other @archguard/* package",
        "All shared types must be defined in core/src/types.ts",
        "Infrastructure concerns (db, llm, git) are centralized in core",
        "Adding new shared functionality requires modifying the core package"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "shared-kernel",
        "foundation-layer",
        "type-definitions",
        "infrastructure"
      ]
    },
    {
      "id": "ZGJOe_77DqGC3f9VCwO0x",
      "title": "Custom Hooks for Data Fetching in Dashboard",
      "description": "The dashboard uses custom React hooks (use-decisions, use-reviews, use-velocity, use-sse) as the data fetching abstraction layer. Each hook encapsulates API calls, loading/error states, and returns typed data. Pages compose these hooks rather than calling APIs directly.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "Four custom hooks exist in packages/dashboard/src/hooks/, each following the same pattern: they import from @/lib/api, manage loading/error state, and return typed data. Every page component examined uses these hooks rather than direct API calls. This is a consistent, deliberate abstraction pattern.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/hooks/use-decisions.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "imports: react, @/lib/api\nexports: DecisionCategory, DecisionStatus, DecisionEvidence, Decision, DecisionFilters, useDecisions, useDecision",
          "explanation": "Custom hook providing decisions data with filtering, typed interfaces, and both list/detail variants"
        },
        {
          "filePath": "packages/dashboard/src/app/(app)/decisions/page.tsx",
          "lineRange": [
            42,
            47
          ],
          "snippet": "const { decisions, loading, error } = useDecisions({\n    search: search || undefined,\n    category: category || undefined,\n    status: status || undefined,\n  });",
          "explanation": "Page consumes hook with filter parameters, receiving typed data + loading/error states"
        },
        {
          "filePath": "packages/dashboard/src/hooks/use-velocity.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: useTeamVelocity, useDeveloperVelocity",
          "explanation": "Velocity hook provides both team-level and individual developer data fetching"
        }
      ],
      "constraints": [
        "Pages must use custom hooks for data fetching, not direct API calls",
        "Each hook must handle loading and error states",
        "Hook interfaces must be typed and exported for component consumption",
        "New data domains require new custom hooks in the hooks/ directory"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "custom-hooks",
        "data-fetching",
        "react-patterns",
        "separation-of-concerns"
      ]
    },
    {
      "id": "tlbR71EaNd0zrxMxkZ8OG",
      "title": "Hono as HTTP Framework with Middleware Chain",
      "description": "The server package uses Hono as the HTTP framework with a layered middleware chain: CORS, logging, auth middleware, org-context middleware, and rate limiting. Routes are organized as separate router modules mounted on the main app.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The server/src/index.ts imports from hono, hono/cors, hono/logger, and @hono/node-server. Middleware files exist for auth, org-context, rate-limit, and rbac. Routes are organized as separate files each exporting a createXxxRouter function. This is a deliberate, well-structured middleware architecture.",
      "evidence": [
        {
          "filePath": "packages/server/src/index.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "imports: hono, hono/cors, hono/logger, @hono/node-server, ./middleware/auth.js, ./middleware/org-context.js, ./middleware/rate-limit.js, ./auth/index.js, ./routes/decisions.js, ./routes/analysis.js, ...",
          "explanation": "Main server file imports Hono framework, middleware chain, and all route modules"
        },
        {
          "filePath": "packages/server/src/middleware/auth.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "imports: hono, @archguard/core, ../auth/index.js\nexports: authMiddleware",
          "explanation": "Auth middleware as a Hono middleware function"
        },
        {
          "filePath": "packages/server/src/middleware/rate-limit.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: rateLimit, standardLimit, strictLimit, analysisLimit",
          "explanation": "Rate limiting middleware with pre-configured tiers for different endpoint types"
        }
      ],
      "constraints": [
        "All HTTP handling must go through Hono framework",
        "New routes must be created as separate router modules in routes/",
        "Middleware must be applied in the correct order: CORS → logging → auth → org-context",
        "Rate limiting must be applied per-route using the appropriate tier"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "hono",
        "middleware",
        "http-framework",
        "route-modules"
      ]
    },
    {
      "id": "VF34TnjSX_ZJdHzhH-Yqz",
      "title": "Server-Sent Events (SSE) for Real-Time Updates",
      "description": "The system uses Server-Sent Events for real-time communication from server to dashboard. The server has an SSE route with broadcastEvent and client management. The dashboard has both a lib/sse.ts utility and a use-sse.ts hook for consuming events.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "Three separate SSE implementations exist: server/src/routes/sse.ts (server-side broadcasting), dashboard/src/lib/sse.ts (client-side EventSource wrapper), and dashboard/src/hooks/use-sse.ts (React hook). The server's broadcastEvent is also re-exported from server/src/index.ts, suggesting it's used by job workers to push updates.",
      "evidence": [
        {
          "filePath": "packages/server/src/routes/sse.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "imports: hono, hono/streaming\nexports: SSEEventType, SSEEvent, broadcastEvent, getConnectedClientCount, createSSERouter",
          "explanation": "Server-side SSE implementation with typed events and broadcasting"
        },
        {
          "filePath": "packages/dashboard/src/hooks/use-sse.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: SSEOptions, SSEMessage, SSEStatus, useSSE",
          "explanation": "React hook for consuming SSE events with connection status tracking"
        },
        {
          "filePath": "packages/dashboard/src/lib/sse.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: SSEStatus, SSEEvent, useEventSource",
          "explanation": "Lower-level SSE utility with EventSource management"
        }
      ],
      "constraints": [
        "Real-time updates must use SSE, not WebSockets",
        "SSE events must be typed using SSEEventType",
        "Dashboard components must use the use-sse hook for event consumption",
        "Server-side broadcasting must go through the broadcastEvent function"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "sse",
        "real-time",
        "event-streaming",
        "push-notifications"
      ]
    },
    {
      "id": "UQgyYffyJu-FCVgqPRvCW",
      "title": "Multi-Format Output Strategy Pattern in Reviewer",
      "description": "The reviewer package implements a strategy pattern for output formatting with four formatters: terminal (CLI), GitHub PR (inline comments + check annotations), Bitbucket PR (reports + annotations), and JSON (structured output). Each formatter transforms the same ReviewResult into platform-specific output.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "Four formatter files exist in reviewer/src/formatters/, each exporting a format function. The reviewer's index.ts re-exports all formatters. The CLI review command imports formatForTerminal, formatForGitHubPr, and formatForBitbucket. Each formatter has platform-specific types (GitHubInlineComment, BitbucketAnnotation, etc.).",
      "evidence": [
        {
          "filePath": "packages/reviewer/src/formatters/github-pr.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: GitHubInlineComment, GitHubCheckAnnotation, GitHubFormattedOutput, formatForGitHubPr, formatForGitHubFull",
          "explanation": "GitHub-specific formatter producing inline comments and check annotations"
        },
        {
          "filePath": "packages/reviewer/src/formatters/bitbucket-pr.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: BitbucketReport, BitbucketReportData, BitbucketAnnotation, BitbucketFormattedOutput, formatForBitbucketPr, formatForBitbucketFull",
          "explanation": "Bitbucket-specific formatter producing code insights reports and annotations"
        },
        {
          "filePath": "packages/reviewer/src/index.ts",
          "lineRange": [
            1,
            20
          ],
          "snippet": "exports: formatForTerminal, formatForGitHubPr, formatForGitHubFull, formatForBitbucketPr, formatForBitbucketFull, formatForJson, buildJsonOutput",
          "explanation": "Barrel export re-exports all formatters, confirming they're first-class public APIs"
        }
      ],
      "constraints": [
        "New output platforms require a new formatter in reviewer/src/formatters/",
        "All formatters must accept the same ReviewResult input",
        "Platform-specific types must be defined within each formatter file",
        "Formatters must be re-exported through the reviewer's index.ts"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "strategy-pattern",
        "formatters",
        "multi-platform",
        "output-adapters"
      ]
    },
    {
      "id": "2m1y5Cv5RsJQmBJvLBDcV",
      "title": "AI-Powered Context Sync to Multiple IDE Formats",
      "description": "The context-sync package generates AI coding assistant configuration files from architectural decisions. It supports 7 output formats: Cursor rules, Claude CLAUDE.md, GitHub Copilot instructions, Windsurf rules, Kiro steering, Agents.md, and custom templates. A SyncEngine class orchestrates generation with file watching support.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "Seven generator files exist in context-sync/src/generators/, each targeting a specific IDE/AI assistant format. The SyncEngine class imports all generators and orchestrates sync. The templates.ts provides Handlebars-based template compilation shared across generators. This is a clear adapter pattern for multiple output targets.",
      "evidence": [
        {
          "filePath": "packages/context-sync/src/sync-engine.ts",
          "lineRange": [
            1,
            15
          ],
          "snippet": "imports: chokidar, @archguard/core, ./generators/cursorrules.js, ./generators/claude-md.js, ./generators/agents-md.js, ./generators/copilot.js, ./generators/windsurf.js, ./generators/kiro.js, ./generators/custom.js, ./llm-sync.js, ./templates.js",
          "explanation": "SyncEngine imports all 7 generators plus LLM sync and template utilities"
        },
        {
          "filePath": "packages/context-sync/src/generators/cursorrules.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: @archguard/core, ../templates.js\nexports: generateCursorRules",
          "explanation": "Cursor rules generator using shared template infrastructure"
        },
        {
          "filePath": "packages/context-sync/src/templates.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "imports: handlebars, @archguard/core\nexports: registerHelpers, groupByCategory, compileTemplate, extractUserSections, insertUserSections, generationHeader",
          "explanation": "Shared Handlebars template infrastructure with user section preservation"
        }
      ],
      "constraints": [
        "New IDE/assistant formats require a new generator in generators/",
        "All generators must use the shared template infrastructure from templates.ts",
        "User-customized sections must be preserved across regeneration (extractUserSections/insertUserSections)",
        "Generated files must include a generation header"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "context-sync",
        "ide-integration",
        "code-generation",
        "handlebars",
        "adapter-pattern"
      ]
    },
    {
      "id": "khTFpP5dx-r5_V61dmO0O",
      "title": "Commander.js CLI with Register Pattern",
      "description": "The CLI uses Commander.js with a consistent registration pattern: each command is defined in its own file exporting a registerXxxCommand function that receives the Commander program instance. The main index.ts calls all registration functions sequentially.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.97,
      "reasoning": "The CLI index.ts imports 12 registerXxxCommand functions and calls them all with the program instance. Each command file follows the same pattern. This is a deliberate plugin-like architecture for CLI commands.",
      "evidence": [
        {
          "filePath": "packages/cli/src/index.ts",
          "lineRange": [
            50,
            75
          ],
          "snippet": "registerInitCommand(program);\nregisterAnalyzeCommand(program);\nregisterDecisionsCommand(program);\nregisterSyncCommand(program);\nregisterWatchCommand(program);\nregisterServeCommand(program);\nregisterReviewCommand(program);\nregisterVelocityCommand(program);\nregisterSummaryCommand(program);\nregisterLoginCommand(program);\nregisterServerCommand(program);\nregisterCostsCommand(program);",
          "explanation": "All 12 commands registered via consistent registerXxxCommand pattern"
        },
        {
          "filePath": "packages/cli/src/commands/analyze.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: commander, chalk, @archguard/core, @archguard/analyzer, ../tapir-spinner.js\nexports: registerAnalyzeCommand",
          "explanation": "Each command file exports a single registerXxxCommand function"
        }
      ],
      "constraints": [
        "New CLI commands must follow the registerXxxCommand pattern",
        "Each command must be in its own file under commands/",
        "Commands must be registered in the main index.ts",
        "Commands should import from @archguard/* packages for business logic"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "commander",
        "cli",
        "command-pattern",
        "plugin-architecture"
      ]
    },
    {
      "id": "NBJ_oWE0pJzYcl0NZ1Qnb",
      "title": "Model Context Protocol (MCP) Server with Tools and Resources",
      "description": "The system implements an MCP server exposing architectural knowledge as tools (get-decisions, check-pattern, suggest-approach, get-dependencies) and resources (decisions, patterns). It supports multiple transport modes: stdio, SSE, and streamable HTTP.",
      "category": "api",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "The mcp-server package imports @modelcontextprotocol/sdk and organizes functionality into tools/ and resources/ directories. The index.ts registers tools and resources on the MCP server and supports three transport types. This is a deliberate integration point for AI coding assistants.",
      "evidence": [
        {
          "filePath": "packages/mcp-server/src/index.ts",
          "lineRange": [
            1,
            15
          ],
          "snippet": "imports: @modelcontextprotocol/sdk/server/mcp.js, @modelcontextprotocol/sdk/server/stdio.js, @modelcontextprotocol/sdk/server/sse.js, @modelcontextprotocol/sdk/server/streamableHttp.js",
          "explanation": "MCP server with multiple transport support"
        },
        {
          "filePath": "packages/mcp-server/src/tools/check-pattern.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: zod, @archguard/core\nexports: CheckPatternInput, checkPatternInputSchema",
          "explanation": "MCP tool with Zod schema validation for input"
        },
        {
          "filePath": "packages/mcp-server/src/resources/decisions.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "exports: loadAllDecisions, loadDecisionById, loadAllConstraints, getDecisionsResource, getDecisionByIdResource, getConstraintsResource",
          "explanation": "MCP resources exposing architectural decisions as queryable data"
        }
      ],
      "constraints": [
        "MCP tools must have Zod input schemas for validation",
        "New tools go in tools/, new resources go in resources/",
        "All three transport modes must be supported",
        "Tools and resources must be registered in the main createMcpServer function"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "mcp",
        "model-context-protocol",
        "ai-tools",
        "multi-transport"
      ]
    },
    {
      "id": "DQZ4zFlPyHOddFCuti2Yd",
      "title": "Functional Module Pattern (No Classes for Business Logic)",
      "description": "The codebase predominantly uses exported functions rather than classes for business logic. Packages expose factory functions (createGitHubClient, createBitbucketClient, createSlackApp) and pure functions (detectLayerViolations, calculateVelocity, reviewChanges). Classes are used sparingly — mainly for errors, the SyncEngine, Logger, and SummaryScheduler.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.9,
      "reasoning": "Examining the exports across all packages, the vast majority are functions, not classes. The analyzer, reviewer, velocity, and work-summary packages are entirely function-based. Factory functions return object interfaces rather than class instances. The few classes that exist (Logger, SyncEngine, SummaryScheduler, error classes) are infrastructure concerns, not business logic.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/layer-detector.ts",
          "lineRange": [
            33,
            40
          ],
          "snippet": "export function detectLayerViolations(\n  graph: DependencyGraph,\n  files: ParsedFile[],\n  layers: LayerDefinition[]\n): LayerViolation[] {",
          "explanation": "Pure function taking data in, returning results — no class instantiation"
        },
        {
          "filePath": "packages/integrations/src/github/api.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: createGitHubClient\nfunctions: createGitHubClient, getDiff, createComment, createReview, createCheckRun, getFile, getPR",
          "explanation": "Factory function pattern returning an object with methods, not a class"
        },
        {
          "filePath": "packages/velocity/src/index.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "functions: calculateVelocity\nexports: collectGitStats, calculateEffortScores, calculateImpactScores, calculateDeveloperVelocityScores, detectBlockers",
          "explanation": "Velocity package is entirely function-based"
        }
      ],
      "constraints": [
        "Business logic should be implemented as exported functions, not classes",
        "External service clients should use factory function pattern",
        "Classes are reserved for stateful infrastructure (Logger, Scheduler) and error types",
        "Functions should accept typed parameters and return typed results"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "functional-style",
        "factory-functions",
        "no-classes",
        "pure-functions"
      ]
    },
    {
      "id": "4t24Z6Mn2l5AFICYgk91D",
      "title": "Zod for Runtime Schema Validation",
      "description": "Zod is used throughout the codebase for runtime validation of LLM outputs, configuration files, MCP tool inputs, and API data. It serves as the bridge between untyped external data (LLM responses, user config, API inputs) and the typed internal domain.",
      "category": "api",
      "status": "detected",
      "confidence": 0.92,
      "reasoning": "Zod is imported in core/src/config.ts (config validation), core/src/llm.ts (LLM response validation with analyzeWithLlmValidated), analyzer/src/decision-extractor.ts (decision schema), mcp-server tools (input schemas), and reviewer/src/llm-reviewer.ts. This consistent usage across trust boundaries is clearly intentional.",
      "evidence": [
        {
          "filePath": "packages/core/src/config.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: js-yaml, zod, ./types.js",
          "explanation": "Configuration loading uses Zod for schema validation"
        },
        {
          "filePath": "packages/core/src/llm.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: @anthropic-ai/sdk, zod\nexports: analyzeWithLlmValidated, extractJson",
          "explanation": "LLM module uses Zod to validate AI-generated responses"
        },
        {
          "filePath": "packages/mcp-server/src/tools/check-pattern.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: zod, @archguard/core\nexports: CheckPatternInput, checkPatternInputSchema",
          "explanation": "MCP tool inputs validated with Zod schemas"
        }
      ],
      "constraints": [
        "All external data (LLM responses, config files, API inputs) must be validated with Zod",
        "MCP tool inputs must define Zod schemas",
        "LLM response parsing should use analyzeWithLlmValidated for type-safe extraction",
        "Configuration loading must validate against Zod schemas"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "zod",
        "schema-validation",
        "runtime-validation",
        "type-safety"
      ]
    },
    {
      "id": "qq_AepcTAUTjUOxUD9DNC",
      "title": "LLM-Powered Prompt Template System for Work Summaries",
      "description": "The work-summary package uses a template-based approach for generating LLM prompts. Four templates (standup, sprint-review, one-on-one, progress-report) each build system and user prompts from collected data. A collector gathers git stats, PR data, and velocity metrics, then templates transform this into structured prompts.",
      "category": "behavioral",
      "status": "detected",
      "confidence": 0.94,
      "reasoning": "Four template files exist in work-summary/src/templates/, each exporting a buildXxxPrompt function that returns {systemPrompt, userPrompt}. The collector.ts gathers data into a CollectedData structure. The summarizer.ts orchestrates template selection and LLM invocation. The sprint-review template (full source) shows detailed prompt engineering with structured sections.",
      "evidence": [
        {
          "filePath": "packages/work-summary/src/templates/sprint-review.ts",
          "lineRange": [
            14,
            25
          ],
          "snippet": "export function buildSprintReviewPrompt(\n  data: CollectedData,\n  developerName: string,\n  period: string\n): { systemPrompt: string; userPrompt: string } {",
          "explanation": "Template function taking collected data and returning structured prompts"
        },
        {
          "filePath": "packages/work-summary/src/collector.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: CommitInfo, PullRequestInfo, ModuleActivity, PeriodVelocity, CollectedData, CollectorOptions\nfunctions: collectData, aggregateDevStats, collectCommits",
          "explanation": "Data collector gathering all inputs needed by templates"
        },
        {
          "filePath": "packages/work-summary/src/summarizer.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "imports: ./templates/one-on-one.js, ./templates/standup.js, ./templates/sprint-review.js, ./templates/progress-report.js",
          "explanation": "Summarizer imports all templates and orchestrates the generation pipeline"
        }
      ],
      "constraints": [
        "New summary types require a new template in templates/",
        "Templates must return {systemPrompt, userPrompt} structure",
        "All templates consume the same CollectedData structure from the collector",
        "Template prompts should be data-driven, not fabricating information"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "prompt-engineering",
        "templates",
        "llm-prompts",
        "work-summaries"
      ]
    },
    {
      "id": "U7py-hfgzpER0Om38UZgC",
      "title": "Configurable Layer Architecture Detection and Enforcement",
      "description": "The analyzer implements both automatic layer inference from directory naming conventions and configurable layer violation detection. The default hierarchy is presentation → application → domain ← infrastructure. Layer definitions can be customized in .archguard.yml configuration.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.95,
      "reasoning": "The layer-detector.ts (full source) shows both detectLayerViolations (configurable) and inferLayers (automatic). The inferLayers function maps common directory names to four architectural layers. The detectLayerViolations function checks every import edge against allowed dependencies. This is the core product feature — enforcing architectural boundaries.",
      "evidence": [
        {
          "filePath": "packages/analyzer/src/layer-detector.ts",
          "lineRange": [
            108,
            145
          ],
          "snippet": "export function inferLayers(files: ParsedFile[]): LayerDefinition[] {\n  const layerPatterns: Record<string, string[]> = {\n    presentation: ['ui', 'views', 'pages', 'components', 'presentation', 'frontend', 'web'],\n    application: ['application', 'services', 'use-cases', 'usecases', 'handlers', 'controllers'],\n    domain: ['domain', 'entities', 'models', 'core', 'business'],\n    infrastructure: ['infrastructure', 'repositories', 'adapters', 'db', 'database', 'external', 'clients'],\n  };",
          "explanation": "Automatic layer inference from directory naming conventions"
        },
        {
          "filePath": "packages/analyzer/src/layer-detector.ts",
          "lineRange": [
            33,
            95
          ],
          "snippet": "export function detectLayerViolations(\n  graph: DependencyGraph,\n  files: ParsedFile[],\n  layers: LayerDefinition[]\n): LayerViolation[] {",
          "explanation": "Configurable layer violation detection checking every import edge"
        },
        {
          "filePath": "packages/analyzer/src/layer-detector.ts",
          "lineRange": [
            147,
            151
          ],
          "snippet": "function getDefaultAllowedDeps(layerName: string): string[] {\n  switch (layerName) {\n    case 'presentation': return ['application', 'domain'];\n    case 'application': return ['domain'];\n    case 'domain': return [];\n    case 'infrastructure': return ['domain', 'application'];",
          "explanation": "Default dependency rules enforcing clean architecture boundaries"
        }
      ],
      "constraints": [
        "Layer definitions are configurable via .archguard.yml",
        "Default layer hierarchy follows clean architecture principles",
        "Layer violations are detected by analyzing the full dependency graph",
        "File-to-layer mapping uses glob patterns (minimatch)"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.006Z",
      "tags": [
        "layer-architecture",
        "clean-architecture",
        "violation-detection",
        "configurable"
      ]
    },
    {
      "id": "k8CEivt-jSSvGIq3BxWQz",
      "title": "Dashboard Component Organization by Domain",
      "description": "Dashboard components are organized by domain (decisions/, reviews/, velocity/, summaries/, charts/, graphs/, layout/) rather than by component type (buttons/, forms/, etc.). Each domain folder contains related components that are consumed by the corresponding page routes.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.92,
      "reasoning": "The components directory has 7 subdirectories, each aligned with a feature domain. decisions/ has decision-card, decision-editor, decision-table, evidence-viewer. reviews/ has diff-viewer, review-summary, violation-list. charts/ groups all chart components. This domain-driven organization mirrors the route structure.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/app/(app)/decisions/page.tsx",
          "lineRange": [
            6,
            10
          ],
          "snippet": "import { DecisionCard } from '@/components/decisions/decision-card';\nimport { DecisionTable } from '@/components/decisions/decision-table';",
          "explanation": "Decisions page imports from domain-specific component directory"
        },
        {
          "filePath": "packages/dashboard/src/app/(app)/reviews/[id]/page.tsx",
          "lineRange": [
            7,
            10
          ],
          "snippet": "import { ReviewSummaryCard } from '@/components/reviews/review-summary';\nimport { ViolationList } from '@/components/reviews/violation-list';\nimport { ViolationBreakdown } from '@/components/charts/violation-breakdown';",
          "explanation": "Review detail page imports from reviews/ and charts/ component directories"
        }
      ],
      "constraints": [
        "New components must be placed in the appropriate domain directory",
        "Shared visualization components go in charts/ or graphs/",
        "Layout components go in layout/",
        "Component directories should mirror the route structure"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.007Z",
      "tags": [
        "component-organization",
        "domain-driven",
        "feature-folders"
      ]
    },
    {
      "id": "FDFF6U_uj1RkCO8H_hr2A",
      "title": "Centralized API Client with Auth Token Management",
      "description": "The dashboard uses a centralized API client (lib/api.ts) that handles authentication token injection, error handling with typed ApiError, and provides typed HTTP methods (apiGet, apiPost, apiPut, apiDelete). All hooks and pages use this client rather than raw fetch.",
      "category": "api",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "lib/api.ts exports ApiError class and typed HTTP methods. It includes getAuthToken for automatic auth header injection. All custom hooks (use-decisions, use-reviews, use-velocity) import from @/lib/api. The SSE connection factory is also in this module.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/lib/api.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: ApiError, apiGet, apiPost, apiPut, apiDelete, createSSEConnection\nfunctions: getAuthToken, apiFetch, apiGet, apiPost, apiPut, apiDelete, createSSEConnection",
          "explanation": "Centralized API client with auth, error handling, and typed methods"
        },
        {
          "filePath": "packages/dashboard/src/hooks/use-decisions.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: react, @/lib/api",
          "explanation": "Decisions hook uses centralized API client"
        },
        {
          "filePath": "packages/dashboard/src/hooks/use-reviews.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: react, @/lib/api",
          "explanation": "Reviews hook uses centralized API client"
        }
      ],
      "constraints": [
        "All API calls must go through the centralized api.ts client",
        "Auth tokens are automatically injected by the client",
        "API errors must be thrown as ApiError instances",
        "New HTTP methods or connection types must be added to api.ts"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.007Z",
      "tags": [
        "api-client",
        "centralized",
        "auth-injection",
        "typed-http"
      ]
    },
    {
      "id": "LGoODJPAU9fEJMe6WNHbj",
      "title": "Inline .env Loader Without External Dependency",
      "description": "The CLI implements its own .env file parser inline rather than using the dotenv package. It reads .env from the current working directory, parses key=value pairs, strips quotes, and respects existing environment variables (no override).",
      "category": "deployment",
      "status": "detected",
      "confidence": 0.88,
      "reasoning": "The CLI index.ts contains a loadDotenv function with a comment 'Inline loader — avoids a dotenv dependency'. This is a deliberate choice to minimize dependencies. The implementation handles comments, quotes, and no-override semantics.",
      "evidence": [
        {
          "filePath": "packages/cli/src/index.ts",
          "lineRange": [
            14,
            40
          ],
          "snippet": "// Load .env file from the current working directory (or --path target).\n// Inline loader — avoids a dotenv dependency.\nfunction loadDotenv(dir: string): void {\n  const envPath = path.resolve(dir, '.env');\n  try {\n    const content = fs.readFileSync(envPath, 'utf-8');\n    for (const line of content.split('\\n')) {",
          "explanation": "Custom inline .env parser with explicit comment about avoiding dotenv dependency"
        }
      ],
      "constraints": [
        "No dotenv package dependency in the CLI",
        "Environment variables from .env must not override existing env vars",
        "The .env loader must handle comments, empty lines, and quoted values"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.007Z",
      "tags": [
        "zero-dependency",
        "env-loading",
        "minimal-dependencies"
      ]
    },
    {
      "id": "SNMIZmOHVppBsM2qTxan5",
      "title": "Tailwind CSS with Custom Brand Theme",
      "description": "The dashboard uses Tailwind CSS with a custom brand color palette and design system. Components use utility classes with a consistent pattern: card, card-padded, btn-primary, btn-secondary, btn-ghost, input-field as custom component classes alongside standard Tailwind utilities.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.91,
      "reasoning": "tailwind.config.ts exists with custom configuration. postcss.config.js is present. All dashboard components use Tailwind utility classes consistently. Custom class names like 'card', 'card-padded', 'btn-primary', 'btn-ghost', 'input-field' appear across multiple components, suggesting a custom component layer on top of Tailwind. The cn() utility (clsx + tailwind-merge) is used everywhere for conditional classes.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/app/(app)/reviews/page.tsx",
          "lineRange": [
            68,
            80
          ],
          "snippet": "<div className=\"card p-4\">\n  <input className=\"input-field pl-9\" />\n  <select className=\"input-field w-full sm:w-40\">",
          "explanation": "Custom component classes (card, input-field) used alongside Tailwind utilities"
        },
        {
          "filePath": "packages/dashboard/src/lib/utils.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: clsx, tailwind-merge\nexports: cn",
          "explanation": "cn() utility combining clsx and tailwind-merge for conditional class merging"
        },
        {
          "filePath": "packages/dashboard/src/app/(app)/decisions/[id]/page.tsx",
          "lineRange": [
            60,
            65
          ],
          "snippet": "className=\"btn-ghost gap-2\"\nclassName=\"card-padded\"\nclassName=\"btn-primary gap-2\"\nclassName=\"btn-secondary gap-2\"",
          "explanation": "Consistent use of custom button and card component classes"
        }
      ],
      "constraints": [
        "All styling must use Tailwind CSS utilities or custom component classes",
        "Conditional classes must use the cn() utility",
        "Brand colors must be defined in tailwind.config.ts",
        "Custom component classes (card, btn-*, input-field) must be used consistently"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.007Z",
      "tags": [
        "tailwind-css",
        "design-system",
        "utility-first",
        "custom-theme"
      ]
    },
    {
      "id": "xho7L_5jI3zpTFDnD9znV",
      "title": "Recharts for Data Visualization",
      "description": "The dashboard uses Recharts as its charting library for all data visualizations: velocity charts, contribution charts, drift timelines, violation breakdowns, and complexity heatmaps. Each chart is a self-contained component with typed props.",
      "category": "structural",
      "status": "detected",
      "confidence": 0.92,
      "reasoning": "Five chart components in dashboard/src/components/charts/ all import from recharts. The complexity-heatmap is a custom implementation but follows the same pattern. Each chart component defines its own data point interface and accepts typed props.",
      "evidence": [
        {
          "filePath": "packages/dashboard/src/components/charts/velocity-chart.tsx",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: recharts\nexports: VelocityChartDataPoint, VelocityChart",
          "explanation": "Velocity chart using Recharts with typed data points"
        },
        {
          "filePath": "packages/dashboard/src/components/charts/violation-breakdown.tsx",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: recharts\nexports: ViolationBreakdownData, ViolationBreakdown",
          "explanation": "Violation breakdown chart supporting both bar and pie variants"
        },
        {
          "filePath": "packages/dashboard/src/components/charts/drift-timeline.tsx",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: recharts\nexports: DriftDataPoint, DriftTimeline",
          "explanation": "Drift timeline chart using Recharts"
        }
      ],
      "constraints": [
        "All charts must use Recharts library",
        "Each chart component must define its own typed data point interface",
        "Charts must accept height as a prop for flexible sizing",
        "New visualizations should be added as components in charts/"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.007Z",
      "tags": [
        "recharts",
        "data-visualization",
        "charts",
        "typed-components"
      ]
    },
    {
      "id": "Rj5Ro9FUl-1KI-Wf2XfOO",
      "title": "YAML-Based Configuration with Schema Validation",
      "description": "The system uses .archguard.yml as its configuration file format, parsed with js-yaml and validated with Zod schemas. The config module provides loadConfig, writeDefaultConfig, and getDefaultConfig functions. Configuration covers languages, layers, rules, sync formats, LLM settings, and more.",
      "category": "deployment",
      "status": "detected",
      "confidence": 0.93,
      "reasoning": "core/src/config.ts imports js-yaml and zod, exports loadConfig and writeDefaultConfig. The ArchGuardConfig type in types.ts defines a comprehensive configuration structure. The CLI init command generates a default config file. This is a deliberate configuration-as-code approach.",
      "evidence": [
        {
          "filePath": "packages/core/src/config.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: js-yaml, zod, ./types.js\nexports: getDefaultConfig, loadConfig, writeDefaultConfig",
          "explanation": "Config module using YAML parsing with Zod validation"
        },
        {
          "filePath": "packages/core/src/types.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: ... LayerDefinition, ArchGuardConfig, ...",
          "explanation": "ArchGuardConfig type defining the full configuration schema"
        },
        {
          "filePath": "packages/cli/src/commands/init.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: commander, chalk, ora, @archguard/core\nexports: registerInitCommand",
          "explanation": "Init command generates default .archguard.yml configuration"
        }
      ],
      "constraints": [
        "Configuration must be in YAML format (.archguard.yml)",
        "All config values must be validated against Zod schemas",
        "Default configuration must be provided via getDefaultConfig",
        "New configuration options must be added to both the Zod schema and TypeScript types"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.007Z",
      "tags": [
        "yaml-config",
        "schema-validation",
        "configuration-as-code"
      ]
    },
    {
      "id": "lU-oaMLj3JerNWMIgPV53",
      "title": "Rate Limiting with Tiered Presets",
      "description": "The server implements rate limiting middleware with three pre-configured tiers: standardLimit (general API), strictLimit (sensitive operations), and analysisLimit (resource-intensive operations). Rate limiting is applied per-route with configurable windows and request counts.",
      "category": "security",
      "status": "detected",
      "confidence": 0.91,
      "reasoning": "rate-limit.ts exports three preset configurations alongside the generic rateLimit factory. The reviews and analysis routes explicitly import rate-limit middleware. The implementation uses in-memory tracking with configurable key generation.",
      "evidence": [
        {
          "filePath": "packages/server/src/middleware/rate-limit.ts",
          "lineRange": [
            1,
            10
          ],
          "snippet": "exports: rateLimit, standardLimit, strictLimit, analysisLimit\ninterfaces: RateLimitEntry, RateLimitOptions",
          "explanation": "Rate limiting with three tiered presets for different endpoint types"
        },
        {
          "filePath": "packages/server/src/routes/reviews.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: ../middleware/rate-limit.js",
          "explanation": "Reviews route applies rate limiting"
        },
        {
          "filePath": "packages/server/src/routes/analysis.ts",
          "lineRange": [
            1,
            5
          ],
          "snippet": "imports: ../middleware/rate-limit.js",
          "explanation": "Analysis route applies rate limiting for resource-intensive operations"
        }
      ],
      "constraints": [
        "Resource-intensive endpoints must use analysisLimit",
        "Sensitive endpoints must use strictLimit",
        "General endpoints should use standardLimit",
        "Rate limit headers must be set on responses"
      ],
      "relatedDecisions": [],
      "detectedAt": "2026-02-20T10:22:56.007Z",
      "tags": [
        "rate-limiting",
        "security",
        "tiered-limits",
        "middleware"
      ]
    }
  ],
  "createdAt": "2026-02-20T10:22:59.009Z",
  "ttlHours": 24,
  "totalFiles": 179
}